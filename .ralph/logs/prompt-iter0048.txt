You are operating inside the Ralph Gold loop.

Rules:
- Do exactly ONE task per iteration.
- Use the Memory Files below as the source of truth (especially ANCHOR and any Repo Prompt context pack).
- Make the smallest correct change-set that satisfies the task acceptance criteria.
- When you finish the task, mark it done in the PRD tracker.
- Do not mark tasks done if you did not run/confirm the configured gates pass locally.
- If you are blocked, record a clear reason (including commands + errors) in .ralph/progress.md and leave the task open.

## File writing authority (CRITICAL)
- **You are authorized to write code directly.** Create and modify files without asking for permission.
- **Do not stop and request approval.** You are autonomousâ€”complete the full implementation.
- **Implement the entire solution** in one iteration. Don't design and then waitâ€”design AND implement.
- Your task acceptance criteria are your complete authority to proceed with file changes.

Workflow:
1) Read Memory Files in order.
2) Re-state the task acceptance criteria.
3) Implement completely (write all necessary files).
4) Run the repo's gates (see .ralph/AGENTS.md) and fix failures.
5) Update PRD + progress.

Output:
- Prefer concise, factual updates.
- If you ran commands, include the command and 1-3 lines of the most relevant output.

<ANCHOR>
# Ralph Gold Anchor

Task: 17 - Add checksum functions to `scripts/migration/lib/checksum.ts`

Acceptance criteria:
- `checksum()`: compute SHA-256 hash of file
- `verifyBackup()`: compare all files between original and backup
- Return summary with mismatches list
- Test: Manual verify with test directory

Repo reality:
- branch: main
- git status --porcelain:
```
M .ralph/PRD.md
 M .ralph/progress.md
 M .ralph/ralph.toml
 D .ralph/specs/tech-spec-2026-01-20-knowledge-reorganization.md
?? .ralph/archive/20260120-190753/
?? .ralph/attempts/
?? .ralph/context/
?? .ralph/logs/
?? .ralph/permissions.json
?? .ralph/receipts/
?? .ralph/state.json
?? scripts/migration/
```
- git diff --stat:
```
.ralph/PRD.md                                      |   18 +-
 .ralph/progress.md                                 |   54 +
 .ralph/ralph.toml                                  |   13 +-
 ...ech-spec-2026-01-20-knowledge-reorganization.md | 1157 --------------------
 4 files changed, 74 insertions(+), 1168 deletions(-)
```

Constraints:
- Work on exactly ONE task per iteration
- Do not claim completion without passing gates
- Prefer minimal diffs; keep repo clean
</ANCHOR>

## Orchestrator Addendum (auto-generated)
Iteration: 48

Hard iteration constraints:
- One task per iteration (one commit per iteration).
- Apply backpressure: run the commands in AGENTS.md and fix until they pass.

Selected task for this iteration:
- id: 17
- title: Add checksum functions to `scripts/migration/lib/checksum.ts`
- acceptance:
  - `checksum()`: compute SHA-256 hash of file
  - `verifyBackup()`: compare all files between original and backup
  - Return summary with mismatches list
  - Test: Manual verify with test directory

Do not work on any other task in this iteration.

<PROJECT_MEMORY>
## .ralph/AGENTS.md
# Ralph Gold Agents & Gates

This file is read by Ralph Gold each iteration.

## Gates (backpressure)

Ralph Gold will run gates *after* the agent makes changes. Configure them in `.ralph/ralph.toml`.

Recommended patterns:

### Option A (recommended): `prek` as the universal gate runner

- Put your quality contract in `.pre-commit-config.yaml`
- Then enable the gate:
  - `[gates.prek] enabled = true` (runs `prek run --all-files`)

No git hooks are installed by Ralph Gold.

### Option B: Explicit commands

Examples:
- `uv run ruff check .`
- `uv run mypy src`
- `uv run pytest -q`
- `npm test`

## Review gate (cross-model)

Optionally enable `[gates.review]` to require a reviewer model to return `SHIP`.

## Notes

- Receipts are written under `.ralph/receipts/` each iteration.
- Repo Prompt context packs (if enabled) are written under `.ralph/context/`.


## .ralph/PRD.md
# Knowledge Reorganization PRD

## Overview

Reorganize the xKit knowledge base from category-first (`year/month/category/@handle/file.md`) to author-first structure (`year/month/@handle (real name)/category/file.md`) with enhanced filenames including date, handle, category, title, and short ID. Includes comprehensive migration tooling with atomic operations, automated rollback, degraded mode support, and full observability.

**Tech Spec:** `.spec/tech-spec-2026-01-20-knowledge-reorganization.md`

## Task Breakdown Guidelines

**CRITICAL:** Tasks must be atomic (5-15 minutes each) with specific acceptance criteria and test commands.

## Tasks

### Phase 1: Core Types

- [-] Create `src/bookmark-organization/types.ts` file
  - Add `AuthorFolder`, `KnowledgePath`, `FilenameComponents` interfaces
  - Add `RealNameCache`, `MigrationState`, `MigrationError` interfaces
  - Add `MigrationFailureMarker`, `PreflightCheck` interfaces
  - Export all types
  - Test: `pnpm test -- src/bookmark-organization/types.test.ts` passes

- [x] Add `sanitizeAuthorName()` to `src/bookmark-organization/sanitize.ts`
  - ASCII-only handle validation (`/^[A-Za-z0-9_]+$/`)
  - Reserved Windows filename check (CON, PRN, AUX, NUL, COM1-9, LPT1-9)
  - Real name sanitization (control chars, Unicode NFC, dangerous chars)
  - Limit real name to 100 chars
  - Return `@handle` or `@handle (Real Name)`
  - Test: `pnpm test -- src/bookmark-organization/sanitize.test.ts` passes

- [x] Add `sanitizeSlug()` to `src/bookmark-organization/sanitize.ts`
  - Pre-check for path traversal (`/\.\.[\/\\]/`)
  - Remove control characters, normalize Unicode to NFC
  - Replace non-alphanumerics with hyphens
  - Limit to 80 chars
  - Test: `pnpm test -- src/bookmark-organization/sanitize.test.ts` passes

### Phase 2: Real Name Cache

- [x] Add real name cache functions to `src/bookmark-organization/cache.ts`
  - `loadRealNameCache()`: load from `.real-name-cache.json` or create new
  - `saveRealNameCache()`: write cache with timestamp
  - `getRealName()`: lookup handle in cache
  - `setRealName()`: add or update cache entry
  - Test: `pnpm test -- src/bookmark-organization/cache.test.ts` passes

### Phase 3: Filename Generation

- [x] Add `generateEnhancedFilename()` to `src/bookmark-markdown/filename.ts`
  - Format: `{date}-{handle}-{category}-{title}-{short_id}.md`
  - Use linked content title or tweet text excerpt
  - Mandatory short ID (last 6 chars of tweet ID)
  - Limit total filename to 255 chars
  - Test: `pnpm test -- src/bookmark-markdown/filename.test.ts` passes

- [x] Add `validatePathLength()` to `src/bookmark-markdown/filename.ts`
  - Check path length â‰¤ 240 chars (Windows safe)
  - Throw error with path preview if exceeded
  - Test: `pnpm test -- src/bookmark-markdown/filename.test.ts` passes

- [x] Update `MarkdownWriter.generateFilename()` in `src/bookmark-markdown/writer.ts`
  - Call `generateEnhancedFilename()` instead of old method
  - Note: writer.test.ts does not exist yet; filename.test.ts passes

### Phase 4: Disk Space & Pre-flight

- [x] Add `getDirectorySize()` to `scripts/migration/lib/disk.ts`
  - Recursively scan directory and sum file sizes
  - Return total bytes
  - Test: Manual verify with known test directory

- [x] Add `checkDiskSpace()` to `scripts/migration/lib/disk.ts`
  - Use `statvfs` to get available space (Unix)
  - Require 2.5x directory size (original + backup + margin)
  - Throw error if insufficient with GB amounts
  - Fallback for Windows (skip check with warning)
  - Test: Manual verify with small directory

- [x] Add `preFlightChecks()` to `scripts/migration/lib/check.ts`
  - Call `getDirectorySize()` and `checkDiskSpace()`
  - Count files to migrate
  - Log summary and throw if checks fail
  - Return `PreflightCheck` result
  - Test: Manual verify on `knowledge/` directory

### Phase 5: Migration Script Core

- [-] Create `scripts/migrate-to-author-first.mjs` CLI scaffold
  - Parse arguments: --dry-run, --backup-dir, --resume, --verify, --verbose, --force, --help
  - Set up logging to `migration.log`
  - Exit codes: 0=success, 1=errors, 2=validation failed, 3=cancelled
  - Test: `node scripts/migrate-to-author-first.mjs --help` shows usage

- [-] Add dry-run mode to `scripts/migrate-to-author-first.mjs`
  - Scan all files in `knowledge/`
  - Calculate new paths for all files
  - Print summary: file counts, new structure example, backup location
  - Prompt for confirmation: "Continue? [y/N]"
  - Exit if not 'y'
  - Test: `node scripts/migrate-to-author-first.mjs --dry-run` shows plan

### Phase 6: File Operations with Timeout

- [-] Add `moveFileWithTimeout()` to `scripts/migration/lib/files.ts`
  - Use `Promise.race()` with 5 second timeout
  - Copy file first, verify size matches, then delete source
  - Throw timeout error if stuck
  - Test: Manual verify with test files

### Phase 7: Checkpoint & Recovery

- [-] Add checkpoint system to `scripts/migration/lib/checkpoint.ts`
  - `writeCheckpoint()`: write state to `.migration-state.json` every 100 files
  - `resumeFromCheckpoint()`: load checkpoint state
  - Track: migrationId, timestamps, files processed, processed files list
  - Test: Manual interrupt and resume

- [-] Add SIGINT handler to `scripts/migrate-to-author-first.mjs`
  - Catch Ctrl+C, write checkpoint, exit gracefully
  - Print message: "Migration paused. Run with --resume to continue."
  - Test: Manual Ctrl+C during migration

### Phase 8: Migration Execution

- [-] Add main migration logic to `scripts/migrate-to-author-first.mjs`
  - For each file: calculate new path, create author folder, create category folder
  - Call `moveFileWithTimeout()` for each file
  - Write checkpoint every 100 files
  - Show progress: `[=====>] 45% (382/847) | 234 files/sec`
  - Log each move to `migration.log`
  - Track errors (recoverable) and continue
  - Test: `node scripts/migrate-to-author-first.mjs --dry-run` on sample data

### Phase 9: Checksum Verification

- [ ] Add checksum functions to `scripts/migration/lib/checksum.ts`
  - `checksum()`: compute SHA-256 hash of file
  - `verifyBackup()`: compare all files between original and backup
  - Return summary with mismatches list
  - Test: Manual verify with test directory

### Phase 10: Backup & Rollback

- [ ] Add backup creation to `scripts/migrate-to-author-first.mjs`
  - Copy entire `knowledge/` to `knowledge_backup_<timestamp>/`
  - Run `verifyBackup()` after copy
  - Throw if verification fails
  - Test: `node scripts/migrate-to-author-first.mjs --dry-run` creates backup

- [ ] Create `scripts/rollback-migration.mjs`
  - Parse --backup-dir and --verify flags
  - Validate backup exists
  - Create backup of current state
  - Delete `knowledge/`, copy backup to `knowledge/`
  - Revert code changes if needed
  - Run build and verify
  - Test: Manual rollback after test migration

### Phase 11: Concurrency Locking

- [ ] Add lock file functions to `src/bookmark-markdown/lock.ts`
  - `createMigrationLock()`: write `.migration-lock` with migration ID and timestamp
  - `checkMigrationLock()`: return true if lock exists
  - `clearMigrationLock()`: remove lock file
  - Test: `pnpm test -- src/bookmark-markdown/lock.test.ts` passes

- [ ] Update bookmark archiving to check for migration lock
  - In archiving entry point, call `checkMigrationLock()`
  - If locked, print warning and exit (pause archiving)
  - Test: Manual verify lock pauses archiving

### Phase 12: Degraded Mode

- [ ] Add degraded mode functions to `scripts/migration/lib/degraded.ts`
  - `markMigrationFailed()`: write `.migration-failed` marker with error
  - `isDegradedMode()`: check if marker exists
  - `getOutputDirectory()`: return `knowledge_degraded/` if failed
  - `clearDegradedMode()`: remove marker
  - Test: Manual verify degraded mode activation

- [ ] Update `MarkdownWriter` constructor to use degraded output
  - Call `isDegradedMode()` on init
  - If degraded, set `outputDir` to `knowledge_degraded/`
  - Print warning message
  - Test: Manual verify degraded mode writes to fallback

- [ ] Add degraded mode handling to `scripts/migrate-to-author-first.mjs`
  - On any error, call `markMigrationFailed()`
  - Exit with error code 1
  - On success, call `clearDegradedMode()`
  - Test: Manual error triggers degraded mode

### Phase 13: Package Scripts & Docs

- [ ] Add npm scripts to `package.json`
  - `"migrate-knowledge": "node scripts/migrate-to-author-first.mjs"`
  - `"migrate-knowledge:dry-run": "node scripts/migrate-to-author-first.mjs --dry-run"`
  - `"rollback-knowledge": "node scripts/rollback-migration.mjs"`
  - Test: `pnpm migrate-knowledge --help` works

- [ ] Add migration documentation to `docs/KNOWLEDGE_MIGRATION.md`
  - Overview of new structure
  - Migration instructions
  - Rollback instructions
  - Troubleshooting guide
  - Test: Documentation is clear and complete

### Phase 14: Testing & Validation

- [ ] Add migration tests to `tests/migration.test.ts`
  - Test dry-run on sample data
  - Test checkpoint creation and resume
  - Test degraded mode activation
  - Test lock file handling
  - Test: `pnpm test -- tests/migration.test.ts` passes

- [ ] Run full migration test on backup
  - Copy `knowledge/` to test location
  - Run full migration
  - Verify all files moved correctly
  - Verify checksums match
  - Test rollback restores correctly
  - Test: Manual end-to-end validation

## Acceptance Criteria

- [ ] All existing files migrated without data loss
- [ ] New bookmarks use author-first structure with enhanced filenames
- [ ] Build succeeds with no broken links (`pnpm build`)
- [ ] Migration script has dry-run mode with detailed output
- [ ] Automated rollback script tested and documented
- [ ] Comprehensive path sanitization implemented (ASCII-only handles)
- [ ] Checksum verification before/after migration
- [ ] Checkpoint/resume capability functional
- [ ] CLI interface with all specified flags
- [ ] Confirmation flow (dry-run â†’ prompt â†’ execute)
- [ ] Migration logging to `migration.log`
- [ ] Progress indicator during migration
- [ ] Concurrency handling (pause with lock file)
- [ ] Path length validation (fail fast if >240 chars)
- [ ] ID suffix mandatory in filename generation
- [ ] TypeScript types defined for all new structures
- [ ] Real name cache format defined
- [ ] Disk space check implemented
- [ ] Per-file timeout implemented (5 second default)
- [ ] Degraded mode functional (fallback to `knowledge_degraded/`)

## Notes

- Mark done: - [x]
- Mark blocked: - [-]
- Dependencies: add acceptance bullet like "- Depends on: 1, 2"


## .ralph/progress.md
# progress.md

Append-only loop memory.
Keep entries short; delete nothing; add clarifications when you learn.

---
- [20260120T213526Z] iter 23 mode=prd status=CONTINUE checks=PASS story=S8 agent=claude branch=main log=20260120T213526Z-iter0023-claude.log
[2026-01-20T21:39:17.716658+00:00] BLOCKED task 8 (Add `getDirectorySize()` to `scripts/migration/lib/disk.ts`) after 3 attempts: unknown
- [20260120T213917Z] iter 24 mode=prd status=CONTINUE checks=PASS story=S9 agent=claude branch=main log=20260120T213917Z-iter0024-claude.log
- [20260120T214243Z] iter 25 mode=prd status=CONTINUE checks=PASS story=S9 agent=claude branch=main log=20260120T214243Z-iter0025-claude.log
- [20260120T214718Z] iter 26 mode=prd status=CONTINUE checks=PASS story=S9 agent=claude branch=main log=20260120T214718Z-iter0026-claude.log
[2026-01-20T21:51:49.894771+00:00] BLOCKED task 9 (Add `checkDiskSpace()` to `scripts/migration/lib/disk.ts`) after 3 attempts: runner failed
- [20260120T215149Z] iter 27 mode=prd status=CONTINUE checks=PASS story=S10 agent=claude branch=main log=20260120T215149Z-iter0027-claude.log
- [20260120T215351Z] iter 28 mode=prd status=CONTINUE checks=PASS story=S10 agent=claude branch=main log=20260120T215351Z-iter0028-claude.log
- [20260120T215652Z] iter 29 mode=prd status=CONTINUE checks=PASS story=S10 agent=claude branch=main log=20260120T215652Z-iter0029-claude.log
[2026-01-20T22:01:23.452309+00:00] BLOCKED task 10 (Add `preFlightChecks()` to `scripts/migration/lib/check.ts`) after 3 attempts: runner failed
- [20260120T220123Z] iter 30 mode=prd status=CONTINUE checks=PASS story=S11 agent=claude branch=main log=20260120T220123Z-iter0030-claude.log
- [20260120T220425Z] iter 31 mode=prd status=CONTINUE checks=PASS story=S11 agent=claude branch=main log=20260120T220425Z-iter0031-claude.log
- [20260120T220717Z] iter 31 mode=prd status=CONTINUE checks=PASS story=S11 agent=claude branch=main log=20260120T220717Z-iter0031-claude.log
- [20260120T220758Z] iter 32 mode=prd status=CONTINUE checks=PASS story=S11 agent=claude branch=main log=20260120T220758Z-iter0032-claude.log
[2026-01-20T22:14:30.302333+00:00] BLOCKED task 11 (Create `scripts/migrate-to-author-first.mjs` CLI scaffold) after 3 attempts: unknown
- [20260120T221148Z] iter 32 mode=prd status=CONTINUE checks=PASS story=S11 agent=claude branch=main log=20260120T221148Z-iter0032-claude.log
[2026-01-20T22:14:47.135984+00:00] BLOCKED task 11 (Create `scripts/migrate-to-author-first.mjs` CLI scaffold) after 3 attempts: unknown
- [20260120T221430Z] iter 33 mode=prd status=CONTINUE checks=PASS story=S12 agent=claude branch=main log=20260120T221430Z-iter0033-claude.log
- [20260120T221447Z] iter 33 mode=prd status=CONTINUE checks=PASS story=S12 agent=claude branch=main log=20260120T221447Z-iter0033-claude.log
- [20260120T221731Z] iter 34 mode=prd status=CONTINUE checks=PASS story=S12 agent=claude branch=main log=20260120T221731Z-iter0034-claude.log
- [20260120T221748Z] iter 34 mode=prd status=CONTINUE checks=PASS story=S12 agent=claude branch=main log=20260120T221748Z-iter0034-claude.log
- [20260120T222202Z] iter 35 mode=prd status=CONTINUE checks=PASS story=S12 agent=claude branch=main log=20260120T222202Z-iter0035-claude.log
[2026-01-20T22:27:35.579304+00:00] BLOCKED task 12 (Add dry-run mode to `scripts/migrate-to-author-first.mjs`) after 3 attempts: unknown
- [20260120T222219Z] iter 35 mode=prd status=CONTINUE checks=PASS story=S12 agent=claude branch=main log=20260120T222219Z-iter0035-claude.log
[2026-01-20T22:28:57.557815+00:00] BLOCKED task 12 (Add dry-run mode to `scripts/migrate-to-author-first.mjs`) after 3 attempts: unknown
- [20260120T222735Z] iter 36 mode=prd status=CONTINUE checks=PASS story=S13 agent=claude branch=main log=20260120T222735Z-iter0036-claude.log
- [20260120T222857Z] iter 36 mode=prd status=CONTINUE checks=PASS story=S13 agent=claude branch=main log=20260120T222857Z-iter0036-claude.log
- [20260120T222936Z] iter 37 mode=prd status=CONTINUE checks=PASS story=S13 agent=claude branch=main log=20260120T222936Z-iter0037-claude.log
- [20260120T223058Z] iter 37 mode=prd status=CONTINUE checks=PASS story=S13 agent=claude branch=main log=20260120T223058Z-iter0037-claude.log
- [20260120T223237Z] iter 38 mode=prd status=CONTINUE checks=PASS story=S13 agent=claude branch=main log=20260120T223237Z-iter0038-claude.log
[2026-01-20T22:35:27.145888+00:00] BLOCKED task 13 (Add `moveFileWithTimeout()` to `scripts/migration/lib/files.ts`) after 3 attempts: unknown
- [20260120T223250Z] iter 38 mode=prd status=CONTINUE checks=PASS story=S13 agent=claude branch=main log=20260120T223250Z-iter0038-claude.log
[2026-01-20T22:36:30.023300+00:00] BLOCKED task 13 (Add `moveFileWithTimeout()` to `scripts/migration/lib/files.ts`) after 3 attempts: unknown
- [20260120T223527Z] iter 39 mode=prd status=CONTINUE checks=PASS story=S14 agent=claude branch=main log=20260120T223527Z-iter0039-claude.log
- [20260120T223630Z] iter 39 mode=prd status=CONTINUE checks=PASS story=S14 agent=claude branch=main log=20260120T223630Z-iter0039-claude.log
- [20260120T223728Z] iter 40 mode=prd status=CONTINUE checks=PASS story=S14 agent=claude branch=main log=20260120T223728Z-iter0040-claude.log
- [20260120T223830Z] iter 40 mode=prd status=CONTINUE checks=PASS story=S14 agent=claude branch=main log=20260120T223830Z-iter0040-claude.log
- [20260120T224029Z] iter 41 mode=prd status=CONTINUE checks=PASS story=S14 agent=claude branch=main log=20260120T224029Z-iter0041-claude.log
[2026-01-20T22:45:00.433454+00:00] BLOCKED task 14 (Add checkpoint system to `scripts/migration/lib/checkpoint.ts`) after 3 attempts: runner failed
- [20260120T224131Z] iter 41 mode=prd status=CONTINUE checks=PASS story=S14 agent=claude branch=main log=20260120T224131Z-iter0041-claude.log
[2026-01-20T22:46:03.012654+00:00] BLOCKED task 14 (Add checkpoint system to `scripts/migration/lib/checkpoint.ts`) after 3 attempts: runner failed
- [20260120T224500Z] iter 42 mode=prd status=CONTINUE checks=PASS story=S15 agent=claude branch=main log=20260120T224500Z-iter0042-claude.log
- [20260120T224603Z] iter 42 mode=prd status=CONTINUE checks=PASS story=S15 agent=claude branch=main log=20260120T224603Z-iter0042-claude.log
- [20260120T224702Z] iter 43 mode=prd status=CONTINUE checks=PASS story=S15 agent=claude branch=main log=20260120T224702Z-iter0043-claude.log
- [20260120T224804Z] iter 43 mode=prd status=CONTINUE checks=PASS story=S15 agent=claude branch=main log=20260120T224804Z-iter0043-claude.log
- [20260120T225003Z] iter 44 mode=prd status=CONTINUE checks=PASS story=S15 agent=claude branch=main log=20260120T225003Z-iter0044-claude.log
[2026-01-20T22:51:28.958949+00:00] BLOCKED task 15 (Add SIGINT handler to `scripts/migrate-to-author-first.mjs`) after 3 attempts: unknown
- [20260120T225105Z] iter 44 mode=prd status=CONTINUE checks=PASS story=S15 agent=claude branch=main log=20260120T225105Z-iter0044-claude.log
[2026-01-20T22:53:41.164379+00:00] BLOCKED task 15 (Add SIGINT handler to `scripts/migrate-to-author-first.mjs`) after 3 attempts: unknown
- [20260120T225129Z] iter 45 mode=prd status=CONTINUE checks=PASS story=S16 agent=claude branch=main log=20260120T225129Z-iter0045-claude.log
- [20260120T225341Z] iter 45 mode=prd status=CONTINUE checks=PASS story=S16 agent=claude branch=main log=20260120T225341Z-iter0045-claude.log
- [20260120T225537Z] iter 46 mode=prd status=CONTINUE checks=PASS story=S16 agent=claude branch=main log=20260120T225537Z-iter0046-claude.log
- [20260120T230008Z] iter 47 mode=prd status=CONTINUE checks=PASS story=S16 agent=claude branch=main log=20260120T230008Z-iter0047-claude.log
[2026-01-20T23:06:54.795412+00:00] BLOCKED task 16 (Add main migration logic to `scripts/migrate-to-author-first.mjs`) after 3 attempts: runner failed


## .ralph/FEEDBACK.md
# Feedback (optional)

This file is read by Ralph Gold each iteration.

Use it to add temporary guidance for the next iteration (constraints, clarifications, links, etc.).

Delete entries when no longer needed.


## .spec/spec-2025-01-19-smaug-feature-port.md
```yaml
schema_version: 1
spec_type: prd
spec_id: SPEC-2025-001
title: "Smaug â†’ xKit Performance & Cost Optimization Features"
status: finalized
created: "2025-01-19"
last_updated: "2025-01-19"
```

# PRD: Smaug â†’ xKit Performance & Cost Optimization Features

## Executive Summary

xKit v0.7.0 is a comprehensive Twitter bookmark archiving system with most core features implemented. However, it processes bookmarks **sequentially**, causing performance issues at scale. This PRD ports three high-value features from Smaug (a similar bookmark archiver) to address documented limitations in xKit:

1. **Token Usage Tracking** - Track and display LLM API costs with detailed breakdown
2. **Parallel Processing Architecture** - Process bookmarks concurrently using worker pools
3. **Model Cost Optimization** - Route tasks to appropriate model tiers (fast/balanced/quality)

**Business Impact:** Reduces archive processing time by 2-4x for 100+ bookmarks, provides cost transparency for cloud LLM usage, and optimizes LLM spend by ~30% through smart model routing.

**Evidence Source:** Smaug codebase analysis shows parallel subagent processing achieves 2-4x speedup with ~50% cost savings via Haiku model usage for simple tasks.

---

## Inputs

### Source Materials
- Smaug codebase analysis (parallel processing architecture)
- xKit v0.7.0 codebase review
- LIMITATIONS.md (lines 134-142 document sequential processing bottleneck)
- Existing xKit modules: `bookmark-analysis/`, `bookmark-stats/`, `commands/bookmarks-archive.ts`

### Constraints
- Must maintain xKit's privacy-first design (local-first, opt-in cloud)
- Must not introduce breaking changes to existing CLI interface
- Must work with existing LLM providers (Ollama, OpenAI, Anthropic)
- Must follow xKit's TypeScript/Node.js architecture

### Assumptions
1. Users primarily process 50-500 bookmarks per session
2. LLM API usage is primarily for categorization and summarization
3. Users want cost transparency before running expensive operations
4. Parallel processing speedup justifies added complexity
5. Model tier routing can maintain acceptable quality while reducing costs

---

## Outputs

### Deliverables
1. **Token tracking module** (`src/bookmark-analysis/token-tracker.ts`)
2. **Parallel processing engine** (`src/bookmark-analysis/parallel-processor.ts`)
3. **Model tier router** (`src/bookmark-analysis/model-router.ts`)
4. **Updated CLI commands** with new flags
5. **Updated documentation** with performance benchmarks

### Success Metrics

**Measurement Methodology:** All benchmarks run on M1 MacBook Pro (8GB RAM), macOS 14.0, stable 100Mbps network, n=10 trials per metric, results reported as mean Â± 95% confidence interval.

- [ ] Token tracking displays accurate API costs within Â±5% of actual billing (validated against API provider billing statements)
- [ ] Parallel processing achieves 2.5Â±0.5x speedup for 100 bookmarks (baseline: 180s sequential â†’ target: <72s parallel)
- [ ] Output ordering is guaranteed (processed bookmarks maintain input order, verified with deterministic test data)
- [ ] Memory usage stays within bounds (< 1.5GB peak for 1000 bookmarks, measured via Node.js `process.memoryUsage()`)
- [ ] Model optimization reduces costs by 28Â±3% for equivalent quality (measured via manual quality assessment on 100-bookmark sample)
- [ ] No increase in error rate vs sequential processing (target: <2% error rate for both modes)

---

## Problem Statement

### Current Pain Points

**As documented in LIMITATIONS.md:134-142:**
> "Archive command processes bookmarks sequentially, not in parallel. Large archives (1000+ bookmarks) can take hours with AI summarization. No resume capability if interrupted mid-run."

**User Impact:**
- **Performance:** Processing 500 bookmarks with AI summarization takes 2-3 hours
- **Cost Blindness:** Users have no visibility into LLM API costs before running
- **Inefficiency:** Expensive models (Sonnet, GPT-4) used for simple categorization tasks
- **Poor UX:** No progress indication during long-running operations

### Technical Debt
1. **Sequential Processing Loop** (`bookmarks-archive.ts:196`): `enrichBatch` processes bookmarks one-at-a-time
2. **No Token Tracking**: LLM clients (`llm-categorizer.ts`) don't track usage or costs
3. **Single Model Strategy**: All tasks use the same model regardless of complexity

---

## Solution Overview

### Three-Phase Implementation

```mermaid
gantt
    title Implementation Timeline
    dateFormat  YYYY-MM-DD
    section Phase 1
    Token Tracking           :p1, 2025-01-20, 2d
    section Phase 2
    Parallel Processing      :p2, after p1, 5d
    section Phase 3
    Model Optimization       :p3, after p2, 3d
```

### Phase 1: Token Usage Tracking (Priority 1)

**What:** Track and display LLM API costs with detailed breakdown

**How:**
- Create `TokenTracker` class to count tokens before/after each LLM call
- Calculate cost based on model pricing (OpenAI, Anthropic, Ollama=$0)
- Aggregate by operation type (categorization, summarization, analysis)
- Display usage report at end of archive run

**Example Output:**
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ“Š TOKEN USAGE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Anthropic (claude-3-haiku-20240307):
  Input:            12,345 tokens  $0.012
  Output:            3,456 tokens  $0.017
  Cache Read:       10,000 tokens  $0.000
  Cache Write:       2,000 tokens  $0.000

OpenAI (gpt-4o):
  Input:            25,000 tokens  $0.250
  Output:            5,000 tokens  $0.150

Ollama (llama3.2):
  Input:           100,000 tokens  $0.000 (local)
  Output:           20,000 tokens  $0.000 (local)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ’° TOTAL ESTIMATED COST: $0.429
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Phase 2: Parallel Processing Architecture (Priority 2)

**What:** Process bookmarks concurrently using worker thread pools

**How:**
- Create `ParallelProcessor` class with configurable worker pool
- Use Node.js `worker_threads` for CPU-bound LLM tasks
- Use async batching for I/O-bound HTTP requests
- Preserve ordering with sequence IDs for reassembly
- Add `--parallel` flag to archive command (default: off)

**Configuration:**
```typescript
interface ParallelConfig {
  enabled: boolean;
  concurrency: number;      // Default: 4-8 workers
  threshold: number;        // Minimum bookmarks to enable (default: 50)
  batchSize: number;        // Items per worker batch (default: 10)
}
```

**Architecture:**
```mermaid
flowchart TD
    A[Input Bookmarks] --> B{Parallel Enabled?}
    B -->|No| C[Sequential Processing]
    B -->|Yes| D[Worker Pool]
    D --> E1[Worker 1]
    D --> E2[Worker 2]
    D --> E3[Worker N]
    E1 --> F[Result Queue]
    E2 --> F
    E3 --> F
    F --> G[Ordering Guarantee]
    G --> H[Output Bookmarks]
    C --> H
```

### Phase 3: Model Cost Optimization (Priority 3)

**What:** Route tasks to appropriate model tiers based on complexity

**How:**
- Define model tiers (fast/balanced/quality) with cost/quality tradeoffs
- Route categorization â†’ fast model (Haiku/GPT-4o-mini)
- Route summarization â†’ balanced model (Sonnet/GPT-4o)
- Route complex analysis â†’ quality model (Opus/GPT-4)
- Add fallback mechanism if premium model fails

**Model Tier Configuration:**
```typescript
interface ModelTier {
  name: 'fast' | 'balanced' | 'quality';
  model: string;
  maxTokens: number;
  costPerMillion: { input: number; output: number };
  useCase: string[];
}

interface ModelStrategy {
  categorization: 'fast';
  summarization: 'balanced';
  analysis: 'quality';
}
```

**Cost Comparison:**
| Operation | Current (Sonnet) | Optimized (Haiku) | Savings |
|-----------|-----------------|-------------------|---------|
| Categorization | $0.25 | $0.012 | ~95% |
| Summarization | $0.25 | $0.25 | 0% |
| Analysis | $0.25 | $0.25 | 0% |
| **Total** | $0.75 | $0.512 | ~30% |

---

## User Personas

### Persona 1: Alex, Research Analyst
**Role:** Senior researcher at tech think tank
**Goals:**
- Archive 500+ bookmarks monthly for literature review
- Minimize processing time to meet publication deadlines
- Control costs within monthly research budget ($200)

**Pain Points:**
- Current archiving takes 3+ hours for large batches
- No visibility into LLM costs before running
- Manual categorization is time-consuming

**Technical Proficiency:** High (comfortable with CLI, config files)

**Typical Volume:** 200-1000 bookmarks per session

---

### Persona 2: Jordan, Casual User
**Role:** Software developer bookmarking for later reference
**Goals:**
- Quick archival of 20-50 bookmarks weekly
- Minimal setup and configuration
- Avoid unexpected API charges

**Pain Points:**
- Long-running operations block workflow
- Confused by parallel processing terminology
- Worried about accidentally running up large bills

**Technical Proficiency:** Medium (can follow docs, prefers defaults)

**Typical Volume:** 20-100 bookmarks per session

---

### Persona 3: Sam, Power User
**Role:** Data scientist building personal knowledge base
**Goals:**
- Archive 2000+ bookmarks across multiple sessions
- Fine-grained control over processing parameters
- Detailed cost and performance analytics

**Pain Points:**
- Sequential processing doesn't scale to thousands of bookmarks
- Can't tune worker pool for hardware (32GB RAM, 12 cores)
- Wants to optimize model selection per task type

**Technical Proficiency:** Expert (contributes to open source, reads source code)

**Typical Volume:** 500-5000 bookmarks per session

---

### Persona 4: Casey, Budget-Conscious Student
**Role:** Graduate student on limited budget
**Goals:**
- Use free/local LLM (Ollama) exclusively
- Occasional cloud LLM for complex analysis only
- Zero unexpected costs

**Pain Points:**
- Worried about accidentally using paid API
- Needs clear cost warnings before expensive operations
- Wants cheapest options that still work well

**Technical Proficiency:** Low-Medium (can run commands, but not debug)

**Typical Volume:** 50-200 bookmarks per session

---

## User Stories

### STORY-001: Token Usage Visibility
**As a** power user who processes hundreds of bookmarks
**I want** to see estimated LLM API costs before and after archiving
**So that** I can budget for cloud LLM usage and avoid surprise charges

**Acceptance Criteria:**
- [ ] Token counts displayed after each LLM operation
- [ ] Cost estimate shown before processing begins (based on sample)
- [ ] Detailed breakdown by model and operation type
- [ ] Ollama/local LLM shows $0.00 cost
- [ ] Currency formatted to 3 decimal places
- [ ] Cache read/write tokens tracked separately (Anthropic)

### STORY-002: Parallel Processing Speedup
**As a** user with 500+ bookmarks to archive
**I want** to process bookmarks in parallel
**So that** archiving completes in minutes instead of hours

**Acceptance Criteria:**
- [ ] `--parallel` flag enables parallel processing
- [ ] Parallel mode only activates above threshold (default: 50 bookmarks)
- [ ] Progress bar shows concurrent worker activity
- [ ] Output maintains original bookmark order
- [ ] Error in one worker doesn't crash entire batch
- [ ] Memory usage stays below 2GB for 1000 bookmarks

### STORY-003: Configurable Concurrency
**As a** user with limited RAM or API rate limits
**I want** to control worker pool size
**So that** I can tune performance for my hardware and API constraints

**Acceptance Criteria:**
- [ ] `--parallel-workers <n>` flag sets concurrency (default: 4)
- [ ] `--parallel-threshold <n>` flag sets minimum bookmarks (default: 50)
- [ ] Config validated (min: 1, max: 16 workers)
- [ ] Warning shown if worker count exceeds CPU cores
- [ ] Rate limiting respected across all workers

### STORY-004: Smart Model Routing
**As a** cost-conscious user
**I want** simple categorization tasks to use cheaper models
**So that** I can reduce LLM costs without sacrificing quality

**Acceptance Criteria:**
- [ ] Categorization uses fast model by default
- [ ] Summarization uses balanced model by default
- [ ] User can override model tier per operation
- [ ] Fallback to balanced model if fast model fails
- [ ] Quality degradation logged when fallback occurs

### STORY-005: Cost Comparison Report
**As a** developer optimizing archiving workflows
**I want** to compare costs between different model strategies
**So that** I can make informed tradeoffs between cost and quality

**Acceptance Criteria:**
- [ ] `--cost-report` flag generates before/after comparison
- [ ] Shows projected cost for each model tier strategy
- [ ] Estimates quality impact (low/medium/high)
- [ ] Saves report to JSON for analysis
- [ ] Historical cost tracking across multiple runs

---

## Scope

### In Scope
- Token usage tracking for all LLM providers (OpenAI, Anthropic, Ollama)
- Parallel processing for bookmark enrichment and categorization
- Model tier routing for categorization and summarization
- CLI flag extensions to existing commands
- Progress reporting for parallel operations
- Error handling and graceful degradation

### Out of Scope
- Parallel processing for Twitter API calls (existing rate limiting sufficient)
- Resume/checkpoint functionality (separate feature, Phase 4)
- New LLM provider integrations beyond existing three
- GPU acceleration for local LLMs
- Distributed processing across multiple machines
- Real-time cost monitoring during processing (only before/after)
- Automatic model selection based on content complexity (manual tier assignment only)

### Feature Creep Guardrails

**Decision Record:**
1. **No GPU acceleration** - Requires significant infrastructure, out of scope for performance optimization
2. **No distributed processing** - Adds operational complexity, local parallel processing sufficient
3. **No automatic model selection** - Would require content analysis overhead, manual tier routing more predictable
4. **No real-time cost tracking** - Would require streaming responses, adds latency

**Scope Decision Log:**
| Date | Decision | Rationale | Who |
|------|----------|-----------|-----|
| 2025-01-19 | Exclude resume/checkpoint | Separate feature, adds state management complexity | Product |
| 2025-01-19 | Exclude new LLM providers | Existing three sufficient for optimization | Engineering |

---

## Technical Architecture

### Component Architecture

```mermaid
flowchart TB
    subgraph "Existing xKit"
        A[Archive Command]
        B[Enricher]
        C[LLM Categorizer]
        D[Stats Tracker]
    end

    subgraph "New: Phase 1"
        E[Token Tracker]
    end

    subgraph "New: Phase 2"
        F[Parallel Processor]
        G[Worker Pool]
    end

    subgraph "New: Phase 3"
        H[Model Router]
        I[Model Tier Config]
    end

    A --> B
    A --> C
    A --> D
    B --> E
    C --> E
    F --> G
    F --> B
    F --> C
    H --> C
    I --> H
```

### Data Models

**Token Tracking:**
```typescript
interface TokenUsage {
  input: number;
  output: number;
  cacheRead: number;
  cacheWrite: number;
  cost: number;
}

interface UsageReport {
  byModel: Record<string, TokenUsage>;
  byOperation: Record<string, TokenUsage>;
  total: TokenUsage;
}

interface TokenTracker {
  record(operation: string, model: string, usage: TokenUsage): void;
  getReport(): UsageReport;
  formatReport(): string;
}
```

**Parallel Processing:**
```typescript
interface ParallelConfig {
  enabled: boolean;
  concurrency: number;
  threshold: number;
  batchSize: number;
}

interface WorkItem {
  id: string;
  sequence: number;
  bookmark: BookmarkRecord;
}

interface WorkResult {
  id: string;
  sequence: number;
  result: EnrichedBookmarkRecord;
  error?: Error;
}

interface ParallelProcessor {
  process(items: WorkItem[]): Promise<WorkResult[]>;
}
```

**Model Routing:**
```typescript
interface ModelTier {
  name: 'fast' | 'balanced' | 'quality';
  model: string;
  maxTokens: number;
  costPerMillion: { input: number; output: number };
  useCase: string[];
}

interface ModelStrategy {
  categorization: 'fast' | 'balanced' | 'quality';
  summarization: 'fast' | 'balanced' | 'quality';
  analysis: 'fast' | 'balanced' | 'quality';
}

interface ModelRouter {
  route(operation: string): string;
  withFallback(operation: string, tiers: string[]): Promise<string>;
}
```

### API Design

**New CLI Flags:**
```bash
# Token tracking (always active with LLM)
xkit archive --summarize

# Parallel processing
xkit archive --all --parallel
xkit archive --all --parallel --parallel-workers 8
xkit archive --all --parallel --parallel-threshold 100

# Model optimization
xkit archive --model-strategy balanced
xkit archive --model-tier fast:summarization

# Cost comparison
xkit archive --cost-report
```

**Configuration File:**
```json
{
  "llm": {
    "strategy": "optimized",
    "tiers": {
      "fast": {
        "categorization": "claude-3-haiku-20240307",
        "summarization": "gpt-4o-mini"
      },
      "balanced": {
        "categorization": "claude-3-5-sonnet-20241022",
        "summarization": "gpt-4o"
      },
      "quality": {
        "categorization": "claude-3-opus-20240229",
        "summarization": "gpt-4-turbo"
      }
    }
  },
  "parallel": {
    "enabled": false,
    "workers": 4,
    "threshold": 50
  }
}
```

---

## Internal API Contracts

### TokenTracker Module

**Interface Definition:**
```typescript
/**
 * TokenTracker - Tracks LLM API usage and costs
 *
 * @example
 * const tracker = new TokenTracker();
 * tracker.record('categorization', 'claude-3-haiku-20240307', {
 *   input: 1000,
 *   output: 200,
 *   cacheRead: 0,
 *   cacheWrite: 0,
 *   cost: 0.0025
 * });
 */
export class TokenTracker {
  /**
   * Record token usage for an LLM operation
   * @param operation - Operation type (categorization, summarization, analysis)
   * @param model - Model identifier (e.g., 'claude-3-haiku-20240307')
   * @param usage - Token counts and cost
   * @throws {Error} if usage counts are negative
   */
  record(operation: string, model: string, usage: TokenUsage): void;

  /**
   * Get aggregated usage report
   * @returns Usage report broken down by model and operation
   */
  getReport(): UsageReport;

  /**
   * Format usage report as human-readable string
   * @returns Formatted string suitable for terminal output
   */
  formatReport(): string;

  /**
   * Reset all tracking data (useful for testing)
   */
  reset(): void;
}
```

### ParallelProcessor Module

**Interface Definition:**
```typescript
/**
 * ParallelProcessor - Processes bookmarks concurrently using worker pool
 *
 * @example
 * const processor = new ParallelProcessor({ concurrency: 4, threshold: 50 });
 * const results = await processor.process(workItems);
 */
export class ParallelProcessor {
  /**
   * Create a new parallel processor
   * @param config - Configuration options
   * @throws {RangeError} if concurrency < 1 or > 16
   * @throws {RangeError} if threshold < 1
   */
  constructor(config: ParallelConfig);

  /**
   * Process work items concurrently
   * @param items - Array of work items with sequence IDs
   * @returns Promise resolving to results in original order
   * @throws {Error} if worker pool fails to initialize
   */
  process(items: WorkItem[]): Promise<WorkResult[]>;

  /**
   * Get current worker pool statistics
   * @returns Statistics including active workers, queue size, processed count
   */
  getStats(): WorkerPoolStats;

  /**
   * Abort all in-progress work
   * @throws {Error} if abort fails
   */
  abort(): Promise<void>;
}
```

### ModelRouter Module

**Interface Definition:**
```typescript
/**
 * ModelRouter - Routes tasks to appropriate model tiers
 *
 * @example
 * const router = new ModelRouter(strategy);
 * const model = router.route('categorization'); // Returns 'claude-3-haiku-20240307'
 */
export class ModelRouter {
  /**
   * Create a new model router
   * @param strategy - Model tier strategy mapping
   * @throws {Error} if strategy references undefined models
   */
  constructor(strategy: ModelStrategy);

  /**
   * Get the appropriate model for an operation
   * @param operation - Operation type (categorization, summarization, analysis)
   * @returns Model identifier string
   * @throws {Error} if operation type not recognized
   */
  route(operation: string): string;

  /**
   * Get model with fallback chain
   * @param operation - Operation type
   * @param tiers - Ordered list of tier names to try
   * @returns Model identifier that succeeded
   * @throws {Error} if all tiers fail
   */
  async withFallback(operation: string, tiers: string[]): Promise<string>;

  /**
   * Update model strategy
   * @param strategy - New strategy configuration
   */
  configure(strategy: ModelStrategy): void;
}
```

---

## Error Codes and Handling

### Error Code Constants

```typescript
/**
 * Error codes for xKit parallel processing and token tracking
 */
export const ErrorCodes = {
  // Token Tracker Errors (TOKEN_XXX)
  TOKEN_INVALID_COUNT: 'TOKEN_001',
  TOKEN_NEGATIVE_COUNT: 'TOKEN_002',
  TOKEN_MISSING_MODEL: 'TOKEN_003',

  // Parallel Processor Errors (PARALLEL_XXX)
  PARALLEL_WORKER_EXHAUSTION: 'PARALLEL_001',
  PARALLEL_INIT_FAILED: 'PARALLEL_002',
  PARALLEL_ABORT_FAILED: 'PARALLEL_003',
  PARALLEL_SEQUENCE_MISMATCH: 'PARALLEL_004',

  // Model Router Errors (MODEL_XXX)
  MODEL_UNKNOWN_OPERATION: 'MODEL_001',
  MODEL_ALL_TIERS_FAILED: 'MODEL_002',
  MODEL_FALLBACK_TRIGGERED: 'MODEL_003',
  MODEL_CONFIG_INVALID: 'MODEL_004',

  // Configuration Errors (CONFIG_XXX)
  CONFIG_INVALID_WORKERS: 'CONFIG_001',
  CONFIG_INVALID_THRESHOLD: 'CONFIG_002',
  CONFIG_MISSING_API_KEY: 'CONFIG_003',
} as const;
```

### Error Messages and User Actions

| Error Code | Message | User Action |
|------------|---------|-------------|
| TOKEN_001 | Invalid token count received from API | Check network connection, retry |
| TOKEN_002 | Negative token count detected | Report bug on GitHub |
| PARALLEL_001 | Worker pool exhausted | Reduce `--parallel-workers` or wait for completion |
| PARALLEL_002 | Failed to initialize worker pool | Check available memory, reduce worker count |
| MODEL_002 | All model tiers failed | Check API keys, network connection |
| MODEL_003 | Model fallback triggered (warning) | Check logs for quality degradation |
| CONFIG_001 | Worker count must be 1-16 | Use valid value for `--parallel-workers` |

---

## Concurrency Control

### Worker Pool Lifecycle

```mermaid
stateDiagram-v2
    [*] --> IDLE: Processor created
    IDLE --> INITIALIZING: process() called
    INITIALIZING --> READY: Workers spawned
    INITIALIZING --> ERROR: Spawn failed
    READY --> PROCESSING: Work items queued
    PROCESSING --> PROCESSING: Workers active
    PROCESSING --> DRAINING: Queue empty, workers finishing
    DRAINING --> READY: All workers complete
    READY --> IDLE: No more work
    PROCESSING --> ERROR: Worker crashed
    ERROR --> IDLE: Error handled, workers terminated
    IDLE --> [*]: Processor destroyed
```

### Thread Safety Guarantees

**Shared State Protection:**
- Token tracker uses atomic counters for thread-safe updates
- Result queue uses mutex for ordered insertion
- Worker pool state protected by mutex

**Data Integrity:**
- Each bookmark processed exactly once (work item idempotency)
- Sequence IDs unique and monotonic (assigned at queue time)
- No duplicate entries in output (result set deduplication)

### Memory Limits

**Boundaries:**
- Worker queue: Max 1000 items (backpressure beyond this)
- Result buffer: Max 1000 items (blocks if full)
- Token history: Max 10,000 entries (LRU eviction)

**Overflow Behavior:**
- Queue full: Block producer until space available
- Result buffer full: Block worker until space available
- Token history full: Evict oldest entry

---

## Retry Strategy and Circuit Breaker

### Retry Configuration

```typescript
interface RetryConfig {
  maxAttempts: number;        // Default: 3
  initialDelayMs: number;     // Default: 1000
  maxDelayMs: number;         // Default: 10000
  backoffMultiplier: number;  // Default: 2.0
  retryableErrors: string[];  // Error codes to retry
}

const defaultRetryConfig: RetryConfig = {
  maxAttempts: 3,
  initialDelayMs: 1000,
  maxDelayMs: 10000,
  backoffMultiplier: 2.0,
  retryableErrors: [
    'ECONNRESET',
    'ETIMEDOUT',
    'ESOCKETTIMEDOUT',
    'HTTP_429',  // Rate limit
    'HTTP_500',  // Server error
    'HTTP_502',  // Bad gateway
    'HTTP_503',  // Service unavailable
    'HTTP_504',  // Gateway timeout
  ],
};
```

### Circuit Breaker Pattern

```typescript
interface CircuitBreakerConfig {
  failureThreshold: number;   // Open circuit after N failures
  successThreshold: number;   // Close circuit after N successes
  timeoutMs: number;          // Time before attempting reset
  halfOpenMaxCalls: number;   // Max calls in half-open state
}

const defaultCircuitBreakerConfig: CircuitBreakerConfig = {
  failureThreshold: 5,        // Open after 5 consecutive failures
  successThreshold: 2,        // Close after 2 consecutive successes
  timeoutMs: 60000,           // Try reset after 60 seconds
  halfOpenMaxCalls: 3,        // Allow 3 test calls in half-open
};
```

**Circuit Breaker States:**
```mermaid
stateDiagram-v2
    [*] --> CLOSED: Initial state
    CLOSED --> OPEN: Failure threshold reached
    OPEN --> HALF_OPEN: Timeout elapsed
    HALF_OPEN --> CLOSED: Success threshold reached
    HALF_OPEN --> OPEN: Failure occurred
    HALF_OPEN --> CLOSED: Max calls reached (all successful)
```

---

## SLOs and Error Budget Policy

### Service Level Objectives

**Parallel Processing:**
- **Success Rate:** â‰¥98% (target: 99%, minimum: 98%)
- **Latency:** P95 < 90s for 100 bookmarks (vs 225s sequential)
- **Memory:** Peak < 1.5GB for 1000 bookmarks
- **Error Budget:** 2% of requests allowed to fail

**Token Tracking:**
- **Accuracy:** Â±5% of actual API billing
- **Availability:** 100% (local only, no remote deps)
- **Latency:** < 100ms per report generation

**Model Routing:**
- **Fallback Rate:** < 5% of requests trigger fallback
- **Fallback Latency:** < 5s additional when fallback triggers

### Error Budget Policy

**Calculation:**
- Error budget = 100% - success rate target = 100% - 98% = 2%
- Budget period: Weekly (rolling 7-day window)
- Budget reset: Weekly

**Burn Rate Triggers:**
- **Warning:** Error rate > 1.5% for 1 hour
- **Critical:** Error rate > 2% for 15 minutes
- **Emergency:** Error rate > 5% for 5 minutes

**Actions on Burn:**
- **Warning:** Alert engineering team, investigate
- **Critical:** Halt rollout, revert to sequential processing
- **Emergency:** Disable feature entirely, incident postmortem

---

## Input Validation

### Parameter Bounds

| Parameter | Min | Max | Default | Validation |
|-----------|-----|-----|---------|------------|
| `--parallel-workers` | 1 | 16 | 4 | Must be integer, â‰¤ CPU cores warning |
| `--parallel-threshold` | 1 | 10000 | 50 | Must be positive integer |
| `--batch-size` | 1 | 100 | 10 | Must be positive integer |
| `--max-retries` | 0 | 10 | 3 | Must be non-negative integer |
| Model tier name | - | - | - | Must be defined in config |

### Sanitization

**User Inputs:**
- Worker count: Parse as integer, validate bounds
- Threshold: Parse as integer, validate bounds
- Model names: Whitelist against defined tiers
- API keys: Validate format, never log or display

**Injection Prevention:**
- Model tier config: JSON schema validation
- File paths: Resolve to absolute, validate within workspace
- URLs: Validate against allowed domains

---

## Secrets Handling Policy

**Never Log or Display:**
- API keys (any LLM provider)
- Request/response bodies (may contain sensitive content)
- User cookie tokens
- File paths containing user info

**May Log:**
- Token counts (input/output only)
- Cost calculations (aggregates only)
- Model names (provider-specified identifiers)
- Operation types (categorization, summarization, etc.)

**Redaction Rules:**
- Replace API keys with `[REDACTED]`
- Replace request bodies with `[BODY OMITTED]`
- Replace file paths with `[PATH]` or user home only

---

## Cost Calculations (Updated)

**Pricing as of 2025-01-19:**

| Provider | Model | Input (per 1M) | Output (per 1M) | Cache Read (per 1M) |
|----------|-------|---------------|----------------|-------------------|
| Anthropic | claude-3-haiku-20240307 | $0.25 | $1.25 | $0.03 |
| Anthropic | claude-3-5-sonnet-20241022 | $3.00 | $15.00 | $0.30 |
| Anthropic | claude-3-opus-20240229 | $15.00 | $75.00 | $1.50 |
| OpenAI | gpt-4o-mini | $0.15 | $0.60 | N/A |
| OpenAI | gpt-4o | $2.50 | $10.00 | N/A |
| OpenAI | gpt-4-turbo | $10.00 | $30.00 | N/A |
| Ollama | Any | $0.00 | $0.00 | N/A |

**Cost Calculation Example (500 bookmarks):**

**Before Optimization (all Sonnet):**
- Categorization: 500 Ã— 250 input tokens Ã— 50 output tokens
  - Input: 125,000 tokens = $0.375
  - Output: 25,000 tokens = $0.375
- Summarization: 500 Ã— 500 input tokens Ã— 200 output tokens
  - Input: 250,000 tokens = $0.75
  - Output: 100,000 tokens = $1.50
- **Total: $3.00**

**After Optimization (Haiku categorization, Sonnet summarization):**
- Categorization: 500 Ã— 250 Ã— 50 (Haiku)
  - Input: 125,000 tokens = $0.031
  - Output: 25,000 tokens = $0.031
- Summarization: 500 Ã— 500 Ã— 200 (Sonnet)
  - Input: 250,000 tokens = $0.75
  - Output: 100,000 tokens = $1.50
- **Total: $2.312 (23% savings)**

---

## Go/No-Go Decision Framework

### Phase 2 (Parallel Processing) Go/No-Go

| Metric | Threshold | Owner | Decision |
|--------|-----------|-------|----------|
| Speedup | â‰¥2x for 100 bookmarks | Engineering | [ ] Go [ ] No-Go |
| Error Rate | <5% increase vs sequential | QA | [ ] Go [ ] No-Go |
| Memory | <2GB for 1000 bookmarks | Engineering | [ ] Go [ ] No-Go |
| Test Coverage | >80% for new modules | QA | [ ] Go [ ] No-Go |
| Documentation | Complete with examples | Tech Writing | [ ] Go [ ] No-Go |

**Decision Date:** 2025-01-27 (after Phase 2 completion)
**Decision Owner:** Product Lead
**Fallback:** Revert to sequential processing, extend timeline by 1 sprint

### Phase 3 (Model Optimization) Go/No-Go

| Metric | Threshold | Owner | Decision |
|--------|-----------|-------|----------|
| Cost Savings | â‰¥25% vs baseline | Product | [ ] Go [ ] No-Go |
| Quality Degradation | <15% user reports | Product | [ ] Go [ ] No-Go |
| Fallback Rate | <10% of requests | Engineering | [ ] Go [ ] No-Go |
| Cost Accuracy | Â±10% of estimates | Engineering | [ ] Go [ ] No-Go |

**Decision Date:** 2025-01-30 (after Phase 3 completion)
**Decision Owner:** Product Lead
**Fallback:** Disable model routing, use single model strategy

---

## Terminal UX Design

### Progress Bar (Parallel Processing)

**Design:**
```
Processing 500 bookmarks with 4 workers...
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 75% (375/500) | Workers: â–ˆâ–ˆâ–ˆâ–ˆ | ETA: 45s
  Worker 1: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] Complete (125/125)
  Worker 2: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] Processing (94/125)
  Worker 3: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] Processing (94/125)
  Worker 4: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] Processing (62/125)
```

**States:**
- **Sequential:** Single progress bar
- **Parallel:** Main bar + per-worker breakdown
- **Complete:** All bars at 100%, checkmarks

### Empty States

**No Bookmarks:**
```
No bookmarks to process.

ðŸ’¡ Tip: Use `xkit bookmarks list` to see available bookmarks,
or `xkit bookmarks fetch` to retrieve new ones.
```

**Parallel Below Threshold:**
```
âš ï¸  Parallel mode enabled but only 12 bookmarks (threshold: 50).

Processing sequentially. Use `--parallel-threshold 10` to force parallel.
```

**Zero Cost (Local LLM):**
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ“Š TOKEN USAGE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Ollama (llama3.2):
  Input:          125,000 tokens  $0.00 (local LLM)
  Output:          25,000 tokens  $0.00 (local LLM)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ’° TOTAL ESTIMATED COST: $0.00 (local LLM, no API charges)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Competitive Analysis

### Feature Comparison

| Feature | xKit (After) | Raindrop.io | Pocket | Pinboard | Smaug |
|---------|--------------|-------------|--------|----------|-------|
| Twitter Native | âœ… | âŒ | âŒ | âŒ | âœ… |
| Local-First | âœ… | âŒ | âŒ | âŒ | âœ… |
| Parallel Processing | âœ… | âœ… | âœ… | âŒ | âœ… |
| Token Tracking | âœ… | âŒ | âŒ | âŒ | âœ… |
| Model Optimization | âœ… | âŒ | âŒ | âŒ | âœ… |
| Free Local LLM | âœ… | âŒ | âŒ | âŒ | âŒ |
| Self-Hostable | âœ… | âŒ | âŒ | âŒ | âŒ |

**Differentiation:**
- Only self-hostable, local-first Twitter bookmark archiver
- Only one with token tracking and model optimization
- Only one supporting both local and cloud LLMs

---

## Risks and Mitigations

### Technical Risks

| Risk | Impact | Probability | Mitigation | Owner |
|------|--------|-------------|------------|-------|
| Worker thread overhead increases memory | Medium | Medium | Only enable above threshold; limit max workers; add memory monitoring | Engineering |
| Output ordering broken in parallel mode | High | Low | Use sequence IDs; deterministic reassembly; comprehensive ordering tests | Engineering |
| Rate limit exceeded with concurrent requests | Medium | Medium | Implement exponential backoff; queue management; per-worker rate limits | Engineering |
| Token counting inaccurate | Medium | Low | Cross-check with API billing; log discrepancies; use official tokenizers | Engineering |
| Model fallback degrades quality | Medium | Low | Log all fallbacks; user opt-in; quality comparison report | Product |

### Product Risks

| Risk | Impact | Probability | Mitigation | Owner |
|------|--------|-------------|------------|-------|
| Users don't trust cost estimates | Medium | Low | Show disclaimer; actual costs may vary; link to billing | Product |
| Parallel processing too complex for average user | Low | Medium | Sensible defaults; feature flag off by default; clear docs | Product |
| Model tier routing reduces quality perception | Medium | Low | Quality report; user control; opt-in for optimization | Product |

### Operational Risks

| Risk | Impact | Probability | Mitigation | Owner |
|------|--------|-------------|------------|-------|
| Increased support burden | Low | Low | Comprehensive docs; FAQ; example configs | Support |
| CI/CD pipeline slowdown | Low | Low | Skip parallel mode in tests; mock LLM calls | Engineering |

---

## Acceptance Criteria

### Top-Level

- [ ] All three phases implemented and tested
- [ ] No breaking changes to existing CLI interface
- [ ] Documentation updated with new flags and examples
- [ ] Performance benchmarks show 2-4x speedup for 100+ bookmarks
- [ ] Token tracking accurate within 5% of actual API costs
- [ ] Memory usage < 2GB for 1000 bookmarks in parallel mode
- [ ] All existing tests pass
- [ ] New test coverage > 80% for new modules

### Phase-Specific

**Phase 1: Token Tracking**
- [ ] TokenTracker class implemented with `record`, `getReport`, `formatReport`
- [ ] Integrated into LLMCategorizer and OllamaClient
- [ ] Usage report displayed after archive command
- [ ] Support for cache read/write tokens (Anthropic)
- [ ] Cost calculations validated against actual API billing

**Phase 2: Parallel Processing**
- [ ] ParallelProcessor class with worker pool
- [ ] `--parallel` flag added to archive command
- [ ] `--parallel-workers` and `--parallel-threshold` flags
- [ ] Ordering guarantee with sequence IDs
- [ ] Error isolation (one worker failure doesn't crash batch)
- [ ] Progress reporting for concurrent operations

**Phase 3: Model Optimization**
- [ ] ModelRouter class with tier configuration
- [ ] Default strategy: fast=categorization, balanced=summarization
- [ ] `--model-strategy` and `--model-tier` flags
- [ ] Fallback mechanism with logging
- [ ] Cost comparison report with `--cost-report`

---

## Data Lifecycle & Retention

### Token Usage Data
- **Storage:** In-memory only during processing
- **Persistence:** Optional JSON export via `--save-token-report`
- **Retention:** Not retained by default (privacy-first)
- **Deletion:** Automatic on process exit

### Processing State
- **Storage:** Existing StateManager for processed bookmark IDs
- **Persistence:** JSON file in `~/.xkit/state.json`
- **Retention:** Indefinite (user can delete)
- **Deletion:** `xkit state --clear` command

### Configuration
- **Storage:** Optional JSON file in project root or `~/.xkit/config.json`
- **Persistence:** User-controlled
- **Retention:** Indefinite
- **Deletion:** Manual file deletion

---

## Post-Launch Monitoring Plan

### Metrics to Track

**Performance Metrics:**
- Average processing time per bookmark (sequential vs parallel)
- Memory usage during parallel processing
- Worker utilization rate
- Error rate by operation type

**Cost Metrics:**
- Actual vs estimated token costs
- Cost savings by model tier
- Cache hit rate (Anthropic)

**Quality Metrics:**
- Model fallback frequency
- User-reported quality issues
- Categorization accuracy (optional user feedback)

### Monitoring Windows
- **Week 1-2:** Daily monitoring of all metrics
- **Week 3-4:** Weekly monitoring
- **Month 2+:** Monthly review

### Owners
- **Performance:** Engineering Lead
- **Cost:** Product Lead
- **Quality:** Product Lead

---

## Launch & Rollout Guardrails

### Phased Rollout

**Phase 1 (Token Tracking):**
- **Feature:** Always active with LLM usage
- **Risk:** Low (observability only)
- **Rollout:** Immediate release to all users
- **Go/No-Go Metrics:** No regressions in existing functionality

**Phase 2 (Parallel Processing):**
- **Feature:** Opt-in via `--parallel` flag
- **Risk:** Medium (new execution model)
- **Rollout:**
  - Week 1: Beta testers only
  - Week 2: Early adopters via documentation
  - Week 3: General availability (flag still off by default)
  - Week 4: Consider default-on based on evidence
- **Go/No-Go Metrics:**
  - < 5% error rate in parallel mode
  - > 2x speedup for 100+ bookmarks
  - No memory leaks or crashes

**Phase 3 (Model Optimization):**
- **Feature:** Opt-in via `--model-strategy` flag
- **Risk:** Low (user-controlled)
- **Rollout:** Same as Phase 2
- **Go/No-Go Metrics:**
  - > 25% cost savings
  - < 10% quality degradation reports

### Rollback Plan

**Phase 1:** No rollback needed (observability only)

**Phase 2:**
- Revert to sequential processing: `--parallel=false`
- Hotfix release to disable feature flag
- Communication via GitHub Issues and README

**Phase 3:**
- Revert to single model: `--model-strategy legacy`
- Hotfix release to disable tier routing
- Communication via GitHub Issues and README

### Kill Criteria

Kill feature development if:
- Parallel processing shows < 1.5x speedup after optimization
- Memory usage exceeds 4GB for 1000 bookmarks
- Error rate in parallel mode > 10%
- User quality degradation reports > 20% for model optimization

---

## Support & Ops Impact

### Documentation Requirements

**User Documentation:**
- Token tracking explanation in README
- Parallel processing guide with benchmarks
- Model tier configuration reference
- Cost comparison examples

**Developer Documentation:**
- Architecture decision records (ADRs)
- Code comments for worker pool logic
- Token counting implementation notes

### Runbook Updates

**New Troubleshooting Sections:**
- "Parallel processing slower than sequential"
- "Token counts don't match API billing"
- "Model fallback occurring frequently"
- "Memory usage too high in parallel mode"

### Training

**Support Team:**
- 1-hour training on new features
- FAQ document for common issues
- Escalation path for complex issues

---

## Compliance & Regulatory Review Triggers

### Data Privacy
- **Trigger:** Token tracking processes user content
- **Review:** Ensure no sensitive content logged or transmitted
- **Mitigation:** Only token counts and costs tracked, not content

### Cost Transparency
- **Trigger:** Estimated costs shown to users
- **Review:** Ensure disclaimer that estimates may vary
- **Mitigation:** Clear messaging: "Estimated cost, actual may vary"

---

## Ownership & RACI

| Role | Name | Responsibilities |
|------|------|------------------|
| **Product Owner** | TBD | Requirements, prioritization, go/no-go decisions |
| **Engineering Lead** | TBD | Architecture, implementation, code review |
| **QA Lead** | TBD | Test strategy, validation, sign-off |
| **Doc Owner** | TBD | Documentation, examples, runbooks |
| **Support Lead** | TBD | Training, FAQ, user support |

---

## Security & Privacy Classification

**Classification:** Low Risk

**Rationale:**
- Token tracking: Only counts and costs, no content
- Parallel processing: Local execution, no new data transmission
- Model optimization: No new data exposure

**Security Considerations:**
- API keys still stored securely (existing mechanism)
- No new attack surface for parallel processing (local workers)
- Model tier config validation to prevent injection

---

## Dependency SLAs & Vendor Risk

### External Dependencies

**Existing (No Change):**
- OpenAI API: Existing SLA, no new risk
- Anthropic API: Existing SLA, no new risk
- Ollama: Local only, no SLA

**New Internal Dependencies:**
- Node.js `worker_threads`: Built-in, stable, no SLA risk
- No new npm packages planned

### Vendor Risk Mitigation
- Multiple provider support already implemented
- Fallback mechanism for model tier routing
- Graceful degradation if parallel processing fails

---

## Cost Model & Budget Guardrails

### Development Cost Estimate

| Phase | Effort | Cost (at $150/hr) |
|-------|--------|-------------------|
| Phase 1: Token Tracking | 2 days | $2,400 |
| Phase 2: Parallel Processing | 5 days | $6,000 |
| Phase 3: Model Optimization | 3 days | $3,600 |
| **Total** | **10 days** | **$12,000** |

### User Cost Impact

**Before Optimization:**
- 500 bookmarks Ã— categorization (Sonnet): $0.25
- 500 bookmarks Ã— summarization (Sonnet): $0.25
- **Total: $250 per archive run**

**After Optimization:**
- 500 bookmarks Ã— categorization (Haiku): $0.012
- 500 bookmarks Ã— summarization (Sonnet): $0.25
- **Total: $131 per archive run (48% savings)**

### Budget Guardrails
- No additional infrastructure costs (local processing)
- API costs are user-controlled (opt-in for cloud LLM)
- Development budget: $12,000 one-time

---

## Localization & Internationalization

**Status:** Not applicable (CLI tool, English-only)

**Future Consideration:**
- Token cost reports could support currency conversion
- Error messages could be localized (low priority)

---

## Backward Compatibility & Deprecation

### Compatibility

**Breaking Changes:** None

**New Features:** All opt-in via flags
- `--parallel` (default: false)
- `--model-strategy` (default: legacy)
- Token tracking (always active, no behavior change)

**Deprecations:** None

**Migration Path:** None required (seamless upgrade)

---

## Experimentation & Feature Flags

### Feature Flags

**Phase 2 (Parallel Processing):**
- **Flag:** `XKIT_PARALLEL_ENABLED`
- **Default:** `false`
- **Rollout:** Gradual based on evidence

**Phase 3 (Model Optimization):**
- **Flag:** `XKIT_MODEL_OPTIMIZATION_ENABLED`
- **Default:** `false`
- **Rollout:** Gradual based on evidence

### A/B Testing (Optional)

**Test Idea:** Compare sequential vs parallel processing performance
- **Metric:** Processing time, error rate, memory usage
- **Sample:** 100 users per variant
- **Duration:** 2 weeks
- **Decision:** Enable default-on if parallel is 2x faster with < 5% error rate

---

## Decision Log / ADRs

### ADR-001: Token Tracking Implementation
**Date:** 2025-01-19
**Status:** Accepted
**Context:** Users need cost visibility for cloud LLM usage
**Decision:** Implement token tracking with official tokenizers, display after processing
**Consequences:** Adds dependency on tokenizer libraries; increases code complexity
**Alternatives Considered:**
- Use rough character count (rejected: too inaccurate)
- Use API-provided token counts (rejected: not available for all providers)
- Skip token tracking (rejected: violates user need)

### ADR-002: Parallel Processing with Worker Threads
**Date:** 2025-01-19
**Status:** Accepted
**Context:** Sequential processing is too slow for large archives
**Decision:** Use Node.js `worker_threads` for CPU-bound LLM tasks
**Consequences:** Adds complexity; memory overhead; requires ordering guarantee
**Alternatives Considered:**
- Use child processes (rejected: higher overhead)
- Use async batching only (rejected: doesn't parallelize CPU work)
- Use external job queue (rejected: over-engineering)

### ADR-003: Model Tier Routing Strategy
**Date:** 2025-01-19
**Status:** Accepted
**Context:** Not all tasks need expensive models
**Decision:** Route categorization to fast model, summarization to balanced model
**Consequences:** Potential quality degradation; requires fallback mechanism
**Alternatives Considered:**
- Single model for all tasks (rejected: wasteful)
- Automatic model selection (rejected: adds overhead)
- User-selected model per task (accepted: user control)

---

## Open Questions

1. **Q:** Should parallel processing be enabled by default after rollout?
   **A:** Decision deferred until after evidence collection (Week 4)

2. **Q:** Should we support custom model tier configurations?
   **A:** Yes, but only for advanced users (document in "Advanced Configuration")

3. **Q:** Should token reports be persisted to disk?
   **A:** No, by default. Opt-in via `--save-token-report` (privacy-first)

4. **Q:** Should we show cost estimates BEFORE processing begins?
   **A:** Yes, based on a sample of 5 bookmarks (Phase 1.5, if evidence supports)

---

## Appendix: Smaug Reference Implementation

### Parallel Processing Pattern (Smaug)
```typescript
// Smaug uses Claude Code subagents for parallel processing
const results = await Promise.allSettled(
  bookmarks.map(b => subagent.analyze(b))
);
```

### Token Tracking Pattern (Smaug)
```typescript
// Smaug tracks token usage per operation
const usage = {
  input: response.usage.input_tokens,
  output: response.usage.output_tokens,
  cost: calculateCost(model, usage)
};
```

### Model Routing Pattern (Smaug)
```typescript
// Smaug uses Haiku for simple tasks, Sonnet for complex
const model = isComplex(task) ? 'sonnet' : 'haiku';
```

---

## References

- **Smaug Codebase:** Private repository (parallel processing architecture)
- **xKit Codebase:** https://github.com/jscraik/xKit
- **LIMITATIONS.md:** `LIMITATIONS.md:134-142`
- **Existing Modules:** `src/bookmark-analysis/`, `src/bookmark-stats/`

---

**Document Version:** 1.0
**Last Updated:** 2025-01-19
**Next Review:** After Phase 1 completion (estimated 2025-01-22)

---

## Debate Summary

**Status:** âœ… ALL PERSONAS [AGREE]

**Rounds Conducted:** 1

**Models:** PM, UI/UX Designer, Frontend Engineer, API Engineer, Backend Engineer, Security, Reliability/SRE, Cost/Scale

**Key Refinements:**

1. **Added User Personas** (ERROR-001)
   - 4 detailed personas: Alex (Research Analyst), Jordan (Casual User), Sam (Power User), Casey (Student)
   - Includes goals, pain points, technical proficiency, typical volumes

2. **Improved Success Metrics** (ERROR-002)
   - Added measurement methodology (hardware, network, statistical confidence)
   - Specific baselines and targets with Â± ranges
   - Validation methods for each metric

3. **Added Internal API Contracts** (ERROR-011)
   - Complete TypeScript interfaces for TokenTracker, ParallelProcessor, ModelRouter
   - JSDoc comments with parameters, returns, throws
   - Usage examples for each module

4. **Defined Error Codes** (ERROR-012)
   - Error code constants (TOKEN_XXX, PARALLEL_XXX, MODEL_XXX, CONFIG_XXX)
   - Error messages with user actions
   - Error code reference table

5. **Added Concurrency Control** (ERROR-014)
   - Worker pool lifecycle state machine diagram
   - Thread safety guarantees
   - Memory limits with overflow behavior

6. **Specified Retry Strategy** (ERROR-021)
   - Retry configuration with exponential backoff
   - Circuit breaker pattern with state diagram
   - Half-open state handling

7. **Defined SLOs and Error Budget** (ERROR-023)
   - Success rate, latency, memory targets
   - Error budget calculation and burn rate triggers
   - Actions on burn (warning, critical, emergency)

8. **Added Input Validation** (ERROR-018)
   - Parameter bounds table
   - Sanitization rules
   - Injection prevention

9. **Specified Secrets Handling** (ERROR-019)
   - Never log/display list (API keys, bodies, cookies)
   - May log list (token counts, costs, model names)
   - Redaction rules

10. **Updated Cost Calculations** (ERROR-025)
    - Current pricing with citations
    - Detailed cost comparison example
    - Before/after optimization breakdown

11. **Added Terminal UX Design** (ERROR-006)
    - Progress bar design for parallel mode
    - Empty state messages
    - Zero cost display

12. **Added Go/No-Go Framework** (ERROR-005)
    - Decision tables for Phase 2 and Phase 3
    - Specific thresholds and owners
    - Fallback plans

13. **Added Competitive Analysis** (ERROR-003)
    - Feature comparison table vs competitors
    - Differentiation highlights

**Resolved Issues:** 27 (14 critical errors, 9 high priority, 4 medium priority)

**Outstanding Questions:** 4 (documented in Open Questions section)

---

**Final Status:** [AGREE] - Specification complete and approved for implementation

[AGREE] PM: Scope, metrics, and personas well-defined
[AGREE] UI/UX: Terminal UX and error states specified
[AGREE] Frontend: State management approach clear
[AGREE] API: Internal contracts complete
[AGREE] Backend: Concurrency control adequate
[AGREE] Security: Input validation and secrets handling specified
[AGREE] SRE: SLOs, retry strategy, circuit breaker defined
[AGREE] Cost/Scale: Cost calculations accurate with current pricing

---

[SPEC]


## .spec/spec-2026-01-20-ai-knowledge-transformation.md
# xKit Enhanced Knowledge Transformation System

**Date:** 2026-01-20
**Type:** Product Requirements Document (PRD) + Technical Specification
**Status:** Draft v1.0
**Schema Version:** 1

---

## Executive Summary

Transform xKit from a bookmark archiver into a **knowledge transformation system** that converts bookmarked content into:
1. **Engaging summaries** using Summarize-style prompt engineering
2. **Agent Skills** for Claude Code (reusable AI capabilities)
3. **Learning materials** (study guides, flashcards, quizzes) for self-learning
4. **Custom prompt templates** for domain-specific summarization

**Vision Statement:** Every bookmark becomes a building block for AI development - not just stored, but transformed into actionable knowledge.

**Key Differentiation:** Unlike generic bookmarking tools, xKit leverages proven patterns from [steipete/summarize](https://github.com/steipete/summarize) (production-grade CLI with 200+ tests, Chrome extension, daemon mode) while adding unique capabilities for skill extraction and learning material generation.

**Evidence-Based Design:** This specification is informed by reconnaissance analysis of Summarize's architecture, security model, and feature set. See `.spec/spec-2026-01-20-summarize-feature-analysis.md` for detailed feature comparison.

---

## Problem & Opportunity

### Current State Analysis

**xKit's Current Capabilities** (from `src/commands/bookmarks-archive.ts`):
- Fetches bookmarks from Twitter API
- Enriches with URL expansion and article extraction
- Categorizes into github/article/video/prompts/visual/tweet
- Exports to markdown with date/author organization
- Basic summarization via Ollama (generic prompt: "You are a helpful assistant that creates concise summaries")

**Limitations** (from `src/bookmark-enrichment/ollama-client.ts:68-88`):
```typescript
// Current generic prompt - lacks engagement and adaptability
private buildSummaryPrompt(content: string, title?: string): string {
  return `You are a helpful assistant that creates concise summaries of articles.
  // Fixed 2-3 sentence format, no persona, no content-type awareness
  ```
}

### User Pain Points (Hypotheses - Validation Required)

1. **Generic Summaries:** Current summaries are one-size-fits-all, not tailored to learning style or content type
2. **Passive Archive:** Bookmarks accumulate without active knowledge extraction
3. **Manual Note-Taking:** Users manually convert bookmarks to Skills, study guides, or reference materials
4. **Lost Context:** Remembering why a bookmark was saved is difficult over time

### Market Opportunity

**Competitive Landscape** (based on Summarize reconnaissance):
- **Summarize:** CLI tool for summarization (no bookmark archiving, no skill generation)
- **Readwise:** Read-later service with highlighting (no skill generation, no custom workflows)
- **Fabric:** AI-powered workspace (expensive, generic prompts, no bookmark integration)

**xKit's Unique Position:**
- **Source:** Twitter/X bookmarks (high-signal content curation)
- **Output:** Multiple transformation types (summaries, Skills, learning materials)
- **Integration:** Direct Claude Code Skills generation (unique capability)
- **Cost:** Local LLM via Ollama (free, private) vs paid APIs

---

## User Personas

### Primary Persona: "Alex, Senior iOS Engineer"

**Demographics:**
- 8 years experience, builds consumer apps
- Active on Twitter/X, follows 500+ developers
- Saves 20-30 bookmarks/week (GitHub repos, technical articles, talks)

**Goals:**
- Stay current with iOS/SwiftUI patterns
- Build personal knowledge base of reusable code patterns
- Learn new technologies efficiently (just-in-time learning)
- Share insights with team via generated Skills

**Pain Points:**
- Bookmarks pile up, forgotten after 1 week
- GitHub repos saved but never mined for patterns
- Articles read but not retained
- Manual conversion to team Skills is time-consuming

**Current Workflow:**
1. Scroll Twitter, tap bookmark on interesting content
2. Never revisit bookmarks (black hole)
3. Manually take notes in Notion for important repos (rarely)
4. Search Google when need pattern (already bookmarked!)

**Desired Workflow:**
1. Bookmark tweet/repo/article on Twitter
2. xKit auto-categorizes and generates engaging summary
3. Review weekly recap, extract valuable Skills
4. Add Skills to Claude Code for daily use
5. Generate study guide for new tech (e.g., "SwiftUI animations")

**Success Metrics for Alex:**
- Reduces time-to-pattern from 30 min (manual) to 5 min (automated)
- Extracts 5+ useful Skills/month from bookmarks
- Generates 2+ study guides/month for new technologies

### Secondary Persona: "Jordan, Technical Product Manager"

**Demographics:**
- 5 years in PM, works on developer tools
- Follows product blogs, engineering blogs, GitHub projects
- Saves 10-15 bookmarks/week

**Goals:**
- Track competitive landscape
- Understand technical feasibility of features
- Learn from other PMs and engineers
- Share insights with team

**Pain Points:**
- Technical articles overwhelming (too much detail)
- Hard to distill "what this means for us"
- GitHub repos saved but never evaluated

**Desired Workflow:**
1. Bookmark technical content
2. Get business-focused summary (product-manager persona)
3. Generate comparison report from related bookmarks
4. Share summary with team via webhook (Slack/Discord)

**Success Metrics for Jordan:**
- Summaries capture business implications (not just technical details)
- Weekly recap highlights competitive insights
- Can explain technical feasibility to non-technical stakeholders

### Tertiary Persona: "Sam, Self-Taught Developer"

**Demographics:**
- 2 years coding, bootcamp grad
- Active learner, follows tutorials and documentation
- Saves 30+ bookmarks/week (tutorials, docs, examples)

**Goals:**
- Learn efficiently (spaced repetition)
- Build comprehensive understanding of topics
- Track learning progress
- Practice with real-world examples

**Pain Points:**
- Tutorial bookmarked but never completed
- Forgets syntax and patterns
- No structured learning path
- Overwhelmed by volume of content

**Desired Workflow:**
1. Bookmark tutorials and docs
2. Generate study guides with learning objectives
3. Create flashcards for spaced repetition
4. Track mastery with quiz assessments
5. Recap monthly to reinforce learning

**Success Metrics for Sam:**
- Completes 80% of bookmarked tutorials (vs 20% baseline)
- Retains 70% of flashcard content after 1 week
- Generates personalized learning roadmap from bookmarks

---

## User Stories

### STORY-001: Enhanced Bookmark Summarization

**As** Alex (senior iOS engineer),
**I want** to generate engaging summaries tailored to my learning style,
**So that** I can quickly grasp key concepts without reading full articles.

**Acceptance Criteria:**
- [ ] CLI flag `--summarize --persona technical-researcher --length long` produces technical summary
- [ ] CLI flag `--summarize --persona curious-learner --length medium` produces accessible summary
- [ ] Summary quality score â‰¥ 4.0/5.0 in user surveys (n=30)
- [ ] Latency â‰¤ 1.5Ã— current baseline (measure with 100 bookmarks)
- [ ] Supports 5 length levels (short, medium, long, xl, xxl)
- [ ] Supports 7 personas (curious-learner, technical-researcher, product-manager, engineer-pragmatic, educator, skeptic, synthesizer)
- [ ] Supports 7 content types (article, video-transcript, github-repo, documentation, twitter-thread, podcast-episode, research-paper)

**Success Metrics:**
- Summary engagement rate (user reads full summary) â‰¥ 60%
- Summary regeneration rate (user regenerates with different options) â‰¤ 20%
- Time-saved vs reading full article â‰¥ 80% (user survey)

### STORY-002: Agent Skill Extraction from Bookmarks

**As** Alex (senior iOS engineer),
**I want** to automatically extract reusable code patterns from bookmarked GitHub repos,
**So that** I can add them to my Claude Code Skills library.

**Acceptance Criteria:**
- [ ] CLI command `xkit generate-skills --category github --min-confidence 0.7` extracts skills
- [ ] Generated Skills follow Claude Code `.skill.md` format (frontmatter, triggers, implementation, examples, edge cases)
- [ ] Skill extraction precision â‰¥ 80% (manual audit of 100 generated skills)
- [ ] Confidence scoring (0-1) indicates likelihood of usefulness
- [ ] Skills written to `.claude/skills-review/` (require manual approval before `.claude/skills/`)
- [ ] Includes disclaimer: "AI-generated, review before use"
- [ ] Supports categories: code-pattern, best-practice, workflow

**Success Metrics:**
- 10+ useful skills generated from existing GitHub bookmarks (manual review)
- User approval rate â‰¥ 60% (skills moved from review to active)
- Zero unsafe code in approved skills (manual audit)

### STORY-003: Learning Material Generation

**As** Sam (self-taught developer),
**I want** to generate study guides and flashcards from bookmarked tutorials,
**So that** I can learn efficiently with spaced repetition.

**Acceptance Criteria:**
- [ ] CLI command `xkit learn --generate study-guide,flashcards --from "SwiftUI animations"` generates materials
- [ ] Study guides include: learning objectives, core concepts, examples, exercises, difficulty assessment
- [ ] Flashcards are Q&A pairs suitable for spaced repetition
- [ ] Learning material completion rate â‰¥ 60% (A/B test vs baseline)
- [ ] User satisfaction â‰¥ 3.5/5.0 (surveys)
- [ ] Materials stored in `~/.xkit/learning/` with organized structure

**Success Metrics:**
- Tutorial completion rate increases from 20% to 80%
- Flashcard retention rate â‰¥ 70% after 1 week (user quiz)
- Study guide generation time â‰¤ 30s per bookmark

### STORY-004: Periodic Recap Generation

**As** Alex (senior iOS engineer),
**I want** a weekly recap of my bookmarks grouped by theme,
**So that** I can discover connections and extract actionable insights.

**Acceptance Criteria:**
- [ ] CLI command `xkit recap --period weekly --categories github,article` generates recap
- [ ] Recap groups bookmarks by semantic theme (using vector embeddings)
- [ ] Identifies cross-connections between topics
- [ ] Suggests actionable next steps
- [ ] Generates reflection questions
- [ ] Recap generation time â‰¤ 2 minutes for 100 bookmarks
- [ ] Recap includes links to original bookmarks

**Success Metrics:**
- Recap engagement rate (user reads full recap) â‰¥ 50%
- Skills extracted from recap â‰¥ 3 per week
- User-reported insight rate â‰¥ 70% (recap revealed new connection)

### STORY-005: Custom Prompt Templates

**As** Jordan (technical PM),
**I want** to create custom prompt templates for domain-specific summarization,
**So that** I can get consistent outputs for my use cases.

**Acceptance Criteria:**
- [ ] Templates stored in `~/.xkit/templates/` as markdown files with YAML frontmatter
- [ ] Template format: name, description, category, prompt content with `{{variable}}` substitutions
- [ ] CLI command `xkit summarize <url> --template research-paper --var domain="ML"` applies template
- [ ] Template validation before use (checks for forbidden patterns, validates variables)
- [ ] Error messages clear when template invalid
- [ ] Example templates included: research-paper, good-first-issue, api-integration

**Success Metrics:**
- Custom template usage rate â‰¥ 10% of summarization calls
- Template validation success rate â‰¥ 95%
- User satisfaction with custom templates â‰¥ 4.0/5.0

---

## Success Criteria

### Phase 1: Enhanced Summarization (Days 1-3)
- [ ] Tagged prompts implemented (XML-style `<instructions>`, `<context>`, `<content>`)
- [ ] All 5 length levels working (short, medium, long, xl, xxl)
- [ ] All 7 personas implemented (curious-learner, technical-researcher, product-manager, engineer-pragmatic, educator, skeptic, synthesizer)
- [ ] All 7 content types supported (article, video-transcript, github-repo, documentation, twitter-thread, podcast-episode, research-paper)
- [ ] Custom templates loading from `~/.xkit/templates/`

### Phase 2: Skill Generation (Days 4-6)
- [ ] Extract patterns from GitHub repos (80%+ useful per manual audit)
- [ ] Extract best practices from articles
- [ ] Generate valid `.skill.md` files
- [ ] 10+ skills generated from existing bookmarks

### Phase 3: Learning Materials (Days 7-9)
- [ ] Study guide generation working
- [ ] Flashcard generation working
- [ ] Quiz generation working
- [ ] Recap clusters by theme (using embeddings)

### Phase 4: Integration (Days 10-11)
- [ ] All CLI commands working
- [ ] Config file support
- [ ] Documentation complete
- [ ] Example outputs generated

### Measurable Success Metrics (All Phases)

**Quality Metrics:**
- Summary quality score â‰¥ 4.0/5.0 (user surveys, n=30)
- Skill extraction precision â‰¥ 80% (manual audit, n=100)
- Learning material completion rate â‰¥ 60% (A/B test vs baseline)

**Performance Metrics:**
- Summary latency â‰¤ 1.5Ã— current baseline (measure with 100 bookmarks)
- Skill generation â‰¤ 3Ã— baseline (acceptable due to complexity)
- Learning material generation â‰¤ 5Ã— baseline (acceptable due to complexity)

**User Engagement Metrics:**
- Summary engagement rate (reads full summary) â‰¥ 60%
- Skill approval rate (review â†’ active) â‰¥ 60%
- Recap engagement rate â‰¥ 50%

**Security Metrics:**
- Zero prompt injection vulnerabilities (penetration testing)
- Zero unsafe code in approved Skills (manual audit)
- All templates validated before use

**Reliability Metrics:**
- CLI command success rate â‰¥ 99% (excludes user errors)
- LLM error rate < 5% (excluding Ollama down)
- Cache hit rate â‰¥ 60% on second run (Same Summarize's 60%+ target)

---

## Risks and Mitigations

### RISK-001: LLM Hallucination in Skill Extraction

**Severity:** High
**Probability:** Medium
**Impact:** Users receive incorrect or unsafe code patterns

**Mitigation:**
- Confidence scoring (0-1) with manual review required for low-confidence skills
- Two-stage validation: (1) LLM extraction, (2) Code linting (Biome) + static analysis
- Manual approval workflow: `.claude/skills-review/` â†’ `.claude/skills/`
- Clear disclaimer: "AI-generated, review before use"

**Owner:** @jamiecraik
**Status:** Open

### RISK-002: Low-Quality Generated Materials

**Severity:** Medium
**Probability:** Medium
**Impact:** Users abandon feature due to poor quality

**Mitigation:**
- User feedback loop: rating system for generated materials
- Iterative refinement: prompts tuned based on feedback
- A/B test against baseline (no generated materials)
- Kill criteria: if satisfaction < 3.5/5.0 for 30 days, deprecate feature

**Owner:** @jamiecraik
**Status:** Open

### RISK-003: Prompt Injection Vulnerability

**Severity:** Critical
**Probability:** Low
**Impact:** Malicious bookmark content manipulates LLM

**Mitigation:**
- Sanitize XML tags in content before inserting into prompts
- Use UUID-based delimiters instead of XML tags
- Implement prompt validation and escaping
- Penetration testing before GA
- **Reference:** See adversarial review ERROR finding Security-1

**Owner:** @jamiecraik
**Status:** Open - Must fix before Phase 1

### RISK-004: Unrealistic Timeline

**Severity:** High
**Probability:** High
**Impact:** Burnout, technical debt, abandoned features

**Mitigation:**
- Revised timeline: 23 days (includes Phase 0 foundation + user research)
- Phased validation: research before building Phases 2-3
- Buffer for iteration: +3 days for user feedback
- Go/no-go decisions after each phase

**Owner:** @jamiecraik
**Status:** Open - Addressed in revised plan

### RISK-005: No User Demand for Skills/Learning Materials

**Severity:** High
**Probability:** Medium
**Impact:** Build features nobody uses

**Mitigation:**
- User research (n=10-15 interviews) before building Phases 2-3
- Go/no-go criteria:
  - If â‰¥ 70% express interest in enhanced summaries â†’ proceed
  - If â‰¥ 50% express interest in Skills â†’ proceed
  - If < 50% express interest in learning materials â†’ cut or defer
- Kill criteria: if feature unused by 20% of users after 30 days, deprecate

**Owner:** @jamiecraik
**Status:** Open - Requires user research

### RISK-006: Cost Overrun from LLM Usage

**Severity:** Medium
**Probability:** Low
**Impact:** Surprise bills or unusable feature

**Mitigation:**
- Default to local Ollama (free)
- Cost estimation before running: `--max-llm-spend $10` with confirmation
- Token tracking: show cost per 1,000 bookmarks
- Kill switch: if cost > $50/month, require explicit re-authorization

**Owner:** @jamiecraik
**Status:** Open

---

## Out of Scope

**Explicitly Out of Scope for v1.0:**
- Chrome extension (deferred to v2.0, requires daemon infrastructure)
- Podcast transcription (YouTube only in v1.0)
- Multi-format file processing (PDFs, images - requires MarkItDown integration)
- Real-time streaming of summaries (batch only in v1.0)
- Collaborative features (sharing Skills, team learning materials)
- Advanced analytics (usage dashboards, learning progress tracking)
- Mobile apps (CLI only in v1.0)
- Paid API integrations (OpenAI, Anthropic - Ollama/local only in v1.0)

**Rationale:** Focus on CLI workflow (matches xKit's current usage), validate demand before adding Chrome extension or mobile apps, leverage existing Ollama infrastructure before adding paid APIs.

**Future Considerations (v2.0+):**
- Chrome Side Panel extension (å€Ÿé‰´ Summarize's architecture)
- Daemon mode for long-running processes
- Podcast transcription (å€Ÿé‰´ Summarize's 4-level fallback)
- Paid API integrations with auto model selection
- Real-time streaming summaries

---

## Feature Creep Guardrails

**Scope Change Policy:**
1. Any new feature must displace an existing feature (zero-sum scope)
2. New features require 48-hour consideration period (preventså†²åŠ¨ decisions)
3. Must pass cost-benefit analysis (user value vs implementation effort)
4. Must update success criteria and risk register

**Example Guardrails:**
- **Question:** "Should we add podcast transcription in v1.0?"
- **Answer:** No, displaces Skill Generation (higher user value per hypothesis). Defer to v2.0.
- **Question:** "Should we add Chrome extension in v1.0?"
- **Answer:** No, requires daemon infrastructure (5-7 days), displaces user research (higher priority). Defer to v2.0.

**48-Hour Rule for New Documentation:**
- Adding new documentation artifacts (e.g., SPEC_INDEX.md) requires explicit justification
- Must answer: (1) What problem does this solve? (2) Who will maintain it? (3) When will it be updated?
- Default answer: No new docs unless critical for shipping

---

## Scope Decision Log

### Decision 001: Exclude Chrome Extension from v1.0
**Date:** 2026-01-20
**Decision:** CLI-only workflow for v1.0, defer Chrome extension to v2.0
**Rationale:**
- Chrome extension requires daemon infrastructure (5-7 days per Summarize analysis)
- User research higher priority (validates demand for Skills/learning materials)
- CLI workflow matches xKit's current usage patterns
- Reduces initial scope from 23 days to 15 days (without extension)
**Alternatives Considered:**
- Include extension: +7 days, higher complexity, unproven demand
**Revisit:** After v1.0 GA and user feedback

### Decision 002: Prioritize User Research Before Skills/Learning Materials
**Date:** 2026-01-20
**Decision:** Add Phase 1A (User Research, 3 days) before building Phases 2-3
**Rationale:**
- No evidence users want Skills or learning materials (per adversarial review PM-1)
- Risk building features nobody uses
- Low-cost investment (3 days) vs high-risk implementation (10+ days)
**Alternatives Considered:**
- Skip research, build anyway: rejected (high risk of waste)
**Revisit:** After user research complete

### Decision 003: Add Phase 0 (Foundation) Before Features
**Date:** 2026-01-20
**Decision:** Implement caching, observability, security foundations before adding features
**Rationale:**
- Adversarial review identified 36 ERROR findings across reliability/security
- Cannot measure success without observability
- Cannot ship safely without security foundations
- Summarize has proven caching (eliminates 60%+ redundant API calls)
**Alternatives Considered:**
- Build features first, add foundations later: rejected (technical debt trap)
**Revisit:** After Phase 0 complete

---

## Technical Architecture

### System Overview

```mermaid
flowchart TD
    A[xKit CLI: bookmarks-archive] --> B[Fetch Bookmarks<br/>Twitter API]
    B --> C[BookmarkEnricher<br/>URL expansion, content extraction]
    C --> D{Summarization Enabled?}
    D -->|No| E[Skip to Categorization]
    D -->|Yes| F[OllamaClient Enhanced]
    F --> G[TaggedPromptBuilder<br/>instructions/context/content]
    G --> H[PersonaSelector<br/>7 personas]
    G --> I[LengthSelector<br/>5 levels]
    G --> J[ContentTypeAdapter<br/>7 types]
    H --> K[Ollama API]
    I --> K
    J --> K
    K --> L[SummaryResult<br/>content, tokens, cost]
    L --> M[BookmarkCategorizer]
    E --> M
    M --> N{Skill Generation?}
    N -->|Yes| O[SkillExtractor<br/>LLM-based pattern extraction]
    O --> P[SkillTemplateGenerator<br/>.skill.md format]
    P --> Q[SkillWriter<br/>.claude/skills-review/]
    N -->|No| R{Learning Materials?}
    R -->|Yes| S[LearningMaterialGenerator<br/>study guides, flashcards, quizzes]
    S --> T[LearningWriter<br/>~/.xkit/learning/]
    R -->|No| U[MarkdownWriter<br/>knowledge files]
    Q --> U
    T --> U
    U --> V[StateManager<br/>mark processed]
    V --> W[TokenTracker<br/>usage, cost]
```

### Component Behavior / State Model

```mermaid
stateDiagram-v2
    [*] --> IDLE: CLI invoked

    IDLE --> FETCHING: user confirms credentials
    FETCHING --> IDLE: fetch failed / retryable
    FETCHING --> ENRICHING: bookmarks fetched

    ENRICHING --> ENRICHING: batch progress
    ENRICHING --> SUMMARIZING: enrichment complete / summarize enabled
    ENRICHING --> CATEGORIZING: enrichment complete / summarize disabled

    SUMMARIZING --> SUMMARIZING: persona/length selection
    SUMMARIZING --> CATEGORIZING: summary generated / skip summarization
    SUMMARIZING --> ERROR: LLM timeout / Ollama down
    SUMMARIZING --> ERROR: prompt injection detected

    CATEGORIZING --> CATEGORIZING: category determination
    CATEGORIZING --> SKILL_EXTRACTION: categorization complete / skill generation enabled
    CATEGORIZING --> LEARNING_GENERATION: categorization complete / learning enabled
    CATEGORIZING --> WRITING: categorization complete / skip skills/learning

    SKILL_EXTRACTION --> SKILL_EXTRACTION: LLM extraction per bookmark
    SKILL_EXTRACTION --> WRITING: skills extracted / write review files
    SKILL_EXTRACTION --> ERROR: extraction failed / log error, continue

    LEARNING_GENERATION --> LEARNING_GENERATION: material generation per bookmark
    LEARNING_GENERATION --> WRITING: materials generated / write learning files
    LEARNING_GENERATION --> ERROR: generation failed / log error, continue

    WRITING --> WRITING: markdown files written
    WRITING --> COMPLETE: all files written

    ERROR --> COMPLETE: partial success / some bookmarks failed
    ERROR --> [*]: fatal error / abort

    COMPLETE --> [*]
```

### Data Models

#### EnhancedSummary
```typescript
interface EnhancedSummary {
  id: string; // UUID
  bookmarkId: string; // Foreign key to CategorizedBookmark
  persona: PersonaType; // curious-learner | technical-researcher | ...
  length: SummaryLength; // short | medium | long | xl | xxl
  contentType: ContentType; // article | video-transcript | github-repo | ...
  content: string; // Generated summary
  tokensUsed: {
    input: number;
    output: number;
    total: number;
  };
  costEstimate: number; // USD (0.0 for local Ollama)
  model: string; // e.g., "nomic-embed-text", "qwen2.5:7b"
  timestamp: string; // ISO 8601
}
```

#### SkillCandidate
```typescript
interface SkillCandidate {
  id: string; // UUID
  bookmarkId: string; // Foreign key to CategorizedBookmark
  name: string; // Skill name
  description: string; // One-sentence summary
  triggers: string[]; // When to use this skill
  category: 'code-pattern' | 'best-practice' | 'workflow';
  implementation: string; // Step-by-step guidance
  examples: Array<{
    scenario: string;
    code: string;
  }>;
  edgeCases: string[]; // Common pitfalls
  confidence: number; // 0-1, likelihood of usefulness
  status: 'review' | 'approved' | 'rejected';
  generatedAt: string; // ISO 8601
  reviewedAt?: string; // ISO 8601
}
```

#### LearningMaterial
```typescript
interface LearningMaterial {
  id: string; // UUID
  bookmarkId: string; // Foreign key to CategorizedBookmark
  type: 'study-guide' | 'flashcards' | 'quiz';
  title: string; // Material title
  difficulty: 'beginner' | 'intermediate' | 'advanced';
  objectives: string[]; // Learning objectives
  content: {
    concepts: Array<{
      name: string;
      definition: string;
      examples: string[];
    }>;
    exercises: Array<{
      question: string;
      answer: string;
      difficulty: number; // 1-5
    }>;
  };
  estimatedTime: number; // Minutes
  generatedAt: string; // ISO 8601
}
```

#### Recap
```typescript
interface Recap {
  id: string; // UUID
  period: 'daily' | 'weekly' | 'monthly';
  startDate: string; // ISO 8601
  endDate: string; // ISO 8601
  themes: Array<{
    name: string; // Theme name (e.g., "SwiftUI Animations")
    bookmarkIds: string[]; // Related bookmarks
    summary: string; // Thematic summary
    connections: string[]; // Cross-connections
    nextSteps: string[]; // Actionable items
  }>;
  reflectionQuestions: string[]; // Prompts for user
  generatedAt: string; // ISO 8601
}
```

### Security Considerations

**å€Ÿé‰´ Summarize's Security Model:**
- Localhost-only binding for any future daemon mode
- Bearer token authentication for API endpoints
- CORS validation for Chrome extension (future)
- API keys captured at startup from environment
- No key leakage in codebase (verified via reconnaissance)

**Additional Security Measures for xKit:**

#### Prompt Injection Protection (Critical - Must Fix Before Phase 1)
```typescript
function escapeXmlTags(content: string): string {
  return content
    .replace(/<instructions>/gi, '&lt;instructions&gt;')
    .replace(/<\/instructions>/gi, '&lt;/instructions&gt;')
    .replace(/<context>/gi, '&lt;context&gt;')
    .replace(/<\/context>/gi, '&lt;/context&gt;')
    .replace(/<content>/gi, '&lt;content&gt;')
    .replace(/<\/content>/gi, '&lt;/content&gt;');
}

function buildSafeTaggedPrompt(options: {
  instructions: string;
  context: string;
  content: string;
}): string {
  const safeContent = escapeXmlTags(options.content);
  return `<instructions>
${options.instructions.trim()}
</instructions>

<context>
${options.context.trim()}
</context>

<content>
${safeContent.trim()}
</content>`;
}
```

#### Template Validation
```typescript
interface TemplateSchema {
  allowedVariables: string[]; // e.g., ['domain', 'language', 'difficulty']
  forbiddenPatterns: RegExp[]; // e.g., [/process\./, /child_process/]
  maxLength: number; // e.g., 10_000 characters
}

function validateTemplate(
  template: string,
  schema: TemplateSchema
): { valid: boolean; errors: string[] } {
  const errors: string[] = [];

  // Check for forbidden patterns
  for (const pattern of schema.forbiddenPatterns) {
    if (pattern.test(template)) {
      errors.push(`Forbidden pattern detected: ${pattern}`);
    }
  }

  // Check for system calls
  if (template.includes('process.') || template.includes('child_process')) {
    errors.push('Template must not access system APIs');
  }

  // Validate variables
  const variables = template.match(/\{\{(\w+)\}\}/g) || [];
  for (const variable of variables) {
    const name = variable.slice(2, -2);
    if (!schema.allowedVariables.includes(name)) {
      errors.push(`Unknown variable: ${name}`);
    }
  }

  return { valid: errors.length === 0, errors };
}
```

#### Generated Code Disclaimer
```markdown
---
**Disclaimer:** This Skill was auto-generated by xKit from bookmarked content.
**Do not use in production without thorough review.** Always test code in a safe
environment before deploying to production systems.

Review checklist:
- [ ] Code compiles without errors
- [ ] No unsafe operations (eval, exec, SQL injection)
- [ ] Error handling is appropriate
- [ ] Tested with sample inputs
---
```

### API Design

#### CLI Commands (New)

```bash
# Enhanced summarization
xkit archive --summarize --persona <persona> --length <length> --content-type <type>
  persona: curious-learner | technical-researcher | product-manager | engineer-pragmatic | educator | skeptic | synthesizer
  length: short | medium | long | xl | xxl
  content-type: article | video-transcript | github-repo | documentation | twitter-thread | podcast-episode | research-paper

# Skill generation
xkit generate-skills --category <category> --min-confidence <0.0-1.0> --last <n>
  category: github | article | video | all
  min-confidence: 0.7 (default)
  last: number of recent bookmarks to process (default: all)

# Learning materials
xkit learn --generate <types> --from <query> --difficulty <level>
  types: study-guide,flashcards,quiz (comma-separated)
  from: search query for bookmarks (e.g., "SwiftUI animations")
  difficulty: beginner | intermediate | advanced

# Recap
xkit recap --period <daily|weekly|monthly> --categories <categories>
  categories: github,article,video,prompts,visual,tweet (comma-separated)

# Custom templates
xkit summarize <url> --template <name> --var <key=value>
  template: template name (from ~/.xkit/templates/)
  var: variable substitutions (e.g., domain="ML", language="python")

# Cache management (å€Ÿé‰´ Summarize)
xkit cache --stats --clear --no-cache
  --stats: show cache statistics
  --clear: clear all cached data
  --no-cache: disable caching for this run
```

#### Programmatic API (Future - for Daemon Mode)

```typescript
// Future: HTTP API for Chrome extension (v2.0)
interface DaemonAPI {
  // Health check
  'GET /health': { ok: true; pid: number; version: string }

  // Bookmark operations
  'POST /v1/bookmark': { ok: true; id: string }
  'GET /v1/bookmark/:id': CategorizedBookmark
  'DELETE /v1/bookmark/:id': { ok: true }

  // Summarization
  'POST /v1/summarize': EnhancedSummary
  'GET /v1/summarize/:id': EnhancedSummary

  // Skill generation
  'POST /v1/skills': SkillCandidate[]
  'GET /v1/skills': SkillCandidate[]
  'PUT /v1/skills/:id/approve': { ok: true }

  // Learning materials
  'POST /v1/learn': LearningMaterial
  'GET /v1/learn': LearningMaterial[]

  // Recap
  'POST /v1/recap': Recap

  // Search (using embeddings)
  'GET /v1/search?q=<query>': CategorizedBookmark[]
  'GET /v1/similar/:id': CategorizedBookmark[]

  // Stats
  'GET /v1/stats': {
    totalBookmarks: number;
    cached: number;
    lastRun: string;
    llmCalls: number;
    tokensUsed: number;
  }
}
```

### Deployment Strategy

#### Phase 0: Foundation (Days 1-3)
1. **SQLite Caching** (å€Ÿé‰´ Summarize)
   - Implement extract cache and summary cache
   - TTL: 30 days, size cap: 512MB
   - WAL mode for performance, LRU eviction
   - CLI flags: `--cache-stats`, `--clear-cache`, `--no-cache`

2. **Observability Foundation**
   - Structured logging with pino
   - Metrics collection (latency, error rate, token usage)
   - Health check command: `xkit status`

3. **Security Foundation**
   - Prompt injection protection (XML tag escaping)
   - Template validation schema
   - Audit logging (opt-in)

#### Phase 1A: User Research (Days 4-6)
1. **User Interviews** (n=10-15)
   - Current bookmark workflow pain points
   - Interest in enhanced summaries (personas, lengths)
   - Interest in Skills generation
   - Interest in learning materials

2. **Mockup Testing**
   - Paper prototypes for CLI UX
   - Example outputs (hand-crafted)
   - Feedback on feature prioritization

3. **Go/No-Go Decision**
   - If â‰¥ 70% express interest in enhanced summaries â†’ proceed
   - If â‰¥ 50% express interest in Skills â†’ proceed
   - If < 50% express interest in learning materials â†’ cut or defer

#### Phase 1B: Enhanced Summarization (Days 7-10)
1. **Tagged Prompt Structure**
2. **Length-Specific Templates** (5 levels)
3. **Persona System** (7 personas)
4. **Content-Type Adaptation** (7 types)

**Success Criteria:**
- Summary quality â‰¥ 4.0/5.0 (user surveys, n=30)
- No regressions in latency (> 1.5Ã— current time)

#### Phase 2: Skill Generation (Days 11-16) - **CONDITIONAL**
**Goal:** Ship ONLY if validated in research (â‰¥ 50% interest)

1. **Skill Extraction**
2. **Skill Template Generator**
3. **Skill Writer**

**Success Criteria:**
- Skill extraction precision â‰¥ 80% (manual audit)
- 10+ useful skills from test data
- Users approve â‰¥ 60% of generated skills

#### Phase 3: Learning Materials (Days 17-20) - **CONDITIONAL**
**Goal:** Ship ONLY if validated in research (â‰¥ 50% interest)

1. **Material Generator** (study guides, flashcards, quizzes)
2. **Recap System**

**Success Criteria:**
- Learning material completion rate â‰¥ 60% (A/B test)
- User satisfaction â‰¥ 3.5/5.0 (surveys)

#### Phase 4: CLI Integration & Docs (Days 21-23)
1. **CLI Commands**
2. **Documentation**
3. **Example Outputs**

**Total Timeline:** 23 days (with validation and conditional phases)

### Performance Targets

**Latency:**
- Single bookmark summarization: p95 < 30s
- Skill extraction: p95 < 90s (3Ã— baseline)
- Learning material generation: p95 < 150s (5Ã— baseline)
- Recap generation (100 bookmarks): < 2 minutes

**Throughput:**
- Batch processing (100 bookmarks): < 30 minutes
- Cache hit rate: â‰¥ 60% on second run

**Resource Usage:**
- Ollama memory: < 8GB (nomic-embed-text: 7B params)
- Disk usage: < 1GB for 1,000 bookmarks (including cache, skills, learning materials)

### Reliability Targets

**Availability:**
- CLI command success rate: â‰¥ 99% (excludes user errors)

**Error Rate:**
- LLM-related errors: < 5% (excluding Ollama down)
- Cache-related errors: < 1%
- Template validation errors: < 1%

**Data Quality:**
- Summary quality score: â‰¥ 4.0/5.0 (user surveys)
- Skill extraction precision: â‰¥ 80% (manual audit)
- Learning material completeness: â‰¥ 95% (automated checks)

---

## Cost Model & Budget Guardrails

### Local LLM (Default)
- **Cost:** $0 (Ollama with local models)
- **Hardware:** 8GB RAM minimum (nomic-embed-text: 7B params)
- **Pros:** Free, private, no rate limits
- **Cons:** Requires local hardware, slower than paid APIs

### Paid API (Optional - Future)
- **Estimated Cost:** $0.001 per bookmark (2K input tokens + 500 output tokens @ $0.0003/1K tokens)
- **1,000 bookmarks:** ~$1
- **10,000 bookmarks:** ~$10
- **With Skills + Learning Materials:** ~$5-10 per 1,000 bookmarks (3-5Ã— more tokens)

**Budget Guardrails:**
- Max spend per month: $50 (configurable via `--max-llm-spend`)
- Confirmation required if estimated cost > $10
- Kill switch: if cost > $50/month, require explicit re-authorization

---

## Data Lifecycle & Retention

### Retention Policy
- **Cached LLM responses:** 30 days TTL (å€Ÿé‰´ Summarize)
- **Generated Skills:** Retain indefinitely (unless user deletes)
- **Learning Materials:** Retain indefinitely (unless user deletes)
- **Recaps:** Retain for 90 days, then auto-archive

### Deletion Policy
- User can delete individual Skills/Learning Materials via CLI
- `--clear-cache` deletes all cached data
- `--purge` deletes all generated materials (Skills, Learning Materials)

### Data Storage
- **Cache:** SQLite database at `~/.xkit/cache.sqlite`
- **Skills:** `.claude/skills-review/` and `.claude/skills/`
- **Learning Materials:** `~/.xkit/learning/`
- **Recaps:** `~/.xkit/recaps/`

---

## Launch & Rollback Guardrails

### Go/No-Go Metrics (Phase 1B: Enhanced Summarization)
**Go Criteria:**
- [ ] Summary quality â‰¥ 4.0/5.0 (user surveys, n=30)
- [ ] Latency â‰¤ 1.5Ã— baseline (measured with 100 bookmarks)
- [ ] Zero critical security vulnerabilities (penetration testing)
- [ ] Cache hit rate â‰¥ 60% on second run
- [ ] User engagement rate (reads full summary) â‰¥ 60%

**No-Go Criteria:**
- Summary quality < 3.5/5.0
- Latency > 2Ã— baseline
- Any critical security vulnerabilities
- Cache hit rate < 40%

**Rollback Plan:**
- Feature flag: `--features enhanced-summarization` (opt-in initially)
- Fallback to old summarization if new fails
- Data migration path (old to new format)
- `--summarize-legacy` flag to force old behavior

### Go/No-Go Metrics (Phase 2: Skill Generation)
**Go Criteria:**
- [ ] Skill extraction precision â‰¥ 80% (manual audit)
- [ ] 10+ useful skills from test data
- [ ] User approval rate â‰¥ 60%
- [ ] Zero unsafe code in approved skills (manual audit)

**No-Go Criteria:**
- Precision < 60%
- User approval rate < 40%
- Any unsafe code in approved skills

**Rollback Plan:**
- Disable feature flag: `--no-features skill-generation`
- Remove `xkit generate-skills` command from docs
- Delete `.claude/skills-review/` directory (preserve `.claude/skills/`)

### Go/No-Go Metrics (Phase 3: Learning Materials)
**Go Criteria:**
- [ ] Learning material completion rate â‰¥ 60% (A/B test)
- [ ] User satisfaction â‰¥ 3.5/5.0 (surveys)
- [ ] Generation time â‰¤ 5Ã— baseline

**No-Go Criteria:**
- Completion rate < 40%
- Satisfaction < 3.0/5.0
- Generation time > 10Ã— baseline

**Rollback Plan:**
- Disable feature flag: `--no-features learning-materials`
- Remove `xkit learn` command from docs
- Archive `~/.xkit/learning/` directory

---

## Post-Launch Monitoring Plan

### Metrics Dashboard (Optional - v2.0)
**Summary Metrics:**
- Summaries generated per day
- Average summary quality (user ratings)
- Persona/length usage distribution
- Cache hit rate

**Skill Metrics:**
- Skills generated per day
- Approval rate (review â†’ approved)
- Confidence distribution
- Category distribution

**Learning Material Metrics:**
- Materials generated per day
- Completion rate
- Satisfaction score
- Type distribution (study-guide vs flashcards vs quiz)

### Alerts
- **Critical:** Summary quality < 3.5/5.0 for 24 hours
- **Critical:** LLM error rate > 10% for 1 hour
- **Warning:** Cache hit rate < 40% for 7 days
- **Info:** Feature usage < 10% for 30 days

### User Feedback Loop
- In-app rating: "Rate this summary (1-5 stars)"
- Quarterly surveys: satisfaction, feature requests
- GitHub Issues: bug reports, feature requests

---

## Support / Ops Impact

### Runbooks

#### Troubleshooting Summarization
```bash
# Check Ollama status
xkit status

# Clear cache if stale
xkit cache --clear

# Force specific persona/length
xkit archive --summarize --persona technical-researcher --length long

# Enable debug logging
xkit archive --summarize --log-level debug

# Verify template syntax
xkit validate-templates
```

#### Troubleshooting Skill Generation
```bash
# List pending review skills
ls -la .claude/skills-review/

# Approve skill (manual)
mv .claude/skills-review/skill-name.md .claude/skills/

# Reject skill (manual)
rm .claude/skills-review/skill-name.md

# Adjust confidence threshold
xkit generate-skills --min-confidence 0.8
```

#### Troubleshooting Learning Materials
```bash
# List generated materials
ls -la ~/.xkit/learning/

# Regenerate material
xkit learn --generate study-guide --from "SwiftUI animations" --force

# Check difficulty level
xkit learn --generate flashcards --from "TypeScript" --difficulty intermediate
```

### Documentation
- CLI help: `xkit --help`, `xkit archive --help`
- Feature docs: `docs/enhanced-summarization.md`, `docs/skill-generation.md`, `docs/learning-materials.md`
- Template guide: `docs/custom-templates.md`
- Troubleshooting: `docs/troubleshooting.md`

### Support Channels
- GitHub Issues: bug reports, feature requests
- GitHub Discussions: usage questions, tips & tricks

---

## Compliance & Regulatory Review Triggers

### Data Privacy
- **PII in Bookmarks:** User bookmarks may contain personal data (names, emails, addresses)
- **Handling:** PII stored in plaintext, sent to LLM
- **Mitigation:**
  - Add `--redact-pii` flag (optional, uses NER to redact)
  - Document that LLM provider receives bookmark content
  - Add privacy notice to README

### Security
- **Prompt Injection:** Malicious bookmark content manipulates LLM
- **Handling:** XML tag escaping before prompt insertion
- **Mitigation:**
  - Penetration testing before GA
  - Bug bounty program (post-GA)

### Intellectual Property
- **Generated Skills:** May contain code from bookmarked repos
- **Handling:** Skills include reference to original bookmark
- **Mitigation:**
  - Add attribution to generated Skills
  - Document that users are responsible for license compliance

---

## Ownership & RACI

### Responsible (Implementer)
- **@jamiecraik:** Implementation, testing, documentation

### Accountable (Decision Maker)
- **@jamiecraik:** Final approval on all decisions

### Consulted (Subject Matter Experts)
- **Summarize Community:** Prompt engineering patterns (via GitHub issues/docs)
- **Claude Code Users:** Skill format validation (via Discord/GitHub)

### Informed (Stakeholders)
- **xKit Users:** Feature feedback, testing, validation

---

## Dependency SLAs & Vendor Risk

### Internal Dependencies
- **Ollama:** Local LLM runtime (no SLA, user-managed)
- **Node.js:** Runtime environment (LTS support: 18 months)
- **pnpm:** Package manager (community support)

### External Dependencies (Future - v2.0+)
- **OpenAI API:** 99.9% uptime SLA, rate limits apply
- **Anthropic API:** 99.9% uptime SLA, rate limits apply
- **Firecrawl:** 99.9% uptime SLA, pay-per-use

**Mitigation:**
- Default to local Ollama (no external dependencies)
- Fallback chain: Ollama â†’ OpenAI free â†’ paid models
- Circuit breaker: disable paid APIs if error rate > 10%

---

## Localization & Internationalization

### v1.0 Stance
- **Language:** English only
- **Rationale:** Validate demand in English-speaking market first
- **Future:** Multi-language support if international demand exists

### v2.0+ Considerations
- Language detection: Detect bookmark content language
- Multi-language templates: Translate personas and prompts
- Locale-specific formatting: Date/time, number formats

---

## Backward Compatibility & Deprecation

### Backward Compatibility
- **Existing CLI:** All existing flags work as before
- **New Flags:** Opt-in via `--summarize`, `--persona`, `--length`
- **Data Format:** Existing markdown files unchanged

### Deprecation Policy
- **Old Summarization:** Deprecate after 6 months of enhanced summarization GA
- **Notice:** Add deprecation notice to CLI help and docs
- **Grace Period:** 6 months (2 minor releases)
- **Removal:** Remove in v1.7.0 (if enhanced summarization GA in v1.0.0)

---

## Experimentation & Feature Flags

### Feature Flags
```bash
# Enable enhanced summarization (opt-in initially)
xkit archive --features enhanced-summarization --summarize

# Enable skill generation (conditional on user research)
xkit generate-skills --features skill-generation --category github

# Enable learning materials (conditional on user research)
xkit learn --features learning-materials --generate study-guide
```

### Rollout Plan
1. **Alpha:** Internal testing (@jamiecraik only)
2. **Beta:** Friendly users (n=5-10) with feature flags
3. **GA:** Feature flags removed, features enabled by default

### Kill Criteria
- **Enhanced Summarization:** If quality < 3.5/5.0 for 30 days, revert to legacy
- **Skill Generation:** If precision < 60% for 30 days, disable feature
- **Learning Materials:** If unused by 20% of users after 30 days, deprecate

---

## Kill Criteria

### Project Level
- **User Demand:** If < 20% of users adopt any enhanced features after 90 days, sunset project
- **Cost:** If LLM costs > $100/month with < 10% adoption, re-architect or sunset
- **Security:** If any critical vulnerability is exploited, halt all features until fixed

### Feature Level
- **Enhanced Summarization:** Kill if quality < 3.5/5.0 OR latency > 3Ã— baseline for 30 days
- **Skill Generation:** Kill if precision < 60% OR approval rate < 40% for 30 days
- **Learning Materials:** Kill if completion rate < 40% OR satisfaction < 3.0/5.0 for 30 days

---

## Decision Log / ADRs

### ADR-001: Use Tagged Prompt Structure from Summarize
**Date:** 2026-01-20
**Status:** Accepted
**Context:** Need proven prompt engineering pattern for engaging summaries
**Decision:** Adopt Summarize's XML-style tagged prompts (`<instructions>`, `<context>`, `<content>`)
**Rationale:**
- Battle-tested in production (Summarize has 200+ tests)
- Clear separation of concerns (instructions vs context vs content)
- Easy to extend with personas, lengths, content types
**Consequences:**
- Must implement prompt injection protection (XML tag escaping)
- Templates will be more verbose than simple prompts
**Alternatives Considered:**
- Simple text prompts: rejected (less structured, harder to maintain)
- JSON prompts: rejected (less human-readable)
**Revisit:** After 6 months of production use

### ADR-002: Default to Local Ollama vs Paid APIs
**Date:** 2026-01-20
**Status:** Accepted
**Context:** Need to choose LLM provider for summarization
**Decision:** Default to local Ollama with `nomic-embed-text`, support paid APIs via `--model` flag
**Rationale:**
- Zero cost for users
- Privacy (data never leaves machine)
- No rate limits
- Aligns with xKit's existing infrastructure
**Consequences:**
- Slower than paid APIs (acceptable for CLI workflow)
- Requires 8GB RAM (user hardware requirement)
**Alternatives Considered:**
- Default to OpenAI API: rejected (cost, privacy, rate limits)
- Hybrid (paid API first, Ollama fallback): rejected (cost, complexity)
**Revisit:** If users demand faster performance and are willing to pay

### ADR-003: Manual Approval Required for Skills
**Date:** 2026-01-20
**Status:** Accepted
**Context:** Skills contain executable code, must ensure safety
**Decision:** Write generated Skills to `.claude/skills-review/`, require manual approval before `.claude/skills/`
**Rationale:**
- Risk of hallucinated or unsafe code
- User trust critical for adoption
- Legal liability concerns
**Consequences:**
- Extra step in workflow (friction)
- May reduce Skills usage
**Alternatives Considered:**
- Auto-add to `.claude/skills/`: rejected (unsafe)
- No Skills feature: rejected (high user value)
**Revisit:** If confidence scoring improves to â‰¥ 95% precision

### ADR-004: SQLite Caching Before Features
**Date:** 2026-01-20
**Status:** Accepted
**Context:** Adversarial review identified 36 ERROR findings, no observability
**Decision:** Implement Phase 0 (caching, observability, security) before adding features
**Rationale:**
- Cannot measure success without observability
- Cannot ship safely without security foundations
- Summarize's cache eliminates 60%+ redundant API calls
**Consequences:**
- Delays feature delivery by 3 days
- Adds complexity to architecture
**Alternatives Considered:**
- Build features first, add foundations later: rejected (technical debt trap)
**Revisit:** After Phase 0 complete, reassess timeline

### ADR-005: User Research Before Skills/Learning Materials
**Date:** 2026-01-20
**Status:** Accepted
**Context:** No evidence users want Skills or learning materials (per adversarial review)
**Decision:** Add Phase 1A (3 days user research) before building Phases 2-3
**Rationale:**
- Risk building features nobody uses
- Low-cost investment (3 days) vs high-risk implementation (10+ days)
- Go/no-go criteria prevent wasted effort
**Consequences:**
- Delays feature delivery by 3 days
- May discover Skills/learning materials unwanted (kill features)
**Alternatives Considered:**
- Skip research, build anyway: rejected (high risk of waste)
**Revisit:** After user research complete

---

## References

- [Summarize Feature Analysis](.spec/spec-2026-01-20-summarize-feature-analysis.md)
- [Summarize Reconnaissance Report](/Users/jamiecraik/dev/recon-workbench/runs/summarize-session/derived/report.md)
- [Adversarial Review Output](/Users/jamiecraik/.claude/plans/adversarial-review-output.md)
- [xKit Repository](https://github.com/jscraik/xKit)
- [Summarize Repository](https://github.com/steipete/summarize)

---

## Appendix: Example Outputs

### Enhanced Summary (Persona: Technical Researcher, Length: Long)
```markdown
### Core Concepts: Type-Level Programming

TypeScript's type system extends beyond simple runtime type checking into a
Turing-complete language for compile-time computation. This enables powerful
abstractions like conditional types, mapped types, and template literal types
that can validate and transform data structures at compile time.

### Conditional Types: Dynamic Type Decisions

Conditional types serve as the fundamental control flow primitive in TypeScript's
type system. They enable type-level if/else decisions that can distribute unions,
extract properties, and enforce complex constraints. The syntax `T extends U ? X : Y`
mirrors ternary operators but operates entirely on types rather than values.

Practical applications include:
- API response validation (`FetchResponse<200>` vs `FetchResponse<500>`)
- Function overloads via type inference
- Exclude/Extract utility types under the hood

### Template Literal Types: Type-Safe Strings

Template literal types enable string manipulation at the type level, supporting
interpolation, unions, and pattern matching. This makes it possible to encode
event names (`"click_${ButtonID}"`), CSS selectors, or route patterns as types
that prevent invalid strings from even compiling.

[continues with detailed technical analysis]
```

### Generated Skill
```markdown
---
name: Implement Type-Safe API Response Validation
description: Validate API responses at compile time using conditional types
triggers:
  - User adds REST API integration
  - Type safety is critical for API contracts
category: code-pattern
---

# Implement Type-Safe API Response Validation

## When to Use This Skill
Use when integrating with REST APIs where:
- Response structure varies by status code
- Type safety is more important than runtime flexibility
- API contracts are stable or versioned

## Implementation

### Step 1: Define Response Types
```typescript
type ApiResponse<T, Code extends number> = {
  status: Code;
  data: T;
};

type SuccessResponse<T> = ApiResponse<T, 200>;
type ErrorResponse = ApiResponse<{ message: string }, 400 | 500>;
```

### Step 2: Create Fetch Wrapper
```typescript
async function fetchTyped<T>(
  url: string
): Promise<SuccessResponse<T> | ErrorResponse> {
  const response = await fetch(url);
  const data = await response.json();
  return { status: response.status, data };
}
```

### Step 3: Use with Type Guards
```typescript
const result = await fetchTyped<User>('/api/user/1');
if (result.status === 200) {
  // TypeScript knows result.data is User
  console.log(result.data.name);
} else {
  // TypeScript knows result.data is { message: string }
  console.error(result.data.message);
}
```

## Examples

### Example 1: User API
```typescript
interface User {
  id: number;
  name: string;
  email: string;
}

const result = await fetchTyped<User>('/api/user/1');
// TypeScript infers result as:
// SuccessResponse<User> | ErrorResponse
```

### Example 2: Search API with Union Responses
```typescript
type SearchResponse =
  | ApiResponse<{ results: User[] }, 200>
  | ApiResponse<{ error: string }, 400>
  | ApiResponse<never, 500>;

const search = await fetchTyped<SearchResponse>('/api/search?q=test');
// TypeScript handles all status codes
```

## Edge Cases

### Edge Case 1: Dynamic Status Codes
If status codes are dynamic (not known at compile time), use a more flexible type:
```typescript
type LooseApiResponse<T> = {
  status: number;
  data: T | null;
};
```

### Edge Case 2: Nested Discriminated Unions
For complex response structures, use discriminated unions recursively:
```typescript
type Response<T, E> =
  | { ok: true; data: T }
  | { ok: false; error: E };
```

## Common Pitfalls

1. **Over-constraining:** Don't use conditional types if status codes are dynamic
2. **Runtime validation:** Types don't validate at runtime, still need Zod/etc
3. **API changes:** Keep types in sync with API contracts
```

### Study Guide Excerpt
```markdown
# Study Guide: Advanced TypeScript Type System Patterns

## Learning Objectives
By the end of this guide, you will be able to:
- Design conditional types for dynamic type decisions
- Use template literal types for type-safe string manipulation
- Build type-level parsers and validators
- Apply mapped types and utility types in real-world scenarios

## Difficulty: Intermediate
**Prerequisites:**
- Familiarity with basic TypeScript types (interfaces, type aliases)
- Understanding of generics and type inference
- Experience with utility types (Partial, Required, Pick)

**Estimated Time:** 45 minutes

## Core Concepts

### Conditional Types
**Definition:** Type-level if/else statements that enable conditional type selection based on type relationships.

**Syntax:** `T extends U ? X : Y`

**How It Works:**
1. Check if type `T` extends type `U`
2. If true, return type `X`
3. If false, return type `Y`

**Example:**
```typescript
type IsArray<T> = T extends any[] ? true : false;

type Test1 = IsArray<number>; // false
type Test2 = IsArray<string[]>; // true
```

**Use Cases:**
- API response validation (different types for different status codes)
- Function overloads via type inference
- Exclude/Extract utility types

## Exercises

### Exercise 1: Build a NonNullable Utility Type
**Goal:** Create a utility type that removes `null` and `undefined` from a type.

**Hint:** Use conditional types with union types.

<details>
<summary>Solution</summary>

```typescript
type NonNullable<T> = T extends null | undefined ? never : T;

type Test = NonNullable<string | null | undefined>; // string
```
</details>

### Exercise 2: Build a Type Guard Helper
**Goal:** Create a type that extracts the return type of a function.

**Hint:** Use TypeScript's built-in `ReturnType` utility type as inspiration.

<details>
<summary>Solution</summary>

```typescript
type MyReturnType<T extends (...args: any) => any> = T extends (
  ...args: any
) => infer R
  ? R
  : any;

function foo() {
  return { x: 1, y: 2 };
}

type FooReturn = MyReturnType<typeof foo>; // { x: number; y: number }
```
</details>

## Flashcards

**Q1:** What is the syntax for conditional types?
**A1:** `T extends U ? X : Y`

**Q2:** How do you extract the type of a promise's resolved value?
**A2:** `T extends Promise<infer U> ? U : never`

**Q3:** What is a distributive conditional type?
**A3:** When a conditional type is applied to a union type, it distributes over each union member: `(A | B) extends C ? D : E` becomes `(A extends C ? D : E) | (B extends C ? D : E)`

## Next Steps
- Practice with [TypeScript Type Challenges](https://github.com/type-challenges/type-challenges)
- Explore mapped types and template literal types
- Build a type-level parser for a JSON schema
```

---

**Document Version:** 1.0
**Last Updated:** 2026-01-20
**Status:** Ready for user research

**Next Steps:**
1. Review and approve PRD
2. Conduct user research (Phase 1A, 3 days)
3. Implement Phase 0 (Foundation, 3 days)
4. Build Phase 1B (Enhanced Summarization, 4 days)
5. Evaluate go/no-go for Phases 2-3 based on research

---

## Standards Mapping

**Gold Industry Standard Compliance** (baseline: January 31, 2026)

- **Security:** Prompt injection protection, template validation, code review disclaimers
- **Testing:** User acceptance testing (n=30), manual audits (n=100), A/B testing
- **Documentation:** Comprehensive PRD, CLI help, feature docs, troubleshooting guides
- **Supply Chain:** pnpm lockfile, frozen-lockfile installs, dependency audits
- **Code Quality:** TypeScript strict mode, Biome linting, manual code reviews

**Checks Executed:**
- [x] Adversarial review (7 role-based passes, 36 ERROR findings addressed)
- [x] User research plan (n=10-15 interviews)
- [x] Security considerations (prompt injection, template validation, PII)
- [x] Performance targets (latency, throughput, resource usage)
- [x] Reliability targets (availability, error rate, data quality)
- [x] Cost model (local vs paid APIs, budget guardrails)

**Review Artifact:** Adversarial review conducted per product-spec skill requirements. All ERROR findings from review incorporated into revised plan with Phase 0 (Foundation), Phase 1A (User Research), and conditional Phases 2-3.

**Deviations/Risks:**
- **Deviation:** 11-day timeline deemed unrealistic by adversarial review. Revised to 23 days with user research and validation.
- **Risk:** User research may reveal low demand for Skills/learning materials. Mitigated with go/no-go criteria (â‰¥ 50% interest required).
- **Risk:** LLM hallucination in Skill extraction. Mitigated with confidence scoring, manual approval, two-stage validation.
- **Risk:** Prompt injection vulnerability. Mitigated with XML tag escaping, UUID delimiters, penetration testing.

---

**End of PRD + Technical Specification**


</PROJECT_MEMORY>

Exit protocol (required):
At the very end of your output, print exactly one line:
EXIT_SIGNAL: true  OR  EXIT_SIGNAL: false

