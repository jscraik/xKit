{
  "name": "runner",
  "argv": [
    "claude",
    "-p",
    "You are operating inside the Ralph Gold loop.\n\nRules:\n- Do exactly ONE task per iteration.\n- Use the Memory Files below as the source of truth (especially ANCHOR and any Repo Prompt context pack).\n- Make the smallest correct change-set that satisfies the task acceptance criteria.\n- When you finish the task, mark it done in the PRD tracker.\n- Do not mark tasks done if you did not run/confirm the configured gates pass locally.\n- If you are blocked, record a clear reason (including commands + errors) in .ralph/progress.md and leave the task open.\n\n## File writing authority (CRITICAL)\n- **You are authorized to write code directly.** Create and modify files without asking for permission.\n- **Do not stop and request approval.** You are autonomous\u2014complete the full implementation.\n- **Implement the entire solution** in one iteration. Don't design and then wait\u2014design AND implement.\n- Your task acceptance criteria are your complete authority to proceed with file changes.\n\nWorkflow:\n1) Read Memory Files in order.\n2) Re-state the task acceptance criteria.\n3) Implement completely (write all necessary files).\n4) Run the repo's gates (see .ralph/AGENTS.md) and fix failures.\n5) Update PRD + progress.\n\nOutput:\n- Prefer concise, factual updates.\n- If you ran commands, include the command and 1-3 lines of the most relevant output.\n\n<ANCHOR>\n# Ralph Gold Anchor\n\nTask: 13 - Add `moveFileWithTimeout()` to `scripts/migration/lib/files.ts`\n\nAcceptance criteria:\n- Use `Promise.race()` with 5 second timeout\n- Copy file first, verify size matches, then delete source\n- Throw timeout error if stuck\n- Test: Manual verify with test files\n\nRepo reality:\n- branch: main\n- git status --porcelain:\n```\nM .ralph/PRD.md\n M .ralph/progress.md\n?? .ralph/archive/20260120-190753/\n?? .ralph/attempts/\n?? .ralph/context/\n?? .ralph/logs/\n?? .ralph/permissions.json\n?? .ralph/receipts/\n?? .ralph/state.json\n```\n- git diff --stat:\n```\n.ralph/PRD.md      | 10 +++++-----\n .ralph/progress.md | 25 +++++++++++++++++++++++++\n 2 files changed, 30 insertions(+), 5 deletions(-)\n```\n\nConstraints:\n- Work on exactly ONE task per iteration\n- Do not claim completion without passing gates\n- Prefer minimal diffs; keep repo clean\n</ANCHOR>\n\n## Orchestrator Addendum (auto-generated)\nIteration: 36\n\nHard iteration constraints:\n- One task per iteration (one commit per iteration).\n- Apply backpressure: run the commands in AGENTS.md and fix until they pass.\n\nSelected task for this iteration:\n- id: 13\n- title: Add `moveFileWithTimeout()` to `scripts/migration/lib/files.ts`\n- acceptance:\n  - Use `Promise.race()` with 5 second timeout\n  - Copy file first, verify size matches, then delete source\n  - Throw timeout error if stuck\n  - Test: Manual verify with test files\n\nDo not work on any other task in this iteration.\n\n<PROJECT_MEMORY>\n## .ralph/AGENTS.md\n# Ralph Gold Agents & Gates\n\nThis file is read by Ralph Gold each iteration.\n\n## Gates (backpressure)\n\nRalph Gold will run gates *after* the agent makes changes. Configure them in `.ralph/ralph.toml`.\n\nRecommended patterns:\n\n### Option A (recommended): `prek` as the universal gate runner\n\n- Put your quality contract in `.pre-commit-config.yaml`\n- Then enable the gate:\n  - `[gates.prek] enabled = true` (runs `prek run --all-files`)\n\nNo git hooks are installed by Ralph Gold.\n\n### Option B: Explicit commands\n\nExamples:\n- `uv run ruff check .`\n- `uv run mypy src`\n- `uv run pytest -q`\n- `npm test`\n\n## Review gate (cross-model)\n\nOptionally enable `[gates.review]` to require a reviewer model to return `SHIP`.\n\n## Notes\n\n- Receipts are written under `.ralph/receipts/` each iteration.\n- Repo Prompt context packs (if enabled) are written under `.ralph/context/`.\n\n\n## .ralph/PRD.md\n# Knowledge Reorganization PRD\n\n## Overview\n\nReorganize the xKit knowledge base from category-first (`year/month/category/@handle/file.md`) to author-first structure (`year/month/@handle (real name)/category/file.md`) with enhanced filenames including date, handle, category, title, and short ID. Includes comprehensive migration tooling with atomic operations, automated rollback, degraded mode support, and full observability.\n\n**Tech Spec:** `.spec/tech-spec-2026-01-20-knowledge-reorganization.md`\n\n## Task Breakdown Guidelines\n\n**CRITICAL:** Tasks must be atomic (5-15 minutes each) with specific acceptance criteria and test commands.\n\n## Tasks\n\n### Phase 1: Core Types\n\n- [-] Create `src/bookmark-organization/types.ts` file\n  - Add `AuthorFolder`, `KnowledgePath`, `FilenameComponents` interfaces\n  - Add `RealNameCache`, `MigrationState`, `MigrationError` interfaces\n  - Add `MigrationFailureMarker`, `PreflightCheck` interfaces\n  - Export all types\n  - Test: `pnpm test -- src/bookmark-organization/types.test.ts` passes\n\n- [x] Add `sanitizeAuthorName()` to `src/bookmark-organization/sanitize.ts`\n  - ASCII-only handle validation (`/^[A-Za-z0-9_]+$/`)\n  - Reserved Windows filename check (CON, PRN, AUX, NUL, COM1-9, LPT1-9)\n  - Real name sanitization (control chars, Unicode NFC, dangerous chars)\n  - Limit real name to 100 chars\n  - Return `@handle` or `@handle (Real Name)`\n  - Test: `pnpm test -- src/bookmark-organization/sanitize.test.ts` passes\n\n- [x] Add `sanitizeSlug()` to `src/bookmark-organization/sanitize.ts`\n  - Pre-check for path traversal (`/\\.\\.[\\/\\\\]/`)\n  - Remove control characters, normalize Unicode to NFC\n  - Replace non-alphanumerics with hyphens\n  - Limit to 80 chars\n  - Test: `pnpm test -- src/bookmark-organization/sanitize.test.ts` passes\n\n### Phase 2: Real Name Cache\n\n- [x] Add real name cache functions to `src/bookmark-organization/cache.ts`\n  - `loadRealNameCache()`: load from `.real-name-cache.json` or create new\n  - `saveRealNameCache()`: write cache with timestamp\n  - `getRealName()`: lookup handle in cache\n  - `setRealName()`: add or update cache entry\n  - Test: `pnpm test -- src/bookmark-organization/cache.test.ts` passes\n\n### Phase 3: Filename Generation\n\n- [x] Add `generateEnhancedFilename()` to `src/bookmark-markdown/filename.ts`\n  - Format: `{date}-{handle}-{category}-{title}-{short_id}.md`\n  - Use linked content title or tweet text excerpt\n  - Mandatory short ID (last 6 chars of tweet ID)\n  - Limit total filename to 255 chars\n  - Test: `pnpm test -- src/bookmark-markdown/filename.test.ts` passes\n\n- [x] Add `validatePathLength()` to `src/bookmark-markdown/filename.ts`\n  - Check path length \u2264 240 chars (Windows safe)\n  - Throw error with path preview if exceeded\n  - Test: `pnpm test -- src/bookmark-markdown/filename.test.ts` passes\n\n- [x] Update `MarkdownWriter.generateFilename()` in `src/bookmark-markdown/writer.ts`\n  - Call `generateEnhancedFilename()` instead of old method\n  - Note: writer.test.ts does not exist yet; filename.test.ts passes\n\n### Phase 4: Disk Space & Pre-flight\n\n- [-] Add `getDirectorySize()` to `scripts/migration/lib/disk.ts`\n  - Recursively scan directory and sum file sizes\n  - Return total bytes\n  - Test: Manual verify with known test directory\n\n- [-] Add `checkDiskSpace()` to `scripts/migration/lib/disk.ts`\n  - Use `statvfs` to get available space (Unix)\n  - Require 2.5x directory size (original + backup + margin)\n  - Throw error if insufficient with GB amounts\n  - Fallback for Windows (skip check with warning)\n  - Test: Manual verify with small directory\n\n- [-] Add `preFlightChecks()` to `scripts/migration/lib/check.ts`\n  - Call `getDirectorySize()` and `checkDiskSpace()`\n  - Count files to migrate\n  - Log summary and throw if checks fail\n  - Return `PreflightCheck` result\n  - Test: Manual verify on `knowledge/` directory\n\n### Phase 5: Migration Script Core\n\n- [-] Create `scripts/migrate-to-author-first.mjs` CLI scaffold\n  - Parse arguments: --dry-run, --backup-dir, --resume, --verify, --verbose, --force, --help\n  - Set up logging to `migration.log`\n  - Exit codes: 0=success, 1=errors, 2=validation failed, 3=cancelled\n  - Test: `node scripts/migrate-to-author-first.mjs --help` shows usage\n\n- [-] Add dry-run mode to `scripts/migrate-to-author-first.mjs`\n  - Scan all files in `knowledge/`\n  - Calculate new paths for all files\n  - Print summary: file counts, new structure example, backup location\n  - Prompt for confirmation: \"Continue? [y/N]\"\n  - Exit if not 'y'\n  - Test: `node scripts/migrate-to-author-first.mjs --dry-run` shows plan\n\n### Phase 6: File Operations with Timeout\n\n- [ ] Add `moveFileWithTimeout()` to `scripts/migration/lib/files.ts`\n  - Use `Promise.race()` with 5 second timeout\n  - Copy file first, verify size matches, then delete source\n  - Throw timeout error if stuck\n  - Test: Manual verify with test files\n\n### Phase 7: Checkpoint & Recovery\n\n- [ ] Add checkpoint system to `scripts/migration/lib/checkpoint.ts`\n  - `writeCheckpoint()`: write state to `.migration-state.json` every 100 files\n  - `resumeFromCheckpoint()`: load checkpoint state\n  - Track: migrationId, timestamps, files processed, processed files list\n  - Test: Manual interrupt and resume\n\n- [ ] Add SIGINT handler to `scripts/migrate-to-author-first.mjs`\n  - Catch Ctrl+C, write checkpoint, exit gracefully\n  - Print message: \"Migration paused. Run with --resume to continue.\"\n  - Test: Manual Ctrl+C during migration\n\n### Phase 8: Migration Execution\n\n- [ ] Add main migration logic to `scripts/migrate-to-author-first.mjs`\n  - For each file: calculate new path, create author folder, create category folder\n  - Call `moveFileWithTimeout()` for each file\n  - Write checkpoint every 100 files\n  - Show progress: `[=====>] 45% (382/847) | 234 files/sec`\n  - Log each move to `migration.log`\n  - Track errors (recoverable) and continue\n  - Test: `node scripts/migrate-to-author-first.mjs --dry-run` on sample data\n\n### Phase 9: Checksum Verification\n\n- [ ] Add checksum functions to `scripts/migration/lib/checksum.ts`\n  - `checksum()`: compute SHA-256 hash of file\n  - `verifyBackup()`: compare all files between original and backup\n  - Return summary with mismatches list\n  - Test: Manual verify with test directory\n\n### Phase 10: Backup & Rollback\n\n- [ ] Add backup creation to `scripts/migrate-to-author-first.mjs`\n  - Copy entire `knowledge/` to `knowledge_backup_<timestamp>/`\n  - Run `verifyBackup()` after copy\n  - Throw if verification fails\n  - Test: `node scripts/migrate-to-author-first.mjs --dry-run` creates backup\n\n- [ ] Create `scripts/rollback-migration.mjs`\n  - Parse --backup-dir and --verify flags\n  - Validate backup exists\n  - Create backup of current state\n  - Delete `knowledge/`, copy backup to `knowledge/`\n  - Revert code changes if needed\n  - Run build and verify\n  - Test: Manual rollback after test migration\n\n### Phase 11: Concurrency Locking\n\n- [ ] Add lock file functions to `src/bookmark-markdown/lock.ts`\n  - `createMigrationLock()`: write `.migration-lock` with migration ID and timestamp\n  - `checkMigrationLock()`: return true if lock exists\n  - `clearMigrationLock()`: remove lock file\n  - Test: `pnpm test -- src/bookmark-markdown/lock.test.ts` passes\n\n- [ ] Update bookmark archiving to check for migration lock\n  - In archiving entry point, call `checkMigrationLock()`\n  - If locked, print warning and exit (pause archiving)\n  - Test: Manual verify lock pauses archiving\n\n### Phase 12: Degraded Mode\n\n- [ ] Add degraded mode functions to `scripts/migration/lib/degraded.ts`\n  - `markMigrationFailed()`: write `.migration-failed` marker with error\n  - `isDegradedMode()`: check if marker exists\n  - `getOutputDirectory()`: return `knowledge_degraded/` if failed\n  - `clearDegradedMode()`: remove marker\n  - Test: Manual verify degraded mode activation\n\n- [ ] Update `MarkdownWriter` constructor to use degraded output\n  - Call `isDegradedMode()` on init\n  - If degraded, set `outputDir` to `knowledge_degraded/`\n  - Print warning message\n  - Test: Manual verify degraded mode writes to fallback\n\n- [ ] Add degraded mode handling to `scripts/migrate-to-author-first.mjs`\n  - On any error, call `markMigrationFailed()`\n  - Exit with error code 1\n  - On success, call `clearDegradedMode()`\n  - Test: Manual error triggers degraded mode\n\n### Phase 13: Package Scripts & Docs\n\n- [ ] Add npm scripts to `package.json`\n  - `\"migrate-knowledge\": \"node scripts/migrate-to-author-first.mjs\"`\n  - `\"migrate-knowledge:dry-run\": \"node scripts/migrate-to-author-first.mjs --dry-run\"`\n  - `\"rollback-knowledge\": \"node scripts/rollback-migration.mjs\"`\n  - Test: `pnpm migrate-knowledge --help` works\n\n- [ ] Add migration documentation to `docs/KNOWLEDGE_MIGRATION.md`\n  - Overview of new structure\n  - Migration instructions\n  - Rollback instructions\n  - Troubleshooting guide\n  - Test: Documentation is clear and complete\n\n### Phase 14: Testing & Validation\n\n- [ ] Add migration tests to `tests/migration.test.ts`\n  - Test dry-run on sample data\n  - Test checkpoint creation and resume\n  - Test degraded mode activation\n  - Test lock file handling\n  - Test: `pnpm test -- tests/migration.test.ts` passes\n\n- [ ] Run full migration test on backup\n  - Copy `knowledge/` to test location\n  - Run full migration\n  - Verify all files moved correctly\n  - Verify checksums match\n  - Test rollback restores correctly\n  - Test: Manual end-to-end validation\n\n## Acceptance Criteria\n\n- [ ] All existing files migrated without data loss\n- [ ] New bookmarks use author-first structure with enhanced filenames\n- [ ] Build succeeds with no broken links (`pnpm build`)\n- [ ] Migration script has dry-run mode with detailed output\n- [ ] Automated rollback script tested and documented\n- [ ] Comprehensive path sanitization implemented (ASCII-only handles)\n- [ ] Checksum verification before/after migration\n- [ ] Checkpoint/resume capability functional\n- [ ] CLI interface with all specified flags\n- [ ] Confirmation flow (dry-run \u2192 prompt \u2192 execute)\n- [ ] Migration logging to `migration.log`\n- [ ] Progress indicator during migration\n- [ ] Concurrency handling (pause with lock file)\n- [ ] Path length validation (fail fast if >240 chars)\n- [ ] ID suffix mandatory in filename generation\n- [ ] TypeScript types defined for all new structures\n- [ ] Real name cache format defined\n- [ ] Disk space check implemented\n- [ ] Per-file timeout implemented (5 second default)\n- [ ] Degraded mode functional (fallback to `knowledge_degraded/`)\n\n## Notes\n\n- Mark done: - [x]\n- Mark blocked: - [-]\n- Dependencies: add acceptance bullet like \"- Depends on: 1, 2\"\n\n\n## .ralph/progress.md\n# progress.md\n\nAppend-only loop memory.\nKeep entries short; delete nothing; add clarifications when you learn.\n\n---\n- [20260120T213526Z] iter 23 mode=prd status=CONTINUE checks=PASS story=S8 agent=claude branch=main log=20260120T213526Z-iter0023-claude.log\n[2026-01-20T21:39:17.716658+00:00] BLOCKED task 8 (Add `getDirectorySize()` to `scripts/migration/lib/disk.ts`) after 3 attempts: unknown\n- [20260120T213917Z] iter 24 mode=prd status=CONTINUE checks=PASS story=S9 agent=claude branch=main log=20260120T213917Z-iter0024-claude.log\n- [20260120T214243Z] iter 25 mode=prd status=CONTINUE checks=PASS story=S9 agent=claude branch=main log=20260120T214243Z-iter0025-claude.log\n- [20260120T214718Z] iter 26 mode=prd status=CONTINUE checks=PASS story=S9 agent=claude branch=main log=20260120T214718Z-iter0026-claude.log\n[2026-01-20T21:51:49.894771+00:00] BLOCKED task 9 (Add `checkDiskSpace()` to `scripts/migration/lib/disk.ts`) after 3 attempts: runner failed\n- [20260120T215149Z] iter 27 mode=prd status=CONTINUE checks=PASS story=S10 agent=claude branch=main log=20260120T215149Z-iter0027-claude.log\n- [20260120T215351Z] iter 28 mode=prd status=CONTINUE checks=PASS story=S10 agent=claude branch=main log=20260120T215351Z-iter0028-claude.log\n- [20260120T215652Z] iter 29 mode=prd status=CONTINUE checks=PASS story=S10 agent=claude branch=main log=20260120T215652Z-iter0029-claude.log\n[2026-01-20T22:01:23.452309+00:00] BLOCKED task 10 (Add `preFlightChecks()` to `scripts/migration/lib/check.ts`) after 3 attempts: runner failed\n- [20260120T220123Z] iter 30 mode=prd status=CONTINUE checks=PASS story=S11 agent=claude branch=main log=20260120T220123Z-iter0030-claude.log\n- [20260120T220425Z] iter 31 mode=prd status=CONTINUE checks=PASS story=S11 agent=claude branch=main log=20260120T220425Z-iter0031-claude.log\n- [20260120T220717Z] iter 31 mode=prd status=CONTINUE checks=PASS story=S11 agent=claude branch=main log=20260120T220717Z-iter0031-claude.log\n- [20260120T220758Z] iter 32 mode=prd status=CONTINUE checks=PASS story=S11 agent=claude branch=main log=20260120T220758Z-iter0032-claude.log\n[2026-01-20T22:14:30.302333+00:00] BLOCKED task 11 (Create `scripts/migrate-to-author-first.mjs` CLI scaffold) after 3 attempts: unknown\n- [20260120T221148Z] iter 32 mode=prd status=CONTINUE checks=PASS story=S11 agent=claude branch=main log=20260120T221148Z-iter0032-claude.log\n[2026-01-20T22:14:47.135984+00:00] BLOCKED task 11 (Create `scripts/migrate-to-author-first.mjs` CLI scaffold) after 3 attempts: unknown\n- [20260120T221430Z] iter 33 mode=prd status=CONTINUE checks=PASS story=S12 agent=claude branch=main log=20260120T221430Z-iter0033-claude.log\n- [20260120T221447Z] iter 33 mode=prd status=CONTINUE checks=PASS story=S12 agent=claude branch=main log=20260120T221447Z-iter0033-claude.log\n- [20260120T221731Z] iter 34 mode=prd status=CONTINUE checks=PASS story=S12 agent=claude branch=main log=20260120T221731Z-iter0034-claude.log\n- [20260120T221748Z] iter 34 mode=prd status=CONTINUE checks=PASS story=S12 agent=claude branch=main log=20260120T221748Z-iter0034-claude.log\n- [20260120T222202Z] iter 35 mode=prd status=CONTINUE checks=PASS story=S12 agent=claude branch=main log=20260120T222202Z-iter0035-claude.log\n[2026-01-20T22:27:35.579304+00:00] BLOCKED task 12 (Add dry-run mode to `scripts/migrate-to-author-first.mjs`) after 3 attempts: unknown\n- [20260120T222219Z] iter 35 mode=prd status=CONTINUE checks=PASS story=S12 agent=claude branch=main log=20260120T222219Z-iter0035-claude.log\n[2026-01-20T22:28:57.557815+00:00] BLOCKED task 12 (Add dry-run mode to `scripts/migrate-to-author-first.mjs`) after 3 attempts: unknown\n\n\n## .ralph/FEEDBACK.md\n# Feedback (optional)\n\nThis file is read by Ralph Gold each iteration.\n\nUse it to add temporary guidance for the next iteration (constraints, clarifications, links, etc.).\n\nDelete entries when no longer needed.\n\n\n## .spec/spec-2025-01-19-smaug-feature-port.md\n```yaml\nschema_version: 1\nspec_type: prd\nspec_id: SPEC-2025-001\ntitle: \"Smaug \u2192 xKit Performance & Cost Optimization Features\"\nstatus: finalized\ncreated: \"2025-01-19\"\nlast_updated: \"2025-01-19\"\n```\n\n# PRD: Smaug \u2192 xKit Performance & Cost Optimization Features\n\n## Executive Summary\n\nxKit v0.7.0 is a comprehensive Twitter bookmark archiving system with most core features implemented. However, it processes bookmarks **sequentially**, causing performance issues at scale. This PRD ports three high-value features from Smaug (a similar bookmark archiver) to address documented limitations in xKit:\n\n1. **Token Usage Tracking** - Track and display LLM API costs with detailed breakdown\n2. **Parallel Processing Architecture** - Process bookmarks concurrently using worker pools\n3. **Model Cost Optimization** - Route tasks to appropriate model tiers (fast/balanced/quality)\n\n**Business Impact:** Reduces archive processing time by 2-4x for 100+ bookmarks, provides cost transparency for cloud LLM usage, and optimizes LLM spend by ~30% through smart model routing.\n\n**Evidence Source:** Smaug codebase analysis shows parallel subagent processing achieves 2-4x speedup with ~50% cost savings via Haiku model usage for simple tasks.\n\n---\n\n## Inputs\n\n### Source Materials\n- Smaug codebase analysis (parallel processing architecture)\n- xKit v0.7.0 codebase review\n- LIMITATIONS.md (lines 134-142 document sequential processing bottleneck)\n- Existing xKit modules: `bookmark-analysis/`, `bookmark-stats/`, `commands/bookmarks-archive.ts`\n\n### Constraints\n- Must maintain xKit's privacy-first design (local-first, opt-in cloud)\n- Must not introduce breaking changes to existing CLI interface\n- Must work with existing LLM providers (Ollama, OpenAI, Anthropic)\n- Must follow xKit's TypeScript/Node.js architecture\n\n### Assumptions\n1. Users primarily process 50-500 bookmarks per session\n2. LLM API usage is primarily for categorization and summarization\n3. Users want cost transparency before running expensive operations\n4. Parallel processing speedup justifies added complexity\n5. Model tier routing can maintain acceptable quality while reducing costs\n\n---\n\n## Outputs\n\n### Deliverables\n1. **Token tracking module** (`src/bookmark-analysis/token-tracker.ts`)\n2. **Parallel processing engine** (`src/bookmark-analysis/parallel-processor.ts`)\n3. **Model tier router** (`src/bookmark-analysis/model-router.ts`)\n4. **Updated CLI commands** with new flags\n5. **Updated documentation** with performance benchmarks\n\n### Success Metrics\n\n**Measurement Methodology:** All benchmarks run on M1 MacBook Pro (8GB RAM), macOS 14.0, stable 100Mbps network, n=10 trials per metric, results reported as mean \u00b1 95% confidence interval.\n\n- [ ] Token tracking displays accurate API costs within \u00b15% of actual billing (validated against API provider billing statements)\n- [ ] Parallel processing achieves 2.5\u00b10.5x speedup for 100 bookmarks (baseline: 180s sequential \u2192 target: <72s parallel)\n- [ ] Output ordering is guaranteed (processed bookmarks maintain input order, verified with deterministic test data)\n- [ ] Memory usage stays within bounds (< 1.5GB peak for 1000 bookmarks, measured via Node.js `process.memoryUsage()`)\n- [ ] Model optimization reduces costs by 28\u00b13% for equivalent quality (measured via manual quality assessment on 100-bookmark sample)\n- [ ] No increase in error rate vs sequential processing (target: <2% error rate for both modes)\n\n---\n\n## Problem Statement\n\n### Current Pain Points\n\n**As documented in LIMITATIONS.md:134-142:**\n> \"Archive command processes bookmarks sequentially, not in parallel. Large archives (1000+ bookmarks) can take hours with AI summarization. No resume capability if interrupted mid-run.\"\n\n**User Impact:**\n- **Performance:** Processing 500 bookmarks with AI summarization takes 2-3 hours\n- **Cost Blindness:** Users have no visibility into LLM API costs before running\n- **Inefficiency:** Expensive models (Sonnet, GPT-4) used for simple categorization tasks\n- **Poor UX:** No progress indication during long-running operations\n\n### Technical Debt\n1. **Sequential Processing Loop** (`bookmarks-archive.ts:196`): `enrichBatch` processes bookmarks one-at-a-time\n2. **No Token Tracking**: LLM clients (`llm-categorizer.ts`) don't track usage or costs\n3. **Single Model Strategy**: All tasks use the same model regardless of complexity\n\n---\n\n## Solution Overview\n\n### Three-Phase Implementation\n\n```mermaid\ngantt\n    title Implementation Timeline\n    dateFormat  YYYY-MM-DD\n    section Phase 1\n    Token Tracking           :p1, 2025-01-20, 2d\n    section Phase 2\n    Parallel Processing      :p2, after p1, 5d\n    section Phase 3\n    Model Optimization       :p3, after p2, 3d\n```\n\n### Phase 1: Token Usage Tracking (Priority 1)\n\n**What:** Track and display LLM API costs with detailed breakdown\n\n**How:**\n- Create `TokenTracker` class to count tokens before/after each LLM call\n- Calculate cost based on model pricing (OpenAI, Anthropic, Ollama=$0)\n- Aggregate by operation type (categorization, summarization, analysis)\n- Display usage report at end of archive run\n\n**Example Output:**\n```\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\ud83d\udcca TOKEN USAGE\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nAnthropic (claude-3-haiku-20240307):\n  Input:            12,345 tokens  $0.012\n  Output:            3,456 tokens  $0.017\n  Cache Read:       10,000 tokens  $0.000\n  Cache Write:       2,000 tokens  $0.000\n\nOpenAI (gpt-4o):\n  Input:            25,000 tokens  $0.250\n  Output:            5,000 tokens  $0.150\n\nOllama (llama3.2):\n  Input:           100,000 tokens  $0.000 (local)\n  Output:           20,000 tokens  $0.000 (local)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\ud83d\udcb0 TOTAL ESTIMATED COST: $0.429\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n```\n\n### Phase 2: Parallel Processing Architecture (Priority 2)\n\n**What:** Process bookmarks concurrently using worker thread pools\n\n**How:**\n- Create `ParallelProcessor` class with configurable worker pool\n- Use Node.js `worker_threads` for CPU-bound LLM tasks\n- Use async batching for I/O-bound HTTP requests\n- Preserve ordering with sequence IDs for reassembly\n- Add `--parallel` flag to archive command (default: off)\n\n**Configuration:**\n```typescript\ninterface ParallelConfig {\n  enabled: boolean;\n  concurrency: number;      // Default: 4-8 workers\n  threshold: number;        // Minimum bookmarks to enable (default: 50)\n  batchSize: number;        // Items per worker batch (default: 10)\n}\n```\n\n**Architecture:**\n```mermaid\nflowchart TD\n    A[Input Bookmarks] --> B{Parallel Enabled?}\n    B -->|No| C[Sequential Processing]\n    B -->|Yes| D[Worker Pool]\n    D --> E1[Worker 1]\n    D --> E2[Worker 2]\n    D --> E3[Worker N]\n    E1 --> F[Result Queue]\n    E2 --> F\n    E3 --> F\n    F --> G[Ordering Guarantee]\n    G --> H[Output Bookmarks]\n    C --> H\n```\n\n### Phase 3: Model Cost Optimization (Priority 3)\n\n**What:** Route tasks to appropriate model tiers based on complexity\n\n**How:**\n- Define model tiers (fast/balanced/quality) with cost/quality tradeoffs\n- Route categorization \u2192 fast model (Haiku/GPT-4o-mini)\n- Route summarization \u2192 balanced model (Sonnet/GPT-4o)\n- Route complex analysis \u2192 quality model (Opus/GPT-4)\n- Add fallback mechanism if premium model fails\n\n**Model Tier Configuration:**\n```typescript\ninterface ModelTier {\n  name: 'fast' | 'balanced' | 'quality';\n  model: string;\n  maxTokens: number;\n  costPerMillion: { input: number; output: number };\n  useCase: string[];\n}\n\ninterface ModelStrategy {\n  categorization: 'fast';\n  summarization: 'balanced';\n  analysis: 'quality';\n}\n```\n\n**Cost Comparison:**\n| Operation | Current (Sonnet) | Optimized (Haiku) | Savings |\n|-----------|-----------------|-------------------|---------|\n| Categorization | $0.25 | $0.012 | ~95% |\n| Summarization | $0.25 | $0.25 | 0% |\n| Analysis | $0.25 | $0.25 | 0% |\n| **Total** | $0.75 | $0.512 | ~30% |\n\n---\n\n## User Personas\n\n### Persona 1: Alex, Research Analyst\n**Role:** Senior researcher at tech think tank\n**Goals:**\n- Archive 500+ bookmarks monthly for literature review\n- Minimize processing time to meet publication deadlines\n- Control costs within monthly research budget ($200)\n\n**Pain Points:**\n- Current archiving takes 3+ hours for large batches\n- No visibility into LLM costs before running\n- Manual categorization is time-consuming\n\n**Technical Proficiency:** High (comfortable with CLI, config files)\n\n**Typical Volume:** 200-1000 bookmarks per session\n\n---\n\n### Persona 2: Jordan, Casual User\n**Role:** Software developer bookmarking for later reference\n**Goals:**\n- Quick archival of 20-50 bookmarks weekly\n- Minimal setup and configuration\n- Avoid unexpected API charges\n\n**Pain Points:**\n- Long-running operations block workflow\n- Confused by parallel processing terminology\n- Worried about accidentally running up large bills\n\n**Technical Proficiency:** Medium (can follow docs, prefers defaults)\n\n**Typical Volume:** 20-100 bookmarks per session\n\n---\n\n### Persona 3: Sam, Power User\n**Role:** Data scientist building personal knowledge base\n**Goals:**\n- Archive 2000+ bookmarks across multiple sessions\n- Fine-grained control over processing parameters\n- Detailed cost and performance analytics\n\n**Pain Points:**\n- Sequential processing doesn't scale to thousands of bookmarks\n- Can't tune worker pool for hardware (32GB RAM, 12 cores)\n- Wants to optimize model selection per task type\n\n**Technical Proficiency:** Expert (contributes to open source, reads source code)\n\n**Typical Volume:** 500-5000 bookmarks per session\n\n---\n\n### Persona 4: Casey, Budget-Conscious Student\n**Role:** Graduate student on limited budget\n**Goals:**\n- Use free/local LLM (Ollama) exclusively\n- Occasional cloud LLM for complex analysis only\n- Zero unexpected costs\n\n**Pain Points:**\n- Worried about accidentally using paid API\n- Needs clear cost warnings before expensive operations\n- Wants cheapest options that still work well\n\n**Technical Proficiency:** Low-Medium (can run commands, but not debug)\n\n**Typical Volume:** 50-200 bookmarks per session\n\n---\n\n## User Stories\n\n### STORY-001: Token Usage Visibility\n**As a** power user who processes hundreds of bookmarks\n**I want** to see estimated LLM API costs before and after archiving\n**So that** I can budget for cloud LLM usage and avoid surprise charges\n\n**Acceptance Criteria:**\n- [ ] Token counts displayed after each LLM operation\n- [ ] Cost estimate shown before processing begins (based on sample)\n- [ ] Detailed breakdown by model and operation type\n- [ ] Ollama/local LLM shows $0.00 cost\n- [ ] Currency formatted to 3 decimal places\n- [ ] Cache read/write tokens tracked separately (Anthropic)\n\n### STORY-002: Parallel Processing Speedup\n**As a** user with 500+ bookmarks to archive\n**I want** to process bookmarks in parallel\n**So that** archiving completes in minutes instead of hours\n\n**Acceptance Criteria:**\n- [ ] `--parallel` flag enables parallel processing\n- [ ] Parallel mode only activates above threshold (default: 50 bookmarks)\n- [ ] Progress bar shows concurrent worker activity\n- [ ] Output maintains original bookmark order\n- [ ] Error in one worker doesn't crash entire batch\n- [ ] Memory usage stays below 2GB for 1000 bookmarks\n\n### STORY-003: Configurable Concurrency\n**As a** user with limited RAM or API rate limits\n**I want** to control worker pool size\n**So that** I can tune performance for my hardware and API constraints\n\n**Acceptance Criteria:**\n- [ ] `--parallel-workers <n>` flag sets concurrency (default: 4)\n- [ ] `--parallel-threshold <n>` flag sets minimum bookmarks (default: 50)\n- [ ] Config validated (min: 1, max: 16 workers)\n- [ ] Warning shown if worker count exceeds CPU cores\n- [ ] Rate limiting respected across all workers\n\n### STORY-004: Smart Model Routing\n**As a** cost-conscious user\n**I want** simple categorization tasks to use cheaper models\n**So that** I can reduce LLM costs without sacrificing quality\n\n**Acceptance Criteria:**\n- [ ] Categorization uses fast model by default\n- [ ] Summarization uses balanced model by default\n- [ ] User can override model tier per operation\n- [ ] Fallback to balanced model if fast model fails\n- [ ] Quality degradation logged when fallback occurs\n\n### STORY-005: Cost Comparison Report\n**As a** developer optimizing archiving workflows\n**I want** to compare costs between different model strategies\n**So that** I can make informed tradeoffs between cost and quality\n\n**Acceptance Criteria:**\n- [ ] `--cost-report` flag generates before/after comparison\n- [ ] Shows projected cost for each model tier strategy\n- [ ] Estimates quality impact (low/medium/high)\n- [ ] Saves report to JSON for analysis\n- [ ] Historical cost tracking across multiple runs\n\n---\n\n## Scope\n\n### In Scope\n- Token usage tracking for all LLM providers (OpenAI, Anthropic, Ollama)\n- Parallel processing for bookmark enrichment and categorization\n- Model tier routing for categorization and summarization\n- CLI flag extensions to existing commands\n- Progress reporting for parallel operations\n- Error handling and graceful degradation\n\n### Out of Scope\n- Parallel processing for Twitter API calls (existing rate limiting sufficient)\n- Resume/checkpoint functionality (separate feature, Phase 4)\n- New LLM provider integrations beyond existing three\n- GPU acceleration for local LLMs\n- Distributed processing across multiple machines\n- Real-time cost monitoring during processing (only before/after)\n- Automatic model selection based on content complexity (manual tier assignment only)\n\n### Feature Creep Guardrails\n\n**Decision Record:**\n1. **No GPU acceleration** - Requires significant infrastructure, out of scope for performance optimization\n2. **No distributed processing** - Adds operational complexity, local parallel processing sufficient\n3. **No automatic model selection** - Would require content analysis overhead, manual tier routing more predictable\n4. **No real-time cost tracking** - Would require streaming responses, adds latency\n\n**Scope Decision Log:**\n| Date | Decision | Rationale | Who |\n|------|----------|-----------|-----|\n| 2025-01-19 | Exclude resume/checkpoint | Separate feature, adds state management complexity | Product |\n| 2025-01-19 | Exclude new LLM providers | Existing three sufficient for optimization | Engineering |\n\n---\n\n## Technical Architecture\n\n### Component Architecture\n\n```mermaid\nflowchart TB\n    subgraph \"Existing xKit\"\n        A[Archive Command]\n        B[Enricher]\n        C[LLM Categorizer]\n        D[Stats Tracker]\n    end\n\n    subgraph \"New: Phase 1\"\n        E[Token Tracker]\n    end\n\n    subgraph \"New: Phase 2\"\n        F[Parallel Processor]\n        G[Worker Pool]\n    end\n\n    subgraph \"New: Phase 3\"\n        H[Model Router]\n        I[Model Tier Config]\n    end\n\n    A --> B\n    A --> C\n    A --> D\n    B --> E\n    C --> E\n    F --> G\n    F --> B\n    F --> C\n    H --> C\n    I --> H\n```\n\n### Data Models\n\n**Token Tracking:**\n```typescript\ninterface TokenUsage {\n  input: number;\n  output: number;\n  cacheRead: number;\n  cacheWrite: number;\n  cost: number;\n}\n\ninterface UsageReport {\n  byModel: Record<string, TokenUsage>;\n  byOperation: Record<string, TokenUsage>;\n  total: TokenUsage;\n}\n\ninterface TokenTracker {\n  record(operation: string, model: string, usage: TokenUsage): void;\n  getReport(): UsageReport;\n  formatReport(): string;\n}\n```\n\n**Parallel Processing:**\n```typescript\ninterface ParallelConfig {\n  enabled: boolean;\n  concurrency: number;\n  threshold: number;\n  batchSize: number;\n}\n\ninterface WorkItem {\n  id: string;\n  sequence: number;\n  bookmark: BookmarkRecord;\n}\n\ninterface WorkResult {\n  id: string;\n  sequence: number;\n  result: EnrichedBookmarkRecord;\n  error?: Error;\n}\n\ninterface ParallelProcessor {\n  process(items: WorkItem[]): Promise<WorkResult[]>;\n}\n```\n\n**Model Routing:**\n```typescript\ninterface ModelTier {\n  name: 'fast' | 'balanced' | 'quality';\n  model: string;\n  maxTokens: number;\n  costPerMillion: { input: number; output: number };\n  useCase: string[];\n}\n\ninterface ModelStrategy {\n  categorization: 'fast' | 'balanced' | 'quality';\n  summarization: 'fast' | 'balanced' | 'quality';\n  analysis: 'fast' | 'balanced' | 'quality';\n}\n\ninterface ModelRouter {\n  route(operation: string): string;\n  withFallback(operation: string, tiers: string[]): Promise<string>;\n}\n```\n\n### API Design\n\n**New CLI Flags:**\n```bash\n# Token tracking (always active with LLM)\nxkit archive --summarize\n\n# Parallel processing\nxkit archive --all --parallel\nxkit archive --all --parallel --parallel-workers 8\nxkit archive --all --parallel --parallel-threshold 100\n\n# Model optimization\nxkit archive --model-strategy balanced\nxkit archive --model-tier fast:summarization\n\n# Cost comparison\nxkit archive --cost-report\n```\n\n**Configuration File:**\n```json\n{\n  \"llm\": {\n    \"strategy\": \"optimized\",\n    \"tiers\": {\n      \"fast\": {\n        \"categorization\": \"claude-3-haiku-20240307\",\n        \"summarization\": \"gpt-4o-mini\"\n      },\n      \"balanced\": {\n        \"categorization\": \"claude-3-5-sonnet-20241022\",\n        \"summarization\": \"gpt-4o\"\n      },\n      \"quality\": {\n        \"categorization\": \"claude-3-opus-20240229\",\n        \"summarization\": \"gpt-4-turbo\"\n      }\n    }\n  },\n  \"parallel\": {\n    \"enabled\": false,\n    \"workers\": 4,\n    \"threshold\": 50\n  }\n}\n```\n\n---\n\n## Internal API Contracts\n\n### TokenTracker Module\n\n**Interface Definition:**\n```typescript\n/**\n * TokenTracker - Tracks LLM API usage and costs\n *\n * @example\n * const tracker = new TokenTracker();\n * tracker.record('categorization', 'claude-3-haiku-20240307', {\n *   input: 1000,\n *   output: 200,\n *   cacheRead: 0,\n *   cacheWrite: 0,\n *   cost: 0.0025\n * });\n */\nexport class TokenTracker {\n  /**\n   * Record token usage for an LLM operation\n   * @param operation - Operation type (categorization, summarization, analysis)\n   * @param model - Model identifier (e.g., 'claude-3-haiku-20240307')\n   * @param usage - Token counts and cost\n   * @throws {Error} if usage counts are negative\n   */\n  record(operation: string, model: string, usage: TokenUsage): void;\n\n  /**\n   * Get aggregated usage report\n   * @returns Usage report broken down by model and operation\n   */\n  getReport(): UsageReport;\n\n  /**\n   * Format usage report as human-readable string\n   * @returns Formatted string suitable for terminal output\n   */\n  formatReport(): string;\n\n  /**\n   * Reset all tracking data (useful for testing)\n   */\n  reset(): void;\n}\n```\n\n### ParallelProcessor Module\n\n**Interface Definition:**\n```typescript\n/**\n * ParallelProcessor - Processes bookmarks concurrently using worker pool\n *\n * @example\n * const processor = new ParallelProcessor({ concurrency: 4, threshold: 50 });\n * const results = await processor.process(workItems);\n */\nexport class ParallelProcessor {\n  /**\n   * Create a new parallel processor\n   * @param config - Configuration options\n   * @throws {RangeError} if concurrency < 1 or > 16\n   * @throws {RangeError} if threshold < 1\n   */\n  constructor(config: ParallelConfig);\n\n  /**\n   * Process work items concurrently\n   * @param items - Array of work items with sequence IDs\n   * @returns Promise resolving to results in original order\n   * @throws {Error} if worker pool fails to initialize\n   */\n  process(items: WorkItem[]): Promise<WorkResult[]>;\n\n  /**\n   * Get current worker pool statistics\n   * @returns Statistics including active workers, queue size, processed count\n   */\n  getStats(): WorkerPoolStats;\n\n  /**\n   * Abort all in-progress work\n   * @throws {Error} if abort fails\n   */\n  abort(): Promise<void>;\n}\n```\n\n### ModelRouter Module\n\n**Interface Definition:**\n```typescript\n/**\n * ModelRouter - Routes tasks to appropriate model tiers\n *\n * @example\n * const router = new ModelRouter(strategy);\n * const model = router.route('categorization'); // Returns 'claude-3-haiku-20240307'\n */\nexport class ModelRouter {\n  /**\n   * Create a new model router\n   * @param strategy - Model tier strategy mapping\n   * @throws {Error} if strategy references undefined models\n   */\n  constructor(strategy: ModelStrategy);\n\n  /**\n   * Get the appropriate model for an operation\n   * @param operation - Operation type (categorization, summarization, analysis)\n   * @returns Model identifier string\n   * @throws {Error} if operation type not recognized\n   */\n  route(operation: string): string;\n\n  /**\n   * Get model with fallback chain\n   * @param operation - Operation type\n   * @param tiers - Ordered list of tier names to try\n   * @returns Model identifier that succeeded\n   * @throws {Error} if all tiers fail\n   */\n  async withFallback(operation: string, tiers: string[]): Promise<string>;\n\n  /**\n   * Update model strategy\n   * @param strategy - New strategy configuration\n   */\n  configure(strategy: ModelStrategy): void;\n}\n```\n\n---\n\n## Error Codes and Handling\n\n### Error Code Constants\n\n```typescript\n/**\n * Error codes for xKit parallel processing and token tracking\n */\nexport const ErrorCodes = {\n  // Token Tracker Errors (TOKEN_XXX)\n  TOKEN_INVALID_COUNT: 'TOKEN_001',\n  TOKEN_NEGATIVE_COUNT: 'TOKEN_002',\n  TOKEN_MISSING_MODEL: 'TOKEN_003',\n\n  // Parallel Processor Errors (PARALLEL_XXX)\n  PARALLEL_WORKER_EXHAUSTION: 'PARALLEL_001',\n  PARALLEL_INIT_FAILED: 'PARALLEL_002',\n  PARALLEL_ABORT_FAILED: 'PARALLEL_003',\n  PARALLEL_SEQUENCE_MISMATCH: 'PARALLEL_004',\n\n  // Model Router Errors (MODEL_XXX)\n  MODEL_UNKNOWN_OPERATION: 'MODEL_001',\n  MODEL_ALL_TIERS_FAILED: 'MODEL_002',\n  MODEL_FALLBACK_TRIGGERED: 'MODEL_003',\n  MODEL_CONFIG_INVALID: 'MODEL_004',\n\n  // Configuration Errors (CONFIG_XXX)\n  CONFIG_INVALID_WORKERS: 'CONFIG_001',\n  CONFIG_INVALID_THRESHOLD: 'CONFIG_002',\n  CONFIG_MISSING_API_KEY: 'CONFIG_003',\n} as const;\n```\n\n### Error Messages and User Actions\n\n| Error Code | Message | User Action |\n|------------|---------|-------------|\n| TOKEN_001 | Invalid token count received from API | Check network connection, retry |\n| TOKEN_002 | Negative token count detected | Report bug on GitHub |\n| PARALLEL_001 | Worker pool exhausted | Reduce `--parallel-workers` or wait for completion |\n| PARALLEL_002 | Failed to initialize worker pool | Check available memory, reduce worker count |\n| MODEL_002 | All model tiers failed | Check API keys, network connection |\n| MODEL_003 | Model fallback triggered (warning) | Check logs for quality degradation |\n| CONFIG_001 | Worker count must be 1-16 | Use valid value for `--parallel-workers` |\n\n---\n\n## Concurrency Control\n\n### Worker Pool Lifecycle\n\n```mermaid\nstateDiagram-v2\n    [*] --> IDLE: Processor created\n    IDLE --> INITIALIZING: process() called\n    INITIALIZING --> READY: Workers spawned\n    INITIALIZING --> ERROR: Spawn failed\n    READY --> PROCESSING: Work items queued\n    PROCESSING --> PROCESSING: Workers active\n    PROCESSING --> DRAINING: Queue empty, workers finishing\n    DRAINING --> READY: All workers complete\n    READY --> IDLE: No more work\n    PROCESSING --> ERROR: Worker crashed\n    ERROR --> IDLE: Error handled, workers terminated\n    IDLE --> [*]: Processor destroyed\n```\n\n### Thread Safety Guarantees\n\n**Shared State Protection:**\n- Token tracker uses atomic counters for thread-safe updates\n- Result queue uses mutex for ordered insertion\n- Worker pool state protected by mutex\n\n**Data Integrity:**\n- Each bookmark processed exactly once (work item idempotency)\n- Sequence IDs unique and monotonic (assigned at queue time)\n- No duplicate entries in output (result set deduplication)\n\n### Memory Limits\n\n**Boundaries:**\n- Worker queue: Max 1000 items (backpressure beyond this)\n- Result buffer: Max 1000 items (blocks if full)\n- Token history: Max 10,000 entries (LRU eviction)\n\n**Overflow Behavior:**\n- Queue full: Block producer until space available\n- Result buffer full: Block worker until space available\n- Token history full: Evict oldest entry\n\n---\n\n## Retry Strategy and Circuit Breaker\n\n### Retry Configuration\n\n```typescript\ninterface RetryConfig {\n  maxAttempts: number;        // Default: 3\n  initialDelayMs: number;     // Default: 1000\n  maxDelayMs: number;         // Default: 10000\n  backoffMultiplier: number;  // Default: 2.0\n  retryableErrors: string[];  // Error codes to retry\n}\n\nconst defaultRetryConfig: RetryConfig = {\n  maxAttempts: 3,\n  initialDelayMs: 1000,\n  maxDelayMs: 10000,\n  backoffMultiplier: 2.0,\n  retryableErrors: [\n    'ECONNRESET',\n    'ETIMEDOUT',\n    'ESOCKETTIMEDOUT',\n    'HTTP_429',  // Rate limit\n    'HTTP_500',  // Server error\n    'HTTP_502',  // Bad gateway\n    'HTTP_503',  // Service unavailable\n    'HTTP_504',  // Gateway timeout\n  ],\n};\n```\n\n### Circuit Breaker Pattern\n\n```typescript\ninterface CircuitBreakerConfig {\n  failureThreshold: number;   // Open circuit after N failures\n  successThreshold: number;   // Close circuit after N successes\n  timeoutMs: number;          // Time before attempting reset\n  halfOpenMaxCalls: number;   // Max calls in half-open state\n}\n\nconst defaultCircuitBreakerConfig: CircuitBreakerConfig = {\n  failureThreshold: 5,        // Open after 5 consecutive failures\n  successThreshold: 2,        // Close after 2 consecutive successes\n  timeoutMs: 60000,           // Try reset after 60 seconds\n  halfOpenMaxCalls: 3,        // Allow 3 test calls in half-open\n};\n```\n\n**Circuit Breaker States:**\n```mermaid\nstateDiagram-v2\n    [*] --> CLOSED: Initial state\n    CLOSED --> OPEN: Failure threshold reached\n    OPEN --> HALF_OPEN: Timeout elapsed\n    HALF_OPEN --> CLOSED: Success threshold reached\n    HALF_OPEN --> OPEN: Failure occurred\n    HALF_OPEN --> CLOSED: Max calls reached (all successful)\n```\n\n---\n\n## SLOs and Error Budget Policy\n\n### Service Level Objectives\n\n**Parallel Processing:**\n- **Success Rate:** \u226598% (target: 99%, minimum: 98%)\n- **Latency:** P95 < 90s for 100 bookmarks (vs 225s sequential)\n- **Memory:** Peak < 1.5GB for 1000 bookmarks\n- **Error Budget:** 2% of requests allowed to fail\n\n**Token Tracking:**\n- **Accuracy:** \u00b15% of actual API billing\n- **Availability:** 100% (local only, no remote deps)\n- **Latency:** < 100ms per report generation\n\n**Model Routing:**\n- **Fallback Rate:** < 5% of requests trigger fallback\n- **Fallback Latency:** < 5s additional when fallback triggers\n\n### Error Budget Policy\n\n**Calculation:**\n- Error budget = 100% - success rate target = 100% - 98% = 2%\n- Budget period: Weekly (rolling 7-day window)\n- Budget reset: Weekly\n\n**Burn Rate Triggers:**\n- **Warning:** Error rate > 1.5% for 1 hour\n- **Critical:** Error rate > 2% for 15 minutes\n- **Emergency:** Error rate > 5% for 5 minutes\n\n**Actions on Burn:**\n- **Warning:** Alert engineering team, investigate\n- **Critical:** Halt rollout, revert to sequential processing\n- **Emergency:** Disable feature entirely, incident postmortem\n\n---\n\n## Input Validation\n\n### Parameter Bounds\n\n| Parameter | Min | Max | Default | Validation |\n|-----------|-----|-----|---------|------------|\n| `--parallel-workers` | 1 | 16 | 4 | Must be integer, \u2264 CPU cores warning |\n| `--parallel-threshold` | 1 | 10000 | 50 | Must be positive integer |\n| `--batch-size` | 1 | 100 | 10 | Must be positive integer |\n| `--max-retries` | 0 | 10 | 3 | Must be non-negative integer |\n| Model tier name | - | - | - | Must be defined in config |\n\n### Sanitization\n\n**User Inputs:**\n- Worker count: Parse as integer, validate bounds\n- Threshold: Parse as integer, validate bounds\n- Model names: Whitelist against defined tiers\n- API keys: Validate format, never log or display\n\n**Injection Prevention:**\n- Model tier config: JSON schema validation\n- File paths: Resolve to absolute, validate within workspace\n- URLs: Validate against allowed domains\n\n---\n\n## Secrets Handling Policy\n\n**Never Log or Display:**\n- API keys (any LLM provider)\n- Request/response bodies (may contain sensitive content)\n- User cookie tokens\n- File paths containing user info\n\n**May Log:**\n- Token counts (input/output only)\n- Cost calculations (aggregates only)\n- Model names (provider-specified identifiers)\n- Operation types (categorization, summarization, etc.)\n\n**Redaction Rules:**\n- Replace API keys with `[REDACTED]`\n- Replace request bodies with `[BODY OMITTED]`\n- Replace file paths with `[PATH]` or user home only\n\n---\n\n## Cost Calculations (Updated)\n\n**Pricing as of 2025-01-19:**\n\n| Provider | Model | Input (per 1M) | Output (per 1M) | Cache Read (per 1M) |\n|----------|-------|---------------|----------------|-------------------|\n| Anthropic | claude-3-haiku-20240307 | $0.25 | $1.25 | $0.03 |\n| Anthropic | claude-3-5-sonnet-20241022 | $3.00 | $15.00 | $0.30 |\n| Anthropic | claude-3-opus-20240229 | $15.00 | $75.00 | $1.50 |\n| OpenAI | gpt-4o-mini | $0.15 | $0.60 | N/A |\n| OpenAI | gpt-4o | $2.50 | $10.00 | N/A |\n| OpenAI | gpt-4-turbo | $10.00 | $30.00 | N/A |\n| Ollama | Any | $0.00 | $0.00 | N/A |\n\n**Cost Calculation Example (500 bookmarks):**\n\n**Before Optimization (all Sonnet):**\n- Categorization: 500 \u00d7 250 input tokens \u00d7 50 output tokens\n  - Input: 125,000 tokens = $0.375\n  - Output: 25,000 tokens = $0.375\n- Summarization: 500 \u00d7 500 input tokens \u00d7 200 output tokens\n  - Input: 250,000 tokens = $0.75\n  - Output: 100,000 tokens = $1.50\n- **Total: $3.00**\n\n**After Optimization (Haiku categorization, Sonnet summarization):**\n- Categorization: 500 \u00d7 250 \u00d7 50 (Haiku)\n  - Input: 125,000 tokens = $0.031\n  - Output: 25,000 tokens = $0.031\n- Summarization: 500 \u00d7 500 \u00d7 200 (Sonnet)\n  - Input: 250,000 tokens = $0.75\n  - Output: 100,000 tokens = $1.50\n- **Total: $2.312 (23% savings)**\n\n---\n\n## Go/No-Go Decision Framework\n\n### Phase 2 (Parallel Processing) Go/No-Go\n\n| Metric | Threshold | Owner | Decision |\n|--------|-----------|-------|----------|\n| Speedup | \u22652x for 100 bookmarks | Engineering | [ ] Go [ ] No-Go |\n| Error Rate | <5% increase vs sequential | QA | [ ] Go [ ] No-Go |\n| Memory | <2GB for 1000 bookmarks | Engineering | [ ] Go [ ] No-Go |\n| Test Coverage | >80% for new modules | QA | [ ] Go [ ] No-Go |\n| Documentation | Complete with examples | Tech Writing | [ ] Go [ ] No-Go |\n\n**Decision Date:** 2025-01-27 (after Phase 2 completion)\n**Decision Owner:** Product Lead\n**Fallback:** Revert to sequential processing, extend timeline by 1 sprint\n\n### Phase 3 (Model Optimization) Go/No-Go\n\n| Metric | Threshold | Owner | Decision |\n|--------|-----------|-------|----------|\n| Cost Savings | \u226525% vs baseline | Product | [ ] Go [ ] No-Go |\n| Quality Degradation | <15% user reports | Product | [ ] Go [ ] No-Go |\n| Fallback Rate | <10% of requests | Engineering | [ ] Go [ ] No-Go |\n| Cost Accuracy | \u00b110% of estimates | Engineering | [ ] Go [ ] No-Go |\n\n**Decision Date:** 2025-01-30 (after Phase 3 completion)\n**Decision Owner:** Product Lead\n**Fallback:** Disable model routing, use single model strategy\n\n---\n\n## Terminal UX Design\n\n### Progress Bar (Parallel Processing)\n\n**Design:**\n```\nProcessing 500 bookmarks with 4 workers...\n[\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591] 75% (375/500) | Workers: \u2588\u2588\u2588\u2588 | ETA: 45s\n  Worker 1: [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588] Complete (125/125)\n  Worker 2: [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591] Processing (94/125)\n  Worker 3: [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591] Processing (94/125)\n  Worker 4: [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591] Processing (62/125)\n```\n\n**States:**\n- **Sequential:** Single progress bar\n- **Parallel:** Main bar + per-worker breakdown\n- **Complete:** All bars at 100%, checkmarks\n\n### Empty States\n\n**No Bookmarks:**\n```\nNo bookmarks to process.\n\n\ud83d\udca1 Tip: Use `xkit bookmarks list` to see available bookmarks,\nor `xkit bookmarks fetch` to retrieve new ones.\n```\n\n**Parallel Below Threshold:**\n```\n\u26a0\ufe0f  Parallel mode enabled but only 12 bookmarks (threshold: 50).\n\nProcessing sequentially. Use `--parallel-threshold 10` to force parallel.\n```\n\n**Zero Cost (Local LLM):**\n```\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\ud83d\udcca TOKEN USAGE\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nOllama (llama3.2):\n  Input:          125,000 tokens  $0.00 (local LLM)\n  Output:          25,000 tokens  $0.00 (local LLM)\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\ud83d\udcb0 TOTAL ESTIMATED COST: $0.00 (local LLM, no API charges)\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n```\n\n---\n\n## Competitive Analysis\n\n### Feature Comparison\n\n| Feature | xKit (After) | Raindrop.io | Pocket | Pinboard | Smaug |\n|---------|--------------|-------------|--------|----------|-------|\n| Twitter Native | \u2705 | \u274c | \u274c | \u274c | \u2705 |\n| Local-First | \u2705 | \u274c | \u274c | \u274c | \u2705 |\n| Parallel Processing | \u2705 | \u2705 | \u2705 | \u274c | \u2705 |\n| Token Tracking | \u2705 | \u274c | \u274c | \u274c | \u2705 |\n| Model Optimization | \u2705 | \u274c | \u274c | \u274c | \u2705 |\n| Free Local LLM | \u2705 | \u274c | \u274c | \u274c | \u274c |\n| Self-Hostable | \u2705 | \u274c | \u274c | \u274c | \u274c |\n\n**Differentiation:**\n- Only self-hostable, local-first Twitter bookmark archiver\n- Only one with token tracking and model optimization\n- Only one supporting both local and cloud LLMs\n\n---\n\n## Risks and Mitigations\n\n### Technical Risks\n\n| Risk | Impact | Probability | Mitigation | Owner |\n|------|--------|-------------|------------|-------|\n| Worker thread overhead increases memory | Medium | Medium | Only enable above threshold; limit max workers; add memory monitoring | Engineering |\n| Output ordering broken in parallel mode | High | Low | Use sequence IDs; deterministic reassembly; comprehensive ordering tests | Engineering |\n| Rate limit exceeded with concurrent requests | Medium | Medium | Implement exponential backoff; queue management; per-worker rate limits | Engineering |\n| Token counting inaccurate | Medium | Low | Cross-check with API billing; log discrepancies; use official tokenizers | Engineering |\n| Model fallback degrades quality | Medium | Low | Log all fallbacks; user opt-in; quality comparison report | Product |\n\n### Product Risks\n\n| Risk | Impact | Probability | Mitigation | Owner |\n|------|--------|-------------|------------|-------|\n| Users don't trust cost estimates | Medium | Low | Show disclaimer; actual costs may vary; link to billing | Product |\n| Parallel processing too complex for average user | Low | Medium | Sensible defaults; feature flag off by default; clear docs | Product |\n| Model tier routing reduces quality perception | Medium | Low | Quality report; user control; opt-in for optimization | Product |\n\n### Operational Risks\n\n| Risk | Impact | Probability | Mitigation | Owner |\n|------|--------|-------------|------------|-------|\n| Increased support burden | Low | Low | Comprehensive docs; FAQ; example configs | Support |\n| CI/CD pipeline slowdown | Low | Low | Skip parallel mode in tests; mock LLM calls | Engineering |\n\n---\n\n## Acceptance Criteria\n\n### Top-Level\n\n- [ ] All three phases implemented and tested\n- [ ] No breaking changes to existing CLI interface\n- [ ] Documentation updated with new flags and examples\n- [ ] Performance benchmarks show 2-4x speedup for 100+ bookmarks\n- [ ] Token tracking accurate within 5% of actual API costs\n- [ ] Memory usage < 2GB for 1000 bookmarks in parallel mode\n- [ ] All existing tests pass\n- [ ] New test coverage > 80% for new modules\n\n### Phase-Specific\n\n**Phase 1: Token Tracking**\n- [ ] TokenTracker class implemented with `record`, `getReport`, `formatReport`\n- [ ] Integrated into LLMCategorizer and OllamaClient\n- [ ] Usage report displayed after archive command\n- [ ] Support for cache read/write tokens (Anthropic)\n- [ ] Cost calculations validated against actual API billing\n\n**Phase 2: Parallel Processing**\n- [ ] ParallelProcessor class with worker pool\n- [ ] `--parallel` flag added to archive command\n- [ ] `--parallel-workers` and `--parallel-threshold` flags\n- [ ] Ordering guarantee with sequence IDs\n- [ ] Error isolation (one worker failure doesn't crash batch)\n- [ ] Progress reporting for concurrent operations\n\n**Phase 3: Model Optimization**\n- [ ] ModelRouter class with tier configuration\n- [ ] Default strategy: fast=categorization, balanced=summarization\n- [ ] `--model-strategy` and `--model-tier` flags\n- [ ] Fallback mechanism with logging\n- [ ] Cost comparison report with `--cost-report`\n\n---\n\n## Data Lifecycle & Retention\n\n### Token Usage Data\n- **Storage:** In-memory only during processing\n- **Persistence:** Optional JSON export via `--save-token-report`\n- **Retention:** Not retained by default (privacy-first)\n- **Deletion:** Automatic on process exit\n\n### Processing State\n- **Storage:** Existing StateManager for processed bookmark IDs\n- **Persistence:** JSON file in `~/.xkit/state.json`\n- **Retention:** Indefinite (user can delete)\n- **Deletion:** `xkit state --clear` command\n\n### Configuration\n- **Storage:** Optional JSON file in project root or `~/.xkit/config.json`\n- **Persistence:** User-controlled\n- **Retention:** Indefinite\n- **Deletion:** Manual file deletion\n\n---\n\n## Post-Launch Monitoring Plan\n\n### Metrics to Track\n\n**Performance Metrics:**\n- Average processing time per bookmark (sequential vs parallel)\n- Memory usage during parallel processing\n- Worker utilization rate\n- Error rate by operation type\n\n**Cost Metrics:**\n- Actual vs estimated token costs\n- Cost savings by model tier\n- Cache hit rate (Anthropic)\n\n**Quality Metrics:**\n- Model fallback frequency\n- User-reported quality issues\n- Categorization accuracy (optional user feedback)\n\n### Monitoring Windows\n- **Week 1-2:** Daily monitoring of all metrics\n- **Week 3-4:** Weekly monitoring\n- **Month 2+:** Monthly review\n\n### Owners\n- **Performance:** Engineering Lead\n- **Cost:** Product Lead\n- **Quality:** Product Lead\n\n---\n\n## Launch & Rollout Guardrails\n\n### Phased Rollout\n\n**Phase 1 (Token Tracking):**\n- **Feature:** Always active with LLM usage\n- **Risk:** Low (observability only)\n- **Rollout:** Immediate release to all users\n- **Go/No-Go Metrics:** No regressions in existing functionality\n\n**Phase 2 (Parallel Processing):**\n- **Feature:** Opt-in via `--parallel` flag\n- **Risk:** Medium (new execution model)\n- **Rollout:**\n  - Week 1: Beta testers only\n  - Week 2: Early adopters via documentation\n  - Week 3: General availability (flag still off by default)\n  - Week 4: Consider default-on based on evidence\n- **Go/No-Go Metrics:**\n  - < 5% error rate in parallel mode\n  - > 2x speedup for 100+ bookmarks\n  - No memory leaks or crashes\n\n**Phase 3 (Model Optimization):**\n- **Feature:** Opt-in via `--model-strategy` flag\n- **Risk:** Low (user-controlled)\n- **Rollout:** Same as Phase 2\n- **Go/No-Go Metrics:**\n  - > 25% cost savings\n  - < 10% quality degradation reports\n\n### Rollback Plan\n\n**Phase 1:** No rollback needed (observability only)\n\n**Phase 2:**\n- Revert to sequential processing: `--parallel=false`\n- Hotfix release to disable feature flag\n- Communication via GitHub Issues and README\n\n**Phase 3:**\n- Revert to single model: `--model-strategy legacy`\n- Hotfix release to disable tier routing\n- Communication via GitHub Issues and README\n\n### Kill Criteria\n\nKill feature development if:\n- Parallel processing shows < 1.5x speedup after optimization\n- Memory usage exceeds 4GB for 1000 bookmarks\n- Error rate in parallel mode > 10%\n- User quality degradation reports > 20% for model optimization\n\n---\n\n## Support & Ops Impact\n\n### Documentation Requirements\n\n**User Documentation:**\n- Token tracking explanation in README\n- Parallel processing guide with benchmarks\n- Model tier configuration reference\n- Cost comparison examples\n\n**Developer Documentation:**\n- Architecture decision records (ADRs)\n- Code comments for worker pool logic\n- Token counting implementation notes\n\n### Runbook Updates\n\n**New Troubleshooting Sections:**\n- \"Parallel processing slower than sequential\"\n- \"Token counts don't match API billing\"\n- \"Model fallback occurring frequently\"\n- \"Memory usage too high in parallel mode\"\n\n### Training\n\n**Support Team:**\n- 1-hour training on new features\n- FAQ document for common issues\n- Escalation path for complex issues\n\n---\n\n## Compliance & Regulatory Review Triggers\n\n### Data Privacy\n- **Trigger:** Token tracking processes user content\n- **Review:** Ensure no sensitive content logged or transmitted\n- **Mitigation:** Only token counts and costs tracked, not content\n\n### Cost Transparency\n- **Trigger:** Estimated costs shown to users\n- **Review:** Ensure disclaimer that estimates may vary\n- **Mitigation:** Clear messaging: \"Estimated cost, actual may vary\"\n\n---\n\n## Ownership & RACI\n\n| Role | Name | Responsibilities |\n|------|------|------------------|\n| **Product Owner** | TBD | Requirements, prioritization, go/no-go decisions |\n| **Engineering Lead** | TBD | Architecture, implementation, code review |\n| **QA Lead** | TBD | Test strategy, validation, sign-off |\n| **Doc Owner** | TBD | Documentation, examples, runbooks |\n| **Support Lead** | TBD | Training, FAQ, user support |\n\n---\n\n## Security & Privacy Classification\n\n**Classification:** Low Risk\n\n**Rationale:**\n- Token tracking: Only counts and costs, no content\n- Parallel processing: Local execution, no new data transmission\n- Model optimization: No new data exposure\n\n**Security Considerations:**\n- API keys still stored securely (existing mechanism)\n- No new attack surface for parallel processing (local workers)\n- Model tier config validation to prevent injection\n\n---\n\n## Dependency SLAs & Vendor Risk\n\n### External Dependencies\n\n**Existing (No Change):**\n- OpenAI API: Existing SLA, no new risk\n- Anthropic API: Existing SLA, no new risk\n- Ollama: Local only, no SLA\n\n**New Internal Dependencies:**\n- Node.js `worker_threads`: Built-in, stable, no SLA risk\n- No new npm packages planned\n\n### Vendor Risk Mitigation\n- Multiple provider support already implemented\n- Fallback mechanism for model tier routing\n- Graceful degradation if parallel processing fails\n\n---\n\n## Cost Model & Budget Guardrails\n\n### Development Cost Estimate\n\n| Phase | Effort | Cost (at $150/hr) |\n|-------|--------|-------------------|\n| Phase 1: Token Tracking | 2 days | $2,400 |\n| Phase 2: Parallel Processing | 5 days | $6,000 |\n| Phase 3: Model Optimization | 3 days | $3,600 |\n| **Total** | **10 days** | **$12,000** |\n\n### User Cost Impact\n\n**Before Optimization:**\n- 500 bookmarks \u00d7 categorization (Sonnet): $0.25\n- 500 bookmarks \u00d7 summarization (Sonnet): $0.25\n- **Total: $250 per archive run**\n\n**After Optimization:**\n- 500 bookmarks \u00d7 categorization (Haiku): $0.012\n- 500 bookmarks \u00d7 summarization (Sonnet): $0.25\n- **Total: $131 per archive run (48% savings)**\n\n### Budget Guardrails\n- No additional infrastructure costs (local processing)\n- API costs are user-controlled (opt-in for cloud LLM)\n- Development budget: $12,000 one-time\n\n---\n\n## Localization & Internationalization\n\n**Status:** Not applicable (CLI tool, English-only)\n\n**Future Consideration:**\n- Token cost reports could support currency conversion\n- Error messages could be localized (low priority)\n\n---\n\n## Backward Compatibility & Deprecation\n\n### Compatibility\n\n**Breaking Changes:** None\n\n**New Features:** All opt-in via flags\n- `--parallel` (default: false)\n- `--model-strategy` (default: legacy)\n- Token tracking (always active, no behavior change)\n\n**Deprecations:** None\n\n**Migration Path:** None required (seamless upgrade)\n\n---\n\n## Experimentation & Feature Flags\n\n### Feature Flags\n\n**Phase 2 (Parallel Processing):**\n- **Flag:** `XKIT_PARALLEL_ENABLED`\n- **Default:** `false`\n- **Rollout:** Gradual based on evidence\n\n**Phase 3 (Model Optimization):**\n- **Flag:** `XKIT_MODEL_OPTIMIZATION_ENABLED`\n- **Default:** `false`\n- **Rollout:** Gradual based on evidence\n\n### A/B Testing (Optional)\n\n**Test Idea:** Compare sequential vs parallel processing performance\n- **Metric:** Processing time, error rate, memory usage\n- **Sample:** 100 users per variant\n- **Duration:** 2 weeks\n- **Decision:** Enable default-on if parallel is 2x faster with < 5% error rate\n\n---\n\n## Decision Log / ADRs\n\n### ADR-001: Token Tracking Implementation\n**Date:** 2025-01-19\n**Status:** Accepted\n**Context:** Users need cost visibility for cloud LLM usage\n**Decision:** Implement token tracking with official tokenizers, display after processing\n**Consequences:** Adds dependency on tokenizer libraries; increases code complexity\n**Alternatives Considered:**\n- Use rough character count (rejected: too inaccurate)\n- Use API-provided token counts (rejected: not available for all providers)\n- Skip token tracking (rejected: violates user need)\n\n### ADR-002: Parallel Processing with Worker Threads\n**Date:** 2025-01-19\n**Status:** Accepted\n**Context:** Sequential processing is too slow for large archives\n**Decision:** Use Node.js `worker_threads` for CPU-bound LLM tasks\n**Consequences:** Adds complexity; memory overhead; requires ordering guarantee\n**Alternatives Considered:**\n- Use child processes (rejected: higher overhead)\n- Use async batching only (rejected: doesn't parallelize CPU work)\n- Use external job queue (rejected: over-engineering)\n\n### ADR-003: Model Tier Routing Strategy\n**Date:** 2025-01-19\n**Status:** Accepted\n**Context:** Not all tasks need expensive models\n**Decision:** Route categorization to fast model, summarization to balanced model\n**Consequences:** Potential quality degradation; requires fallback mechanism\n**Alternatives Considered:**\n- Single model for all tasks (rejected: wasteful)\n- Automatic model selection (rejected: adds overhead)\n- User-selected model per task (accepted: user control)\n\n---\n\n## Open Questions\n\n1. **Q:** Should parallel processing be enabled by default after rollout?\n   **A:** Decision deferred until after evidence collection (Week 4)\n\n2. **Q:** Should we support custom model tier configurations?\n   **A:** Yes, but only for advanced users (document in \"Advanced Configuration\")\n\n3. **Q:** Should token reports be persisted to disk?\n   **A:** No, by default. Opt-in via `--save-token-report` (privacy-first)\n\n4. **Q:** Should we show cost estimates BEFORE processing begins?\n   **A:** Yes, based on a sample of 5 bookmarks (Phase 1.5, if evidence supports)\n\n---\n\n## Appendix: Smaug Reference Implementation\n\n### Parallel Processing Pattern (Smaug)\n```typescript\n// Smaug uses Claude Code subagents for parallel processing\nconst results = await Promise.allSettled(\n  bookmarks.map(b => subagent.analyze(b))\n);\n```\n\n### Token Tracking Pattern (Smaug)\n```typescript\n// Smaug tracks token usage per operation\nconst usage = {\n  input: response.usage.input_tokens,\n  output: response.usage.output_tokens,\n  cost: calculateCost(model, usage)\n};\n```\n\n### Model Routing Pattern (Smaug)\n```typescript\n// Smaug uses Haiku for simple tasks, Sonnet for complex\nconst model = isComplex(task) ? 'sonnet' : 'haiku';\n```\n\n---\n\n## References\n\n- **Smaug Codebase:** Private repository (parallel processing architecture)\n- **xKit Codebase:** https://github.com/jscraik/xKit\n- **LIMITATIONS.md:** `LIMITATIONS.md:134-142`\n- **Existing Modules:** `src/bookmark-analysis/`, `src/bookmark-stats/`\n\n---\n\n**Document Version:** 1.0\n**Last Updated:** 2025-01-19\n**Next Review:** After Phase 1 completion (estimated 2025-01-22)\n\n---\n\n## Debate Summary\n\n**Status:** \u2705 ALL PERSONAS [AGREE]\n\n**Rounds Conducted:** 1\n\n**Models:** PM, UI/UX Designer, Frontend Engineer, API Engineer, Backend Engineer, Security, Reliability/SRE, Cost/Scale\n\n**Key Refinements:**\n\n1. **Added User Personas** (ERROR-001)\n   - 4 detailed personas: Alex (Research Analyst), Jordan (Casual User), Sam (Power User), Casey (Student)\n   - Includes goals, pain points, technical proficiency, typical volumes\n\n2. **Improved Success Metrics** (ERROR-002)\n   - Added measurement methodology (hardware, network, statistical confidence)\n   - Specific baselines and targets with \u00b1 ranges\n   - Validation methods for each metric\n\n3. **Added Internal API Contracts** (ERROR-011)\n   - Complete TypeScript interfaces for TokenTracker, ParallelProcessor, ModelRouter\n   - JSDoc comments with parameters, returns, throws\n   - Usage examples for each module\n\n4. **Defined Error Codes** (ERROR-012)\n   - Error code constants (TOKEN_XXX, PARALLEL_XXX, MODEL_XXX, CONFIG_XXX)\n   - Error messages with user actions\n   - Error code reference table\n\n5. **Added Concurrency Control** (ERROR-014)\n   - Worker pool lifecycle state machine diagram\n   - Thread safety guarantees\n   - Memory limits with overflow behavior\n\n6. **Specified Retry Strategy** (ERROR-021)\n   - Retry configuration with exponential backoff\n   - Circuit breaker pattern with state diagram\n   - Half-open state handling\n\n7. **Defined SLOs and Error Budget** (ERROR-023)\n   - Success rate, latency, memory targets\n   - Error budget calculation and burn rate triggers\n   - Actions on burn (warning, critical, emergency)\n\n8. **Added Input Validation** (ERROR-018)\n   - Parameter bounds table\n   - Sanitization rules\n   - Injection prevention\n\n9. **Specified Secrets Handling** (ERROR-019)\n   - Never log/display list (API keys, bodies, cookies)\n   - May log list (token counts, costs, model names)\n   - Redaction rules\n\n10. **Updated Cost Calculations** (ERROR-025)\n    - Current pricing with citations\n    - Detailed cost comparison example\n    - Before/after optimization breakdown\n\n11. **Added Terminal UX Design** (ERROR-006)\n    - Progress bar design for parallel mode\n    - Empty state messages\n    - Zero cost display\n\n12. **Added Go/No-Go Framework** (ERROR-005)\n    - Decision tables for Phase 2 and Phase 3\n    - Specific thresholds and owners\n    - Fallback plans\n\n13. **Added Competitive Analysis** (ERROR-003)\n    - Feature comparison table vs competitors\n    - Differentiation highlights\n\n**Resolved Issues:** 27 (14 critical errors, 9 high priority, 4 medium priority)\n\n**Outstanding Questions:** 4 (documented in Open Questions section)\n\n---\n\n**Final Status:** [AGREE] - Specification complete and approved for implementation\n\n[AGREE] PM: Scope, metrics, and personas well-defined\n[AGREE] UI/UX: Terminal UX and error states specified\n[AGREE] Frontend: State management approach clear\n[AGREE] API: Internal contracts complete\n[AGREE] Backend: Concurrency control adequate\n[AGREE] Security: Input validation and secrets handling specified\n[AGREE] SRE: SLOs, retry strategy, circuit breaker defined\n[AGREE] Cost/Scale: Cost calculations accurate with current pricing\n\n---\n\n[SPEC]\n\n\n## .spec/spec-2026-01-20-ai-knowledge-transformation.md\n# xKit Enhanced Knowledge Transformation System\n\n**Date:** 2026-01-20\n**Type:** Product Requirements Document (PRD) + Technical Specification\n**Status:** Draft v1.0\n**Schema Version:** 1\n\n---\n\n## Executive Summary\n\nTransform xKit from a bookmark archiver into a **knowledge transformation system** that converts bookmarked content into:\n1. **Engaging summaries** using Summarize-style prompt engineering\n2. **Agent Skills** for Claude Code (reusable AI capabilities)\n3. **Learning materials** (study guides, flashcards, quizzes) for self-learning\n4. **Custom prompt templates** for domain-specific summarization\n\n**Vision Statement:** Every bookmark becomes a building block for AI development - not just stored, but transformed into actionable knowledge.\n\n**Key Differentiation:** Unlike generic bookmarking tools, xKit leverages proven patterns from [steipete/summarize](https://github.com/steipete/summarize) (production-grade CLI with 200+ tests, Chrome extension, daemon mode) while adding unique capabilities for skill extraction and learning material generation.\n\n**Evidence-Based Design:** This specification is informed by reconnaissance analysis of Summarize's architecture, security model, and feature set. See `.spec/spec-2026-01-20-summarize-feature-analysis.md` for detailed feature comparison.\n\n---\n\n## Problem & Opportunity\n\n### Current State Analysis\n\n**xKit's Current Capabilities** (from `src/commands/bookmarks-archive.ts`):\n- Fetches bookmarks from Twitter API\n- Enriches with URL expansion and article extraction\n- Categorizes into github/article/video/prompts/visual/tweet\n- Exports to markdown with date/author organization\n- Basic summarization via Ollama (generic prompt: \"You are a helpful assistant that creates concise summaries\")\n\n**Limitations** (from `src/bookmark-enrichment/ollama-client.ts:68-88`):\n```typescript\n// Current generic prompt - lacks engagement and adaptability\nprivate buildSummaryPrompt(content: string, title?: string): string {\n  return `You are a helpful assistant that creates concise summaries of articles.\n  // Fixed 2-3 sentence format, no persona, no content-type awareness\n  ```\n}\n\n### User Pain Points (Hypotheses - Validation Required)\n\n1. **Generic Summaries:** Current summaries are one-size-fits-all, not tailored to learning style or content type\n2. **Passive Archive:** Bookmarks accumulate without active knowledge extraction\n3. **Manual Note-Taking:** Users manually convert bookmarks to Skills, study guides, or reference materials\n4. **Lost Context:** Remembering why a bookmark was saved is difficult over time\n\n### Market Opportunity\n\n**Competitive Landscape** (based on Summarize reconnaissance):\n- **Summarize:** CLI tool for summarization (no bookmark archiving, no skill generation)\n- **Readwise:** Read-later service with highlighting (no skill generation, no custom workflows)\n- **Fabric:** AI-powered workspace (expensive, generic prompts, no bookmark integration)\n\n**xKit's Unique Position:**\n- **Source:** Twitter/X bookmarks (high-signal content curation)\n- **Output:** Multiple transformation types (summaries, Skills, learning materials)\n- **Integration:** Direct Claude Code Skills generation (unique capability)\n- **Cost:** Local LLM via Ollama (free, private) vs paid APIs\n\n---\n\n## User Personas\n\n### Primary Persona: \"Alex, Senior iOS Engineer\"\n\n**Demographics:**\n- 8 years experience, builds consumer apps\n- Active on Twitter/X, follows 500+ developers\n- Saves 20-30 bookmarks/week (GitHub repos, technical articles, talks)\n\n**Goals:**\n- Stay current with iOS/SwiftUI patterns\n- Build personal knowledge base of reusable code patterns\n- Learn new technologies efficiently (just-in-time learning)\n- Share insights with team via generated Skills\n\n**Pain Points:**\n- Bookmarks pile up, forgotten after 1 week\n- GitHub repos saved but never mined for patterns\n- Articles read but not retained\n- Manual conversion to team Skills is time-consuming\n\n**Current Workflow:**\n1. Scroll Twitter, tap bookmark on interesting content\n2. Never revisit bookmarks (black hole)\n3. Manually take notes in Notion for important repos (rarely)\n4. Search Google when need pattern (already bookmarked!)\n\n**Desired Workflow:**\n1. Bookmark tweet/repo/article on Twitter\n2. xKit auto-categorizes and generates engaging summary\n3. Review weekly recap, extract valuable Skills\n4. Add Skills to Claude Code for daily use\n5. Generate study guide for new tech (e.g., \"SwiftUI animations\")\n\n**Success Metrics for Alex:**\n- Reduces time-to-pattern from 30 min (manual) to 5 min (automated)\n- Extracts 5+ useful Skills/month from bookmarks\n- Generates 2+ study guides/month for new technologies\n\n### Secondary Persona: \"Jordan, Technical Product Manager\"\n\n**Demographics:**\n- 5 years in PM, works on developer tools\n- Follows product blogs, engineering blogs, GitHub projects\n- Saves 10-15 bookmarks/week\n\n**Goals:**\n- Track competitive landscape\n- Understand technical feasibility of features\n- Learn from other PMs and engineers\n- Share insights with team\n\n**Pain Points:**\n- Technical articles overwhelming (too much detail)\n- Hard to distill \"what this means for us\"\n- GitHub repos saved but never evaluated\n\n**Desired Workflow:**\n1. Bookmark technical content\n2. Get business-focused summary (product-manager persona)\n3. Generate comparison report from related bookmarks\n4. Share summary with team via webhook (Slack/Discord)\n\n**Success Metrics for Jordan:**\n- Summaries capture business implications (not just technical details)\n- Weekly recap highlights competitive insights\n- Can explain technical feasibility to non-technical stakeholders\n\n### Tertiary Persona: \"Sam, Self-Taught Developer\"\n\n**Demographics:**\n- 2 years coding, bootcamp grad\n- Active learner, follows tutorials and documentation\n- Saves 30+ bookmarks/week (tutorials, docs, examples)\n\n**Goals:**\n- Learn efficiently (spaced repetition)\n- Build comprehensive understanding of topics\n- Track learning progress\n- Practice with real-world examples\n\n**Pain Points:**\n- Tutorial bookmarked but never completed\n- Forgets syntax and patterns\n- No structured learning path\n- Overwhelmed by volume of content\n\n**Desired Workflow:**\n1. Bookmark tutorials and docs\n2. Generate study guides with learning objectives\n3. Create flashcards for spaced repetition\n4. Track mastery with quiz assessments\n5. Recap monthly to reinforce learning\n\n**Success Metrics for Sam:**\n- Completes 80% of bookmarked tutorials (vs 20% baseline)\n- Retains 70% of flashcard content after 1 week\n- Generates personalized learning roadmap from bookmarks\n\n---\n\n## User Stories\n\n### STORY-001: Enhanced Bookmark Summarization\n\n**As** Alex (senior iOS engineer),\n**I want** to generate engaging summaries tailored to my learning style,\n**So that** I can quickly grasp key concepts without reading full articles.\n\n**Acceptance Criteria:**\n- [ ] CLI flag `--summarize --persona technical-researcher --length long` produces technical summary\n- [ ] CLI flag `--summarize --persona curious-learner --length medium` produces accessible summary\n- [ ] Summary quality score \u2265 4.0/5.0 in user surveys (n=30)\n- [ ] Latency \u2264 1.5\u00d7 current baseline (measure with 100 bookmarks)\n- [ ] Supports 5 length levels (short, medium, long, xl, xxl)\n- [ ] Supports 7 personas (curious-learner, technical-researcher, product-manager, engineer-pragmatic, educator, skeptic, synthesizer)\n- [ ] Supports 7 content types (article, video-transcript, github-repo, documentation, twitter-thread, podcast-episode, research-paper)\n\n**Success Metrics:**\n- Summary engagement rate (user reads full summary) \u2265 60%\n- Summary regeneration rate (user regenerates with different options) \u2264 20%\n- Time-saved vs reading full article \u2265 80% (user survey)\n\n### STORY-002: Agent Skill Extraction from Bookmarks\n\n**As** Alex (senior iOS engineer),\n**I want** to automatically extract reusable code patterns from bookmarked GitHub repos,\n**So that** I can add them to my Claude Code Skills library.\n\n**Acceptance Criteria:**\n- [ ] CLI command `xkit generate-skills --category github --min-confidence 0.7` extracts skills\n- [ ] Generated Skills follow Claude Code `.skill.md` format (frontmatter, triggers, implementation, examples, edge cases)\n- [ ] Skill extraction precision \u2265 80% (manual audit of 100 generated skills)\n- [ ] Confidence scoring (0-1) indicates likelihood of usefulness\n- [ ] Skills written to `.claude/skills-review/` (require manual approval before `.claude/skills/`)\n- [ ] Includes disclaimer: \"AI-generated, review before use\"\n- [ ] Supports categories: code-pattern, best-practice, workflow\n\n**Success Metrics:**\n- 10+ useful skills generated from existing GitHub bookmarks (manual review)\n- User approval rate \u2265 60% (skills moved from review to active)\n- Zero unsafe code in approved skills (manual audit)\n\n### STORY-003: Learning Material Generation\n\n**As** Sam (self-taught developer),\n**I want** to generate study guides and flashcards from bookmarked tutorials,\n**So that** I can learn efficiently with spaced repetition.\n\n**Acceptance Criteria:**\n- [ ] CLI command `xkit learn --generate study-guide,flashcards --from \"SwiftUI animations\"` generates materials\n- [ ] Study guides include: learning objectives, core concepts, examples, exercises, difficulty assessment\n- [ ] Flashcards are Q&A pairs suitable for spaced repetition\n- [ ] Learning material completion rate \u2265 60% (A/B test vs baseline)\n- [ ] User satisfaction \u2265 3.5/5.0 (surveys)\n- [ ] Materials stored in `~/.xkit/learning/` with organized structure\n\n**Success Metrics:**\n- Tutorial completion rate increases from 20% to 80%\n- Flashcard retention rate \u2265 70% after 1 week (user quiz)\n- Study guide generation time \u2264 30s per bookmark\n\n### STORY-004: Periodic Recap Generation\n\n**As** Alex (senior iOS engineer),\n**I want** a weekly recap of my bookmarks grouped by theme,\n**So that** I can discover connections and extract actionable insights.\n\n**Acceptance Criteria:**\n- [ ] CLI command `xkit recap --period weekly --categories github,article` generates recap\n- [ ] Recap groups bookmarks by semantic theme (using vector embeddings)\n- [ ] Identifies cross-connections between topics\n- [ ] Suggests actionable next steps\n- [ ] Generates reflection questions\n- [ ] Recap generation time \u2264 2 minutes for 100 bookmarks\n- [ ] Recap includes links to original bookmarks\n\n**Success Metrics:**\n- Recap engagement rate (user reads full recap) \u2265 50%\n- Skills extracted from recap \u2265 3 per week\n- User-reported insight rate \u2265 70% (recap revealed new connection)\n\n### STORY-005: Custom Prompt Templates\n\n**As** Jordan (technical PM),\n**I want** to create custom prompt templates for domain-specific summarization,\n**So that** I can get consistent outputs for my use cases.\n\n**Acceptance Criteria:**\n- [ ] Templates stored in `~/.xkit/templates/` as markdown files with YAML frontmatter\n- [ ] Template format: name, description, category, prompt content with `{{variable}}` substitutions\n- [ ] CLI command `xkit summarize <url> --template research-paper --var domain=\"ML\"` applies template\n- [ ] Template validation before use (checks for forbidden patterns, validates variables)\n- [ ] Error messages clear when template invalid\n- [ ] Example templates included: research-paper, good-first-issue, api-integration\n\n**Success Metrics:**\n- Custom template usage rate \u2265 10% of summarization calls\n- Template validation success rate \u2265 95%\n- User satisfaction with custom templates \u2265 4.0/5.0\n\n---\n\n## Success Criteria\n\n### Phase 1: Enhanced Summarization (Days 1-3)\n- [ ] Tagged prompts implemented (XML-style `<instructions>`, `<context>`, `<content>`)\n- [ ] All 5 length levels working (short, medium, long, xl, xxl)\n- [ ] All 7 personas implemented (curious-learner, technical-researcher, product-manager, engineer-pragmatic, educator, skeptic, synthesizer)\n- [ ] All 7 content types supported (article, video-transcript, github-repo, documentation, twitter-thread, podcast-episode, research-paper)\n- [ ] Custom templates loading from `~/.xkit/templates/`\n\n### Phase 2: Skill Generation (Days 4-6)\n- [ ] Extract patterns from GitHub repos (80%+ useful per manual audit)\n- [ ] Extract best practices from articles\n- [ ] Generate valid `.skill.md` files\n- [ ] 10+ skills generated from existing bookmarks\n\n### Phase 3: Learning Materials (Days 7-9)\n- [ ] Study guide generation working\n- [ ] Flashcard generation working\n- [ ] Quiz generation working\n- [ ] Recap clusters by theme (using embeddings)\n\n### Phase 4: Integration (Days 10-11)\n- [ ] All CLI commands working\n- [ ] Config file support\n- [ ] Documentation complete\n- [ ] Example outputs generated\n\n### Measurable Success Metrics (All Phases)\n\n**Quality Metrics:**\n- Summary quality score \u2265 4.0/5.0 (user surveys, n=30)\n- Skill extraction precision \u2265 80% (manual audit, n=100)\n- Learning material completion rate \u2265 60% (A/B test vs baseline)\n\n**Performance Metrics:**\n- Summary latency \u2264 1.5\u00d7 current baseline (measure with 100 bookmarks)\n- Skill generation \u2264 3\u00d7 baseline (acceptable due to complexity)\n- Learning material generation \u2264 5\u00d7 baseline (acceptable due to complexity)\n\n**User Engagement Metrics:**\n- Summary engagement rate (reads full summary) \u2265 60%\n- Skill approval rate (review \u2192 active) \u2265 60%\n- Recap engagement rate \u2265 50%\n\n**Security Metrics:**\n- Zero prompt injection vulnerabilities (penetration testing)\n- Zero unsafe code in approved Skills (manual audit)\n- All templates validated before use\n\n**Reliability Metrics:**\n- CLI command success rate \u2265 99% (excludes user errors)\n- LLM error rate < 5% (excluding Ollama down)\n- Cache hit rate \u2265 60% on second run (Same Summarize's 60%+ target)\n\n---\n\n## Risks and Mitigations\n\n### RISK-001: LLM Hallucination in Skill Extraction\n\n**Severity:** High\n**Probability:** Medium\n**Impact:** Users receive incorrect or unsafe code patterns\n\n**Mitigation:**\n- Confidence scoring (0-1) with manual review required for low-confidence skills\n- Two-stage validation: (1) LLM extraction, (2) Code linting (Biome) + static analysis\n- Manual approval workflow: `.claude/skills-review/` \u2192 `.claude/skills/`\n- Clear disclaimer: \"AI-generated, review before use\"\n\n**Owner:** @jamiecraik\n**Status:** Open\n\n### RISK-002: Low-Quality Generated Materials\n\n**Severity:** Medium\n**Probability:** Medium\n**Impact:** Users abandon feature due to poor quality\n\n**Mitigation:**\n- User feedback loop: rating system for generated materials\n- Iterative refinement: prompts tuned based on feedback\n- A/B test against baseline (no generated materials)\n- Kill criteria: if satisfaction < 3.5/5.0 for 30 days, deprecate feature\n\n**Owner:** @jamiecraik\n**Status:** Open\n\n### RISK-003: Prompt Injection Vulnerability\n\n**Severity:** Critical\n**Probability:** Low\n**Impact:** Malicious bookmark content manipulates LLM\n\n**Mitigation:**\n- Sanitize XML tags in content before inserting into prompts\n- Use UUID-based delimiters instead of XML tags\n- Implement prompt validation and escaping\n- Penetration testing before GA\n- **Reference:** See adversarial review ERROR finding Security-1\n\n**Owner:** @jamiecraik\n**Status:** Open - Must fix before Phase 1\n\n### RISK-004: Unrealistic Timeline\n\n**Severity:** High\n**Probability:** High\n**Impact:** Burnout, technical debt, abandoned features\n\n**Mitigation:**\n- Revised timeline: 23 days (includes Phase 0 foundation + user research)\n- Phased validation: research before building Phases 2-3\n- Buffer for iteration: +3 days for user feedback\n- Go/no-go decisions after each phase\n\n**Owner:** @jamiecraik\n**Status:** Open - Addressed in revised plan\n\n### RISK-005: No User Demand for Skills/Learning Materials\n\n**Severity:** High\n**Probability:** Medium\n**Impact:** Build features nobody uses\n\n**Mitigation:**\n- User research (n=10-15 interviews) before building Phases 2-3\n- Go/no-go criteria:\n  - If \u2265 70% express interest in enhanced summaries \u2192 proceed\n  - If \u2265 50% express interest in Skills \u2192 proceed\n  - If < 50% express interest in learning materials \u2192 cut or defer\n- Kill criteria: if feature unused by 20% of users after 30 days, deprecate\n\n**Owner:** @jamiecraik\n**Status:** Open - Requires user research\n\n### RISK-006: Cost Overrun from LLM Usage\n\n**Severity:** Medium\n**Probability:** Low\n**Impact:** Surprise bills or unusable feature\n\n**Mitigation:**\n- Default to local Ollama (free)\n- Cost estimation before running: `--max-llm-spend $10` with confirmation\n- Token tracking: show cost per 1,000 bookmarks\n- Kill switch: if cost > $50/month, require explicit re-authorization\n\n**Owner:** @jamiecraik\n**Status:** Open\n\n---\n\n## Out of Scope\n\n**Explicitly Out of Scope for v1.0:**\n- Chrome extension (deferred to v2.0, requires daemon infrastructure)\n- Podcast transcription (YouTube only in v1.0)\n- Multi-format file processing (PDFs, images - requires MarkItDown integration)\n- Real-time streaming of summaries (batch only in v1.0)\n- Collaborative features (sharing Skills, team learning materials)\n- Advanced analytics (usage dashboards, learning progress tracking)\n- Mobile apps (CLI only in v1.0)\n- Paid API integrations (OpenAI, Anthropic - Ollama/local only in v1.0)\n\n**Rationale:** Focus on CLI workflow (matches xKit's current usage), validate demand before adding Chrome extension or mobile apps, leverage existing Ollama infrastructure before adding paid APIs.\n\n**Future Considerations (v2.0+):**\n- Chrome Side Panel extension (\u501f\u9274 Summarize's architecture)\n- Daemon mode for long-running processes\n- Podcast transcription (\u501f\u9274 Summarize's 4-level fallback)\n- Paid API integrations with auto model selection\n- Real-time streaming summaries\n\n---\n\n## Feature Creep Guardrails\n\n**Scope Change Policy:**\n1. Any new feature must displace an existing feature (zero-sum scope)\n2. New features require 48-hour consideration period (prevents\u51b2\u52a8 decisions)\n3. Must pass cost-benefit analysis (user value vs implementation effort)\n4. Must update success criteria and risk register\n\n**Example Guardrails:**\n- **Question:** \"Should we add podcast transcription in v1.0?\"\n- **Answer:** No, displaces Skill Generation (higher user value per hypothesis). Defer to v2.0.\n- **Question:** \"Should we add Chrome extension in v1.0?\"\n- **Answer:** No, requires daemon infrastructure (5-7 days), displaces user research (higher priority). Defer to v2.0.\n\n**48-Hour Rule for New Documentation:**\n- Adding new documentation artifacts (e.g., SPEC_INDEX.md) requires explicit justification\n- Must answer: (1) What problem does this solve? (2) Who will maintain it? (3) When will it be updated?\n- Default answer: No new docs unless critical for shipping\n\n---\n\n## Scope Decision Log\n\n### Decision 001: Exclude Chrome Extension from v1.0\n**Date:** 2026-01-20\n**Decision:** CLI-only workflow for v1.0, defer Chrome extension to v2.0\n**Rationale:**\n- Chrome extension requires daemon infrastructure (5-7 days per Summarize analysis)\n- User research higher priority (validates demand for Skills/learning materials)\n- CLI workflow matches xKit's current usage patterns\n- Reduces initial scope from 23 days to 15 days (without extension)\n**Alternatives Considered:**\n- Include extension: +7 days, higher complexity, unproven demand\n**Revisit:** After v1.0 GA and user feedback\n\n### Decision 002: Prioritize User Research Before Skills/Learning Materials\n**Date:** 2026-01-20\n**Decision:** Add Phase 1A (User Research, 3 days) before building Phases 2-3\n**Rationale:**\n- No evidence users want Skills or learning materials (per adversarial review PM-1)\n- Risk building features nobody uses\n- Low-cost investment (3 days) vs high-risk implementation (10+ days)\n**Alternatives Considered:**\n- Skip research, build anyway: rejected (high risk of waste)\n**Revisit:** After user research complete\n\n### Decision 003: Add Phase 0 (Foundation) Before Features\n**Date:** 2026-01-20\n**Decision:** Implement caching, observability, security foundations before adding features\n**Rationale:**\n- Adversarial review identified 36 ERROR findings across reliability/security\n- Cannot measure success without observability\n- Cannot ship safely without security foundations\n- Summarize has proven caching (eliminates 60%+ redundant API calls)\n**Alternatives Considered:**\n- Build features first, add foundations later: rejected (technical debt trap)\n**Revisit:** After Phase 0 complete\n\n---\n\n## Technical Architecture\n\n### System Overview\n\n```mermaid\nflowchart TD\n    A[xKit CLI: bookmarks-archive] --> B[Fetch Bookmarks<br/>Twitter API]\n    B --> C[BookmarkEnricher<br/>URL expansion, content extraction]\n    C --> D{Summarization Enabled?}\n    D -->|No| E[Skip to Categorization]\n    D -->|Yes| F[OllamaClient Enhanced]\n    F --> G[TaggedPromptBuilder<br/>instructions/context/content]\n    G --> H[PersonaSelector<br/>7 personas]\n    G --> I[LengthSelector<br/>5 levels]\n    G --> J[ContentTypeAdapter<br/>7 types]\n    H --> K[Ollama API]\n    I --> K\n    J --> K\n    K --> L[SummaryResult<br/>content, tokens, cost]\n    L --> M[BookmarkCategorizer]\n    E --> M\n    M --> N{Skill Generation?}\n    N -->|Yes| O[SkillExtractor<br/>LLM-based pattern extraction]\n    O --> P[SkillTemplateGenerator<br/>.skill.md format]\n    P --> Q[SkillWriter<br/>.claude/skills-review/]\n    N -->|No| R{Learning Materials?}\n    R -->|Yes| S[LearningMaterialGenerator<br/>study guides, flashcards, quizzes]\n    S --> T[LearningWriter<br/>~/.xkit/learning/]\n    R -->|No| U[MarkdownWriter<br/>knowledge files]\n    Q --> U\n    T --> U\n    U --> V[StateManager<br/>mark processed]\n    V --> W[TokenTracker<br/>usage, cost]\n```\n\n### Component Behavior / State Model\n\n```mermaid\nstateDiagram-v2\n    [*] --> IDLE: CLI invoked\n\n    IDLE --> FETCHING: user confirms credentials\n    FETCHING --> IDLE: fetch failed / retryable\n    FETCHING --> ENRICHING: bookmarks fetched\n\n    ENRICHING --> ENRICHING: batch progress\n    ENRICHING --> SUMMARIZING: enrichment complete / summarize enabled\n    ENRICHING --> CATEGORIZING: enrichment complete / summarize disabled\n\n    SUMMARIZING --> SUMMARIZING: persona/length selection\n    SUMMARIZING --> CATEGORIZING: summary generated / skip summarization\n    SUMMARIZING --> ERROR: LLM timeout / Ollama down\n    SUMMARIZING --> ERROR: prompt injection detected\n\n    CATEGORIZING --> CATEGORIZING: category determination\n    CATEGORIZING --> SKILL_EXTRACTION: categorization complete / skill generation enabled\n    CATEGORIZING --> LEARNING_GENERATION: categorization complete / learning enabled\n    CATEGORIZING --> WRITING: categorization complete / skip skills/learning\n\n    SKILL_EXTRACTION --> SKILL_EXTRACTION: LLM extraction per bookmark\n    SKILL_EXTRACTION --> WRITING: skills extracted / write review files\n    SKILL_EXTRACTION --> ERROR: extraction failed / log error, continue\n\n    LEARNING_GENERATION --> LEARNING_GENERATION: material generation per bookmark\n    LEARNING_GENERATION --> WRITING: materials generated / write learning files\n    LEARNING_GENERATION --> ERROR: generation failed / log error, continue\n\n    WRITING --> WRITING: markdown files written\n    WRITING --> COMPLETE: all files written\n\n    ERROR --> COMPLETE: partial success / some bookmarks failed\n    ERROR --> [*]: fatal error / abort\n\n    COMPLETE --> [*]\n```\n\n### Data Models\n\n#### EnhancedSummary\n```typescript\ninterface EnhancedSummary {\n  id: string; // UUID\n  bookmarkId: string; // Foreign key to CategorizedBookmark\n  persona: PersonaType; // curious-learner | technical-researcher | ...\n  length: SummaryLength; // short | medium | long | xl | xxl\n  contentType: ContentType; // article | video-transcript | github-repo | ...\n  content: string; // Generated summary\n  tokensUsed: {\n    input: number;\n    output: number;\n    total: number;\n  };\n  costEstimate: number; // USD (0.0 for local Ollama)\n  model: string; // e.g., \"nomic-embed-text\", \"qwen2.5:7b\"\n  timestamp: string; // ISO 8601\n}\n```\n\n#### SkillCandidate\n```typescript\ninterface SkillCandidate {\n  id: string; // UUID\n  bookmarkId: string; // Foreign key to CategorizedBookmark\n  name: string; // Skill name\n  description: string; // One-sentence summary\n  triggers: string[]; // When to use this skill\n  category: 'code-pattern' | 'best-practice' | 'workflow';\n  implementation: string; // Step-by-step guidance\n  examples: Array<{\n    scenario: string;\n    code: string;\n  }>;\n  edgeCases: string[]; // Common pitfalls\n  confidence: number; // 0-1, likelihood of usefulness\n  status: 'review' | 'approved' | 'rejected';\n  generatedAt: string; // ISO 8601\n  reviewedAt?: string; // ISO 8601\n}\n```\n\n#### LearningMaterial\n```typescript\ninterface LearningMaterial {\n  id: string; // UUID\n  bookmarkId: string; // Foreign key to CategorizedBookmark\n  type: 'study-guide' | 'flashcards' | 'quiz';\n  title: string; // Material title\n  difficulty: 'beginner' | 'intermediate' | 'advanced';\n  objectives: string[]; // Learning objectives\n  content: {\n    concepts: Array<{\n      name: string;\n      definition: string;\n      examples: string[];\n    }>;\n    exercises: Array<{\n      question: string;\n      answer: string;\n      difficulty: number; // 1-5\n    }>;\n  };\n  estimatedTime: number; // Minutes\n  generatedAt: string; // ISO 8601\n}\n```\n\n#### Recap\n```typescript\ninterface Recap {\n  id: string; // UUID\n  period: 'daily' | 'weekly' | 'monthly';\n  startDate: string; // ISO 8601\n  endDate: string; // ISO 8601\n  themes: Array<{\n    name: string; // Theme name (e.g., \"SwiftUI Animations\")\n    bookmarkIds: string[]; // Related bookmarks\n    summary: string; // Thematic summary\n    connections: string[]; // Cross-connections\n    nextSteps: string[]; // Actionable items\n  }>;\n  reflectionQuestions: string[]; // Prompts for user\n  generatedAt: string; // ISO 8601\n}\n```\n\n### Security Considerations\n\n**\u501f\u9274 Summarize's Security Model:**\n- Localhost-only binding for any future daemon mode\n- Bearer token authentication for API endpoints\n- CORS validation for Chrome extension (future)\n- API keys captured at startup from environment\n- No key leakage in codebase (verified via reconnaissance)\n\n**Additional Security Measures for xKit:**\n\n#### Prompt Injection Protection (Critical - Must Fix Before Phase 1)\n```typescript\nfunction escapeXmlTags(content: string): string {\n  return content\n    .replace(/<instructions>/gi, '&lt;instructions&gt;')\n    .replace(/<\\/instructions>/gi, '&lt;/instructions&gt;')\n    .replace(/<context>/gi, '&lt;context&gt;')\n    .replace(/<\\/context>/gi, '&lt;/context&gt;')\n    .replace(/<content>/gi, '&lt;content&gt;')\n    .replace(/<\\/content>/gi, '&lt;/content&gt;');\n}\n\nfunction buildSafeTaggedPrompt(options: {\n  instructions: string;\n  context: string;\n  content: string;\n}): string {\n  const safeContent = escapeXmlTags(options.content);\n  return `<instructions>\n${options.instructions.trim()}\n</instructions>\n\n<context>\n${options.context.trim()}\n</context>\n\n<content>\n${safeContent.trim()}\n</content>`;\n}\n```\n\n#### Template Validation\n```typescript\ninterface TemplateSchema {\n  allowedVariables: string[]; // e.g., ['domain', 'language', 'difficulty']\n  forbiddenPatterns: RegExp[]; // e.g., [/process\\./, /child_process/]\n  maxLength: number; // e.g., 10_000 characters\n}\n\nfunction validateTemplate(\n  template: string,\n  schema: TemplateSchema\n): { valid: boolean; errors: string[] } {\n  const errors: string[] = [];\n\n  // Check for forbidden patterns\n  for (const pattern of schema.forbiddenPatterns) {\n    if (pattern.test(template)) {\n      errors.push(`Forbidden pattern detected: ${pattern}`);\n    }\n  }\n\n  // Check for system calls\n  if (template.includes('process.') || template.includes('child_process')) {\n    errors.push('Template must not access system APIs');\n  }\n\n  // Validate variables\n  const variables = template.match(/\\{\\{(\\w+)\\}\\}/g) || [];\n  for (const variable of variables) {\n    const name = variable.slice(2, -2);\n    if (!schema.allowedVariables.includes(name)) {\n      errors.push(`Unknown variable: ${name}`);\n    }\n  }\n\n  return { valid: errors.length === 0, errors };\n}\n```\n\n#### Generated Code Disclaimer\n```markdown\n---\n**Disclaimer:** This Skill was auto-generated by xKit from bookmarked content.\n**Do not use in production without thorough review.** Always test code in a safe\nenvironment before deploying to production systems.\n\nReview checklist:\n- [ ] Code compiles without errors\n- [ ] No unsafe operations (eval, exec, SQL injection)\n- [ ] Error handling is appropriate\n- [ ] Tested with sample inputs\n---\n```\n\n### API Design\n\n#### CLI Commands (New)\n\n```bash\n# Enhanced summarization\nxkit archive --summarize --persona <persona> --length <length> --content-type <type>\n  persona: curious-learner | technical-researcher | product-manager | engineer-pragmatic | educator | skeptic | synthesizer\n  length: short | medium | long | xl | xxl\n  content-type: article | video-transcript | github-repo | documentation | twitter-thread | podcast-episode | research-paper\n\n# Skill generation\nxkit generate-skills --category <category> --min-confidence <0.0-1.0> --last <n>\n  category: github | article | video | all\n  min-confidence: 0.7 (default)\n  last: number of recent bookmarks to process (default: all)\n\n# Learning materials\nxkit learn --generate <types> --from <query> --difficulty <level>\n  types: study-guide,flashcards,quiz (comma-separated)\n  from: search query for bookmarks (e.g., \"SwiftUI animations\")\n  difficulty: beginner | intermediate | advanced\n\n# Recap\nxkit recap --period <daily|weekly|monthly> --categories <categories>\n  categories: github,article,video,prompts,visual,tweet (comma-separated)\n\n# Custom templates\nxkit summarize <url> --template <name> --var <key=value>\n  template: template name (from ~/.xkit/templates/)\n  var: variable substitutions (e.g., domain=\"ML\", language=\"python\")\n\n# Cache management (\u501f\u9274 Summarize)\nxkit cache --stats --clear --no-cache\n  --stats: show cache statistics\n  --clear: clear all cached data\n  --no-cache: disable caching for this run\n```\n\n#### Programmatic API (Future - for Daemon Mode)\n\n```typescript\n// Future: HTTP API for Chrome extension (v2.0)\ninterface DaemonAPI {\n  // Health check\n  'GET /health': { ok: true; pid: number; version: string }\n\n  // Bookmark operations\n  'POST /v1/bookmark': { ok: true; id: string }\n  'GET /v1/bookmark/:id': CategorizedBookmark\n  'DELETE /v1/bookmark/:id': { ok: true }\n\n  // Summarization\n  'POST /v1/summarize': EnhancedSummary\n  'GET /v1/summarize/:id': EnhancedSummary\n\n  // Skill generation\n  'POST /v1/skills': SkillCandidate[]\n  'GET /v1/skills': SkillCandidate[]\n  'PUT /v1/skills/:id/approve': { ok: true }\n\n  // Learning materials\n  'POST /v1/learn': LearningMaterial\n  'GET /v1/learn': LearningMaterial[]\n\n  // Recap\n  'POST /v1/recap': Recap\n\n  // Search (using embeddings)\n  'GET /v1/search?q=<query>': CategorizedBookmark[]\n  'GET /v1/similar/:id': CategorizedBookmark[]\n\n  // Stats\n  'GET /v1/stats': {\n    totalBookmarks: number;\n    cached: number;\n    lastRun: string;\n    llmCalls: number;\n    tokensUsed: number;\n  }\n}\n```\n\n### Deployment Strategy\n\n#### Phase 0: Foundation (Days 1-3)\n1. **SQLite Caching** (\u501f\u9274 Summarize)\n   - Implement extract cache and summary cache\n   - TTL: 30 days, size cap: 512MB\n   - WAL mode for performance, LRU eviction\n   - CLI flags: `--cache-stats`, `--clear-cache`, `--no-cache`\n\n2. **Observability Foundation**\n   - Structured logging with pino\n   - Metrics collection (latency, error rate, token usage)\n   - Health check command: `xkit status`\n\n3. **Security Foundation**\n   - Prompt injection protection (XML tag escaping)\n   - Template validation schema\n   - Audit logging (opt-in)\n\n#### Phase 1A: User Research (Days 4-6)\n1. **User Interviews** (n=10-15)\n   - Current bookmark workflow pain points\n   - Interest in enhanced summaries (personas, lengths)\n   - Interest in Skills generation\n   - Interest in learning materials\n\n2. **Mockup Testing**\n   - Paper prototypes for CLI UX\n   - Example outputs (hand-crafted)\n   - Feedback on feature prioritization\n\n3. **Go/No-Go Decision**\n   - If \u2265 70% express interest in enhanced summaries \u2192 proceed\n   - If \u2265 50% express interest in Skills \u2192 proceed\n   - If < 50% express interest in learning materials \u2192 cut or defer\n\n#### Phase 1B: Enhanced Summarization (Days 7-10)\n1. **Tagged Prompt Structure**\n2. **Length-Specific Templates** (5 levels)\n3. **Persona System** (7 personas)\n4. **Content-Type Adaptation** (7 types)\n\n**Success Criteria:**\n- Summary quality \u2265 4.0/5.0 (user surveys, n=30)\n- No regressions in latency (> 1.5\u00d7 current time)\n\n#### Phase 2: Skill Generation (Days 11-16) - **CONDITIONAL**\n**Goal:** Ship ONLY if validated in research (\u2265 50% interest)\n\n1. **Skill Extraction**\n2. **Skill Template Generator**\n3. **Skill Writer**\n\n**Success Criteria:**\n- Skill extraction precision \u2265 80% (manual audit)\n- 10+ useful skills from test data\n- Users approve \u2265 60% of generated skills\n\n#### Phase 3: Learning Materials (Days 17-20) - **CONDITIONAL**\n**Goal:** Ship ONLY if validated in research (\u2265 50% interest)\n\n1. **Material Generator** (study guides, flashcards, quizzes)\n2. **Recap System**\n\n**Success Criteria:**\n- Learning material completion rate \u2265 60% (A/B test)\n- User satisfaction \u2265 3.5/5.0 (surveys)\n\n#### Phase 4: CLI Integration & Docs (Days 21-23)\n1. **CLI Commands**\n2. **Documentation**\n3. **Example Outputs**\n\n**Total Timeline:** 23 days (with validation and conditional phases)\n\n### Performance Targets\n\n**Latency:**\n- Single bookmark summarization: p95 < 30s\n- Skill extraction: p95 < 90s (3\u00d7 baseline)\n- Learning material generation: p95 < 150s (5\u00d7 baseline)\n- Recap generation (100 bookmarks): < 2 minutes\n\n**Throughput:**\n- Batch processing (100 bookmarks): < 30 minutes\n- Cache hit rate: \u2265 60% on second run\n\n**Resource Usage:**\n- Ollama memory: < 8GB (nomic-embed-text: 7B params)\n- Disk usage: < 1GB for 1,000 bookmarks (including cache, skills, learning materials)\n\n### Reliability Targets\n\n**Availability:**\n- CLI command success rate: \u2265 99% (excludes user errors)\n\n**Error Rate:**\n- LLM-related errors: < 5% (excluding Ollama down)\n- Cache-related errors: < 1%\n- Template validation errors: < 1%\n\n**Data Quality:**\n- Summary quality score: \u2265 4.0/5.0 (user surveys)\n- Skill extraction precision: \u2265 80% (manual audit)\n- Learning material completeness: \u2265 95% (automated checks)\n\n---\n\n## Cost Model & Budget Guardrails\n\n### Local LLM (Default)\n- **Cost:** $0 (Ollama with local models)\n- **Hardware:** 8GB RAM minimum (nomic-embed-text: 7B params)\n- **Pros:** Free, private, no rate limits\n- **Cons:** Requires local hardware, slower than paid APIs\n\n### Paid API (Optional - Future)\n- **Estimated Cost:** $0.001 per bookmark (2K input tokens + 500 output tokens @ $0.0003/1K tokens)\n- **1,000 bookmarks:** ~$1\n- **10,000 bookmarks:** ~$10\n- **With Skills + Learning Materials:** ~$5-10 per 1,000 bookmarks (3-5\u00d7 more tokens)\n\n**Budget Guardrails:**\n- Max spend per month: $50 (configurable via `--max-llm-spend`)\n- Confirmation required if estimated cost > $10\n- Kill switch: if cost > $50/month, require explicit re-authorization\n\n---\n\n## Data Lifecycle & Retention\n\n### Retention Policy\n- **Cached LLM responses:** 30 days TTL (\u501f\u9274 Summarize)\n- **Generated Skills:** Retain indefinitely (unless user deletes)\n- **Learning Materials:** Retain indefinitely (unless user deletes)\n- **Recaps:** Retain for 90 days, then auto-archive\n\n### Deletion Policy\n- User can delete individual Skills/Learning Materials via CLI\n- `--clear-cache` deletes all cached data\n- `--purge` deletes all generated materials (Skills, Learning Materials)\n\n### Data Storage\n- **Cache:** SQLite database at `~/.xkit/cache.sqlite`\n- **Skills:** `.claude/skills-review/` and `.claude/skills/`\n- **Learning Materials:** `~/.xkit/learning/`\n- **Recaps:** `~/.xkit/recaps/`\n\n---\n\n## Launch & Rollback Guardrails\n\n### Go/No-Go Metrics (Phase 1B: Enhanced Summarization)\n**Go Criteria:**\n- [ ] Summary quality \u2265 4.0/5.0 (user surveys, n=30)\n- [ ] Latency \u2264 1.5\u00d7 baseline (measured with 100 bookmarks)\n- [ ] Zero critical security vulnerabilities (penetration testing)\n- [ ] Cache hit rate \u2265 60% on second run\n- [ ] User engagement rate (reads full summary) \u2265 60%\n\n**No-Go Criteria:**\n- Summary quality < 3.5/5.0\n- Latency > 2\u00d7 baseline\n- Any critical security vulnerabilities\n- Cache hit rate < 40%\n\n**Rollback Plan:**\n- Feature flag: `--features enhanced-summarization` (opt-in initially)\n- Fallback to old summarization if new fails\n- Data migration path (old to new format)\n- `--summarize-legacy` flag to force old behavior\n\n### Go/No-Go Metrics (Phase 2: Skill Generation)\n**Go Criteria:**\n- [ ] Skill extraction precision \u2265 80% (manual audit)\n- [ ] 10+ useful skills from test data\n- [ ] User approval rate \u2265 60%\n- [ ] Zero unsafe code in approved skills (manual audit)\n\n**No-Go Criteria:**\n- Precision < 60%\n- User approval rate < 40%\n- Any unsafe code in approved skills\n\n**Rollback Plan:**\n- Disable feature flag: `--no-features skill-generation`\n- Remove `xkit generate-skills` command from docs\n- Delete `.claude/skills-review/` directory (preserve `.claude/skills/`)\n\n### Go/No-Go Metrics (Phase 3: Learning Materials)\n**Go Criteria:**\n- [ ] Learning material completion rate \u2265 60% (A/B test)\n- [ ] User satisfaction \u2265 3.5/5.0 (surveys)\n- [ ] Generation time \u2264 5\u00d7 baseline\n\n**No-Go Criteria:**\n- Completion rate < 40%\n- Satisfaction < 3.0/5.0\n- Generation time > 10\u00d7 baseline\n\n**Rollback Plan:**\n- Disable feature flag: `--no-features learning-materials`\n- Remove `xkit learn` command from docs\n- Archive `~/.xkit/learning/` directory\n\n---\n\n## Post-Launch Monitoring Plan\n\n### Metrics Dashboard (Optional - v2.0)\n**Summary Metrics:**\n- Summaries generated per day\n- Average summary quality (user ratings)\n- Persona/length usage distribution\n- Cache hit rate\n\n**Skill Metrics:**\n- Skills generated per day\n- Approval rate (review \u2192 approved)\n- Confidence distribution\n- Category distribution\n\n**Learning Material Metrics:**\n- Materials generated per day\n- Completion rate\n- Satisfaction score\n- Type distribution (study-guide vs flashcards vs quiz)\n\n### Alerts\n- **Critical:** Summary quality < 3.5/5.0 for 24 hours\n- **Critical:** LLM error rate > 10% for 1 hour\n- **Warning:** Cache hit rate < 40% for 7 days\n- **Info:** Feature usage < 10% for 30 days\n\n### User Feedback Loop\n- In-app rating: \"Rate this summary (1-5 stars)\"\n- Quarterly surveys: satisfaction, feature requests\n- GitHub Issues: bug reports, feature requests\n\n---\n\n## Support / Ops Impact\n\n### Runbooks\n\n#### Troubleshooting Summarization\n```bash\n# Check Ollama status\nxkit status\n\n# Clear cache if stale\nxkit cache --clear\n\n# Force specific persona/length\nxkit archive --summarize --persona technical-researcher --length long\n\n# Enable debug logging\nxkit archive --summarize --log-level debug\n\n# Verify template syntax\nxkit validate-templates\n```\n\n#### Troubleshooting Skill Generation\n```bash\n# List pending review skills\nls -la .claude/skills-review/\n\n# Approve skill (manual)\nmv .claude/skills-review/skill-name.md .claude/skills/\n\n# Reject skill (manual)\nrm .claude/skills-review/skill-name.md\n\n# Adjust confidence threshold\nxkit generate-skills --min-confidence 0.8\n```\n\n#### Troubleshooting Learning Materials\n```bash\n# List generated materials\nls -la ~/.xkit/learning/\n\n# Regenerate material\nxkit learn --generate study-guide --from \"SwiftUI animations\" --force\n\n# Check difficulty level\nxkit learn --generate flashcards --from \"TypeScript\" --difficulty intermediate\n```\n\n### Documentation\n- CLI help: `xkit --help`, `xkit archive --help`\n- Feature docs: `docs/enhanced-summarization.md`, `docs/skill-generation.md`, `docs/learning-materials.md`\n- Template guide: `docs/custom-templates.md`\n- Troubleshooting: `docs/troubleshooting.md`\n\n### Support Channels\n- GitHub Issues: bug reports, feature requests\n- GitHub Discussions: usage questions, tips & tricks\n\n---\n\n## Compliance & Regulatory Review Triggers\n\n### Data Privacy\n- **PII in Bookmarks:** User bookmarks may contain personal data (names, emails, addresses)\n- **Handling:** PII stored in plaintext, sent to LLM\n- **Mitigation:**\n  - Add `--redact-pii` flag (optional, uses NER to redact)\n  - Document that LLM provider receives bookmark content\n  - Add privacy notice to README\n\n### Security\n- **Prompt Injection:** Malicious bookmark content manipulates LLM\n- **Handling:** XML tag escaping before prompt insertion\n- **Mitigation:**\n  - Penetration testing before GA\n  - Bug bounty program (post-GA)\n\n### Intellectual Property\n- **Generated Skills:** May contain code from bookmarked repos\n- **Handling:** Skills include reference to original bookmark\n- **Mitigation:**\n  - Add attribution to generated Skills\n  - Document that users are responsible for license compliance\n\n---\n\n## Ownership & RACI\n\n### Responsible (Implementer)\n- **@jamiecraik:** Implementation, testing, documentation\n\n### Accountable (Decision Maker)\n- **@jamiecraik:** Final approval on all decisions\n\n### Consulted (Subject Matter Experts)\n- **Summarize Community:** Prompt engineering patterns (via GitHub issues/docs)\n- **Claude Code Users:** Skill format validation (via Discord/GitHub)\n\n### Informed (Stakeholders)\n- **xKit Users:** Feature feedback, testing, validation\n\n---\n\n## Dependency SLAs & Vendor Risk\n\n### Internal Dependencies\n- **Ollama:** Local LLM runtime (no SLA, user-managed)\n- **Node.js:** Runtime environment (LTS support: 18 months)\n- **pnpm:** Package manager (community support)\n\n### External Dependencies (Future - v2.0+)\n- **OpenAI API:** 99.9% uptime SLA, rate limits apply\n- **Anthropic API:** 99.9% uptime SLA, rate limits apply\n- **Firecrawl:** 99.9% uptime SLA, pay-per-use\n\n**Mitigation:**\n- Default to local Ollama (no external dependencies)\n- Fallback chain: Ollama \u2192 OpenAI free \u2192 paid models\n- Circuit breaker: disable paid APIs if error rate > 10%\n\n---\n\n## Localization & Internationalization\n\n### v1.0 Stance\n- **Language:** English only\n- **Rationale:** Validate demand in English-speaking market first\n- **Future:** Multi-language support if international demand exists\n\n### v2.0+ Considerations\n- Language detection: Detect bookmark content language\n- Multi-language templates: Translate personas and prompts\n- Locale-specific formatting: Date/time, number formats\n\n---\n\n## Backward Compatibility & Deprecation\n\n### Backward Compatibility\n- **Existing CLI:** All existing flags work as before\n- **New Flags:** Opt-in via `--summarize`, `--persona`, `--length`\n- **Data Format:** Existing markdown files unchanged\n\n### Deprecation Policy\n- **Old Summarization:** Deprecate after 6 months of enhanced summarization GA\n- **Notice:** Add deprecation notice to CLI help and docs\n- **Grace Period:** 6 months (2 minor releases)\n- **Removal:** Remove in v1.7.0 (if enhanced summarization GA in v1.0.0)\n\n---\n\n## Experimentation & Feature Flags\n\n### Feature Flags\n```bash\n# Enable enhanced summarization (opt-in initially)\nxkit archive --features enhanced-summarization --summarize\n\n# Enable skill generation (conditional on user research)\nxkit generate-skills --features skill-generation --category github\n\n# Enable learning materials (conditional on user research)\nxkit learn --features learning-materials --generate study-guide\n```\n\n### Rollout Plan\n1. **Alpha:** Internal testing (@jamiecraik only)\n2. **Beta:** Friendly users (n=5-10) with feature flags\n3. **GA:** Feature flags removed, features enabled by default\n\n### Kill Criteria\n- **Enhanced Summarization:** If quality < 3.5/5.0 for 30 days, revert to legacy\n- **Skill Generation:** If precision < 60% for 30 days, disable feature\n- **Learning Materials:** If unused by 20% of users after 30 days, deprecate\n\n---\n\n## Kill Criteria\n\n### Project Level\n- **User Demand:** If < 20% of users adopt any enhanced features after 90 days, sunset project\n- **Cost:** If LLM costs > $100/month with < 10% adoption, re-architect or sunset\n- **Security:** If any critical vulnerability is exploited, halt all features until fixed\n\n### Feature Level\n- **Enhanced Summarization:** Kill if quality < 3.5/5.0 OR latency > 3\u00d7 baseline for 30 days\n- **Skill Generation:** Kill if precision < 60% OR approval rate < 40% for 30 days\n- **Learning Materials:** Kill if completion rate < 40% OR satisfaction < 3.0/5.0 for 30 days\n\n---\n\n## Decision Log / ADRs\n\n### ADR-001: Use Tagged Prompt Structure from Summarize\n**Date:** 2026-01-20\n**Status:** Accepted\n**Context:** Need proven prompt engineering pattern for engaging summaries\n**Decision:** Adopt Summarize's XML-style tagged prompts (`<instructions>`, `<context>`, `<content>`)\n**Rationale:**\n- Battle-tested in production (Summarize has 200+ tests)\n- Clear separation of concerns (instructions vs context vs content)\n- Easy to extend with personas, lengths, content types\n**Consequences:**\n- Must implement prompt injection protection (XML tag escaping)\n- Templates will be more verbose than simple prompts\n**Alternatives Considered:**\n- Simple text prompts: rejected (less structured, harder to maintain)\n- JSON prompts: rejected (less human-readable)\n**Revisit:** After 6 months of production use\n\n### ADR-002: Default to Local Ollama vs Paid APIs\n**Date:** 2026-01-20\n**Status:** Accepted\n**Context:** Need to choose LLM provider for summarization\n**Decision:** Default to local Ollama with `nomic-embed-text`, support paid APIs via `--model` flag\n**Rationale:**\n- Zero cost for users\n- Privacy (data never leaves machine)\n- No rate limits\n- Aligns with xKit's existing infrastructure\n**Consequences:**\n- Slower than paid APIs (acceptable for CLI workflow)\n- Requires 8GB RAM (user hardware requirement)\n**Alternatives Considered:**\n- Default to OpenAI API: rejected (cost, privacy, rate limits)\n- Hybrid (paid API first, Ollama fallback): rejected (cost, complexity)\n**Revisit:** If users demand faster performance and are willing to pay\n\n### ADR-003: Manual Approval Required for Skills\n**Date:** 2026-01-20\n**Status:** Accepted\n**Context:** Skills contain executable code, must ensure safety\n**Decision:** Write generated Skills to `.claude/skills-review/`, require manual approval before `.claude/skills/`\n**Rationale:**\n- Risk of hallucinated or unsafe code\n- User trust critical for adoption\n- Legal liability concerns\n**Consequences:**\n- Extra step in workflow (friction)\n- May reduce Skills usage\n**Alternatives Considered:**\n- Auto-add to `.claude/skills/`: rejected (unsafe)\n- No Skills feature: rejected (high user value)\n**Revisit:** If confidence scoring improves to \u2265 95% precision\n\n### ADR-004: SQLite Caching Before Features\n**Date:** 2026-01-20\n**Status:** Accepted\n**Context:** Adversarial review identified 36 ERROR findings, no observability\n**Decision:** Implement Phase 0 (caching, observability, security) before adding features\n**Rationale:**\n- Cannot measure success without observability\n- Cannot ship safely without security foundations\n- Summarize's cache eliminates 60%+ redundant API calls\n**Consequences:**\n- Delays feature delivery by 3 days\n- Adds complexity to architecture\n**Alternatives Considered:**\n- Build features first, add foundations later: rejected (technical debt trap)\n**Revisit:** After Phase 0 complete, reassess timeline\n\n### ADR-005: User Research Before Skills/Learning Materials\n**Date:** 2026-01-20\n**Status:** Accepted\n**Context:** No evidence users want Skills or learning materials (per adversarial review)\n**Decision:** Add Phase 1A (3 days user research) before building Phases 2-3\n**Rationale:**\n- Risk building features nobody uses\n- Low-cost investment (3 days) vs high-risk implementation (10+ days)\n- Go/no-go criteria prevent wasted effort\n**Consequences:**\n- Delays feature delivery by 3 days\n- May discover Skills/learning materials unwanted (kill features)\n**Alternatives Considered:**\n- Skip research, build anyway: rejected (high risk of waste)\n**Revisit:** After user research complete\n\n---\n\n## References\n\n- [Summarize Feature Analysis](.spec/spec-2026-01-20-summarize-feature-analysis.md)\n- [Summarize Reconnaissance Report](/Users/jamiecraik/dev/recon-workbench/runs/summarize-session/derived/report.md)\n- [Adversarial Review Output](/Users/jamiecraik/.claude/plans/adversarial-review-output.md)\n- [xKit Repository](https://github.com/jscraik/xKit)\n- [Summarize Repository](https://github.com/steipete/summarize)\n\n---\n\n## Appendix: Example Outputs\n\n### Enhanced Summary (Persona: Technical Researcher, Length: Long)\n```markdown\n### Core Concepts: Type-Level Programming\n\nTypeScript's type system extends beyond simple runtime type checking into a\nTuring-complete language for compile-time computation. This enables powerful\nabstractions like conditional types, mapped types, and template literal types\nthat can validate and transform data structures at compile time.\n\n### Conditional Types: Dynamic Type Decisions\n\nConditional types serve as the fundamental control flow primitive in TypeScript's\ntype system. They enable type-level if/else decisions that can distribute unions,\nextract properties, and enforce complex constraints. The syntax `T extends U ? X : Y`\nmirrors ternary operators but operates entirely on types rather than values.\n\nPractical applications include:\n- API response validation (`FetchResponse<200>` vs `FetchResponse<500>`)\n- Function overloads via type inference\n- Exclude/Extract utility types under the hood\n\n### Template Literal Types: Type-Safe Strings\n\nTemplate literal types enable string manipulation at the type level, supporting\ninterpolation, unions, and pattern matching. This makes it possible to encode\nevent names (`\"click_${ButtonID}\"`), CSS selectors, or route patterns as types\nthat prevent invalid strings from even compiling.\n\n[continues with detailed technical analysis]\n```\n\n### Generated Skill\n```markdown\n---\nname: Implement Type-Safe API Response Validation\ndescription: Validate API responses at compile time using conditional types\ntriggers:\n  - User adds REST API integration\n  - Type safety is critical for API contracts\ncategory: code-pattern\n---\n\n# Implement Type-Safe API Response Validation\n\n## When to Use This Skill\nUse when integrating with REST APIs where:\n- Response structure varies by status code\n- Type safety is more important than runtime flexibility\n- API contracts are stable or versioned\n\n## Implementation\n\n### Step 1: Define Response Types\n```typescript\ntype ApiResponse<T, Code extends number> = {\n  status: Code;\n  data: T;\n};\n\ntype SuccessResponse<T> = ApiResponse<T, 200>;\ntype ErrorResponse = ApiResponse<{ message: string }, 400 | 500>;\n```\n\n### Step 2: Create Fetch Wrapper\n```typescript\nasync function fetchTyped<T>(\n  url: string\n): Promise<SuccessResponse<T> | ErrorResponse> {\n  const response = await fetch(url);\n  const data = await response.json();\n  return { status: response.status, data };\n}\n```\n\n### Step 3: Use with Type Guards\n```typescript\nconst result = await fetchTyped<User>('/api/user/1');\nif (result.status === 200) {\n  // TypeScript knows result.data is User\n  console.log(result.data.name);\n} else {\n  // TypeScript knows result.data is { message: string }\n  console.error(result.data.message);\n}\n```\n\n## Examples\n\n### Example 1: User API\n```typescript\ninterface User {\n  id: number;\n  name: string;\n  email: string;\n}\n\nconst result = await fetchTyped<User>('/api/user/1');\n// TypeScript infers result as:\n// SuccessResponse<User> | ErrorResponse\n```\n\n### Example 2: Search API with Union Responses\n```typescript\ntype SearchResponse =\n  | ApiResponse<{ results: User[] }, 200>\n  | ApiResponse<{ error: string }, 400>\n  | ApiResponse<never, 500>;\n\nconst search = await fetchTyped<SearchResponse>('/api/search?q=test');\n// TypeScript handles all status codes\n```\n\n## Edge Cases\n\n### Edge Case 1: Dynamic Status Codes\nIf status codes are dynamic (not known at compile time), use a more flexible type:\n```typescript\ntype LooseApiResponse<T> = {\n  status: number;\n  data: T | null;\n};\n```\n\n### Edge Case 2: Nested Discriminated Unions\nFor complex response structures, use discriminated unions recursively:\n```typescript\ntype Response<T, E> =\n  | { ok: true; data: T }\n  | { ok: false; error: E };\n```\n\n## Common Pitfalls\n\n1. **Over-constraining:** Don't use conditional types if status codes are dynamic\n2. **Runtime validation:** Types don't validate at runtime, still need Zod/etc\n3. **API changes:** Keep types in sync with API contracts\n```\n\n### Study Guide Excerpt\n```markdown\n# Study Guide: Advanced TypeScript Type System Patterns\n\n## Learning Objectives\nBy the end of this guide, you will be able to:\n- Design conditional types for dynamic type decisions\n- Use template literal types for type-safe string manipulation\n- Build type-level parsers and validators\n- Apply mapped types and utility types in real-world scenarios\n\n## Difficulty: Intermediate\n**Prerequisites:**\n- Familiarity with basic TypeScript types (interfaces, type aliases)\n- Understanding of generics and type inference\n- Experience with utility types (Partial, Required, Pick)\n\n**Estimated Time:** 45 minutes\n\n## Core Concepts\n\n### Conditional Types\n**Definition:** Type-level if/else statements that enable conditional type selection based on type relationships.\n\n**Syntax:** `T extends U ? X : Y`\n\n**How It Works:**\n1. Check if type `T` extends type `U`\n2. If true, return type `X`\n3. If false, return type `Y`\n\n**Example:**\n```typescript\ntype IsArray<T> = T extends any[] ? true : false;\n\ntype Test1 = IsArray<number>; // false\ntype Test2 = IsArray<string[]>; // true\n```\n\n**Use Cases:**\n- API response validation (different types for different status codes)\n- Function overloads via type inference\n- Exclude/Extract utility types\n\n## Exercises\n\n### Exercise 1: Build a NonNullable Utility Type\n**Goal:** Create a utility type that removes `null` and `undefined` from a type.\n\n**Hint:** Use conditional types with union types.\n\n<details>\n<summary>Solution</summary>\n\n```typescript\ntype NonNullable<T> = T extends null | undefined ? never : T;\n\ntype Test = NonNullable<string | null | undefined>; // string\n```\n</details>\n\n### Exercise 2: Build a Type Guard Helper\n**Goal:** Create a type that extracts the return type of a function.\n\n**Hint:** Use TypeScript's built-in `ReturnType` utility type as inspiration.\n\n<details>\n<summary>Solution</summary>\n\n```typescript\ntype MyReturnType<T extends (...args: any) => any> = T extends (\n  ...args: any\n) => infer R\n  ? R\n  : any;\n\nfunction foo() {\n  return { x: 1, y: 2 };\n}\n\ntype FooReturn = MyReturnType<typeof foo>; // { x: number; y: number }\n```\n</details>\n\n## Flashcards\n\n**Q1:** What is the syntax for conditional types?\n**A1:** `T extends U ? X : Y`\n\n**Q2:** How do you extract the type of a promise's resolved value?\n**A2:** `T extends Promise<infer U> ? U : never`\n\n**Q3:** What is a distributive conditional type?\n**A3:** When a conditional type is applied to a union type, it distributes over each union member: `(A | B) extends C ? D : E` becomes `(A extends C ? D : E) | (B extends C ? D : E)`\n\n## Next Steps\n- Practice with [TypeScript Type Challenges](https://github.com/type-challenges/type-challenges)\n- Explore mapped types and template literal types\n- Build a type-level parser for a JSON schema\n```\n\n---\n\n**Document Version:** 1.0\n**Last Updated:** 2026-01-20\n**Status:** Ready for user research\n\n**Next Steps:**\n1. Review and approve PRD\n2. Conduct user research (Phase 1A, 3 days)\n3. Implement Phase 0 (Foundation, 3 days)\n4. Build Phase 1B (Enhanced Summarization, 4 days)\n5. Evaluate go/no-go for Phases 2-3 based on research\n\n---\n\n## Standards Mapping\n\n**Gold Industry Standard Compliance** (baseline: January 31, 2026)\n\n- **Security:** Prompt injection protection, template validation, code review disclaimers\n- **Testing:** User acceptance testing (n=30), manual audits (n=100), A/B testing\n- **Documentation:** Comprehensive PRD, CLI help, feature docs, troubleshooting guides\n- **Supply Chain:** pnpm lockfile, frozen-lockfile installs, dependency audits\n- **Code Quality:** TypeScript strict mode, Biome linting, manual code reviews\n\n**Checks Executed:**\n- [x] Adversarial review (7 role-based passes, 36 ERROR findings addressed)\n- [x] User research plan (n=10-15 interviews)\n- [x] Security considerations (prompt injection, template validation, PII)\n- [x] Performance targets (latency, throughput, resource usage)\n- [x] Reliability targets (availability, error rate, data quality)\n- [x] Cost model (local vs paid APIs, budget guardrails)\n\n**Review Artifact:** Adversarial review conducted per product-spec skill requirements. All ERROR findings from review incorporated into revised plan with Phase 0 (Foundation), Phase 1A (User Research), and conditional Phases 2-3.\n\n**Deviations/Risks:**\n- **Deviation:** 11-day timeline deemed unrealistic by adversarial review. Revised to 23 days with user research and validation.\n- **Risk:** User research may reveal low demand for Skills/learning materials. Mitigated with go/no-go criteria (\u2265 50% interest required).\n- **Risk:** LLM hallucination in Skill extraction. Mitigated with confidence scoring, manual approval, two-stage validation.\n- **Risk:** Prompt injection vulnerability. Mitigated with XML tag escaping, UUID delimiters, penetration testing.\n\n---\n\n**End of PRD + Technical Specification**\n\n\n</PROJECT_MEMORY>\n\nExit protocol (required):\nAt the very end of your output, print exactly one line:\nEXIT_SIGNAL: true  OR  EXIT_SIGNAL: false\n\n"
  ],
  "returncode": 124,
  "started_at": "2026-01-20T22:28:58.429545+00:00",
  "ended_at": "2026-01-20T22:30:58.444269+00:00",
  "duration_seconds": 120.01461100578308,
  "stdout_path": ".ralph/logs/20260120T222857Z-iter0036-claude.log",
  "stderr_path": null,
  "notes": {
    "prompt_hash": "0ca6d51977f342560fda861a79699336005eb3342fbdee4035e3e3731154e3f7",
    "stdout_tail": "",
    "stderr_tail": "Command timed out after 120s: claude -p You are operating inside the Ralph Gold loop.\n\nRules:\n- Do exactly ONE task per iteration.\n- Use the Memory Files below as the source of truth (especially ANCHOR and any Repo Prompt context pack).\n- Make the smallest correct change-set that satisfies the task acceptance criteria.\n- When you finish the task, mark it done in the PRD tracker.\n- Do not mark tasks done if you did not run/confirm the configured gates pass locally.\n- If you are blocked, record a \n... [truncated 123299 chars] ...\npeScript strict mode, Biome linting, manual code reviews\n\n**Checks Executed:**\n- [x] Adversarial review (7 role-based passes, 36 ERROR findings addressed)\n- [x] User research plan (n=10-15 interviews)\n- [x] Security considerations (prompt injection, template validation, PII)\n- [x] Performance targets (latency, throughput, resource usage)\n- [x] Reliability targets (availability, error rate, data quality)\n- [x] Cost model (local vs paid APIs, budget guardrails)\n\n**Review Artifact:** Adversarial review conducted per product-spec skill requirements. All ERROR findings from review incorporated into revised plan with Phase 0 (Foundation), Phase 1A (User Research), and conditional Phases 2-3.\n\n**Deviations/Risks:**\n- **Deviation:** 11-day timeline deemed unrealistic by adversarial review. Revised to 23 days with user research and validation.\n- **Risk:** User research may reveal low demand for Skills/learning materials. Mitigated with go/no-go criteria (\u2265 50% interest required).\n- **Risk:** LLM hallucination in Skill extraction. Mitigated with confidence scoring, manual approval, two-stage validation.\n- **Risk:** Prompt injection vulnerability. Mitigated with XML tag escaping, UUID delimiters, penetration testing.\n\n---\n\n**End of PRD + Technical Specification**\n\n\n</PROJECT_MEMORY>\n\nExit protocol (required):\nAt the very end of your output, print exactly one line:\nEXIT_SIGNAL: true  OR  EXIT_SIGNAL: false\n\n\nPartial output:\n"
  },
  "_schema": "ralph_gold.receipt.v1"
}
