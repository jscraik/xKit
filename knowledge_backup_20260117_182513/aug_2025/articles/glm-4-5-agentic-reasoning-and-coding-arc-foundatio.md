---
title: "GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models"
type: "article"
date_added: "Mon Aug 11 03:43:54 +0000 2025"
source: "https://arxiv.org/abs/2508.06471"
via: "Twitter bookmark from @Zai_org"
url: "https://arxiv.org/abs/2508.06471"
---

# GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models

## Summary

We present GLM-4.5, an open-source Mixture-of-Experts (MoE) large language model with 355B total parameters and 32B activated parameters, featuring a hybrid reasoning method that supports both thinking and direct response modes. Through multi-stage training on 23T tokens and comprehensive post-training with expert model iteration and reinforcement learning, GLM-4.5 achieves strong performance across agentic, reasoning, and coding (ARC) tasks, scoring 70.1% on TAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. With much fewer parameters than several competitors, GLM-4.5 ranks 3rd overall among all evaluated models and 2nd on agentic benchmarks. We release both GLM-4.5 (355B parameters) and a compact version, GLM-4.5-Air (106B parameters), to advance research in reasoning and agentic AI systems. Code, models, and more information are available at https://github.com/zai-org/GLM-4.5.

## Links

- [Read Article](https://arxiv.org/abs/2508.06471)
- [Original Tweet](https://x.com/Zai_org/status/1954750596634054965)

## Discovered Via

> Presenting the GLM-4.5 technical report!ðŸ‘‡
https://t.co/6sYwjRsHho

This work demonstrates how we developed models that excel at reasoning, coding, and agentic tasks through a unique, multi-stage training paradigm.

Key innovations include expert model iteration with self-distillation to unify capabilities, a hybrid reasoning mode for dynamic problem-solving, and a difficulty-based reinforcement learning curriculum.

â€” @Zai_org (Z.ai)